{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15501a13",
   "metadata": {},
   "source": [
    "Convert model to onnx format for deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7356b987",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c13ed02",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-uncased\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"./output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c278330",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the model to evaluation mode\n",
    "# so that some layer is disable in inference mode, rather than training mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a15b98bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_19048\\188067039.py:3: UserWarning: # 'dynamic_axes' is not recommended when dynamo=True, and may lead to 'torch._dynamo.exc.UserError: Constraints violated.' Supply the 'dynamic_shapes' argument instead if export is unsuccessful.\n",
      "  torch.onnx.export(\n",
      "W1125 19:55:13.975000 19048 Lib\\site-packages\\torch\\onnx\\_internal\\exporter\\_compat.py:114] Setting ONNX exporter to use operator set version 18 because the requested opset_version 17 is a lower version than we have implementations for. Automatic version conversion will be performed, which may not be successful at converting to the requested version. If version conversion is unsuccessful, the opset version of the exported model will be kept at 18. Please consider setting opset_version >=18 to leverage latest ONNX features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.onnx] Obtain model graph for `BertForSequenceClassification([...]` with `torch.export.export(..., strict=False)`...\n",
      "[torch.onnx] Obtain model graph for `BertForSequenceClassification([...]` with `torch.export.export(..., strict=False)`... ✅\n",
      "[torch.onnx] Run decomposition...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model version conversion is not supported by the onnxscript version converter and fallback is enabled. The model will be converted using the onnx C API (target version: 17).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.onnx] Run decomposition... ✅\n",
      "[torch.onnx] Translate the graph into ONNX...\n",
      "[torch.onnx] Translate the graph into ONNX... ✅\n",
      "Applied 17 of general pattern rewrite rules.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ONNXProgram(\n",
       "    model=\n",
       "        <\n",
       "            ir_version=10,\n",
       "            opset_imports={'': 17},\n",
       "            producer_name='pytorch',\n",
       "            producer_version='2.9.0+cu130',\n",
       "            domain=None,\n",
       "            model_version=None,\n",
       "        >\n",
       "        graph(\n",
       "            name=main_graph,\n",
       "            inputs=(\n",
       "                %\"input_ids\"<INT64,[1,s41]>,\n",
       "                %\"attention_mask\"<INT64,[1,s41]>,\n",
       "                %\"token_type_ids\"<INT64,[1,s41]>\n",
       "            ),\n",
       "            outputs=(\n",
       "                %\"logits\"<FLOAT,[1,2]>\n",
       "            ),\n",
       "            initializers=(\n",
       "                %\"bert.embeddings.LayerNorm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.embeddings.LayerNorm.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.0.attention.self.query.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.0.attention.self.key.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.0.attention.self.value.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.0.attention.output.dense.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.0.attention.output.LayerNorm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.0.attention.output.LayerNorm.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.0.output.dense.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.0.output.LayerNorm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.0.output.LayerNorm.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.1.attention.self.query.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.1.attention.self.key.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.1.attention.self.value.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.1.attention.output.dense.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.1.attention.output.LayerNorm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.1.attention.output.LayerNorm.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.1.output.dense.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.1.output.LayerNorm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.1.output.LayerNorm.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.2.attention.self.query.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.2.attention.self.key.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.2.attention.self.value.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.2.attention.output.dense.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.2.attention.output.LayerNorm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.2.attention.output.LayerNorm.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.2.output.dense.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.2.output.LayerNorm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.2.output.LayerNorm.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.3.attention.self.query.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.3.attention.self.key.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.3.attention.self.value.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.3.attention.output.dense.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.3.attention.output.LayerNorm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.3.attention.output.LayerNorm.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.3.output.dense.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.3.output.LayerNorm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.3.output.LayerNorm.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.4.attention.self.query.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.4.attention.self.key.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.4.attention.self.value.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.4.attention.output.dense.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.4.attention.output.LayerNorm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.4.attention.output.LayerNorm.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.4.output.dense.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.4.output.LayerNorm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.4.output.LayerNorm.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.5.attention.self.query.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.5.attention.self.key.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.5.attention.self.value.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.5.attention.output.dense.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.5.attention.output.LayerNorm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.5.attention.output.LayerNorm.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.5.output.dense.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.5.output.LayerNorm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.5.output.LayerNorm.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.6.attention.self.query.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.6.attention.self.key.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.6.attention.self.value.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.6.attention.output.dense.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.6.attention.output.LayerNorm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.6.attention.output.LayerNorm.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.6.output.dense.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.6.output.LayerNorm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.6.output.LayerNorm.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.7.attention.self.query.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.7.attention.self.key.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.7.attention.self.value.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.7.attention.output.dense.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.7.attention.output.LayerNorm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.7.attention.output.LayerNorm.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.7.output.dense.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.7.output.LayerNorm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.7.output.LayerNorm.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.8.attention.self.query.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.8.attention.self.key.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.8.attention.self.value.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.8.attention.output.dense.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.8.attention.output.LayerNorm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.8.attention.output.LayerNorm.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.8.output.dense.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.8.output.LayerNorm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.8.output.LayerNorm.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.9.attention.self.query.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.9.attention.self.key.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.9.attention.self.value.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.9.attention.output.dense.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.9.attention.output.LayerNorm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.9.attention.output.LayerNorm.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.9.output.dense.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.9.output.LayerNorm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.9.output.LayerNorm.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.10.attention.self.query.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.10.attention.self.key.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.10.attention.self.value.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.10.attention.output.dense.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.10.attention.output.LayerNorm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.10.attention.output.LayerNorm.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.10.output.dense.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.10.output.LayerNorm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.10.output.LayerNorm.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.11.attention.self.query.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.11.attention.self.key.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.11.attention.self.value.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.11.attention.output.dense.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.11.attention.output.LayerNorm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.11.attention.output.LayerNorm.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.11.output.dense.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.11.output.LayerNorm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.11.output.LayerNorm.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.pooler.dense.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"classifier.bias\"<FLOAT,[2]>{TorchTensor<FLOAT,[2]>(Parameter containing: tensor([ 0.0010, -0.0010], requires_grad=True), name='classifier.bias')},\n",
       "                %\"bert.embeddings.position_ids\"<INT64,[1,512]>{TorchTensor(...)},\n",
       "                %\"bert.embeddings.word_embeddings.weight\"<FLOAT,[30522,768]>{TorchTensor(...)},\n",
       "                %\"bert.embeddings.position_embeddings.weight\"<FLOAT,[512,768]>{TorchTensor(...)},\n",
       "                %\"bert.embeddings.token_type_embeddings.weight\"<FLOAT,[2,768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.0.intermediate.dense.bias\"<FLOAT,[3072]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.1.intermediate.dense.bias\"<FLOAT,[3072]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.2.intermediate.dense.bias\"<FLOAT,[3072]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.3.intermediate.dense.bias\"<FLOAT,[3072]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.4.intermediate.dense.bias\"<FLOAT,[3072]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.5.intermediate.dense.bias\"<FLOAT,[3072]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.6.intermediate.dense.bias\"<FLOAT,[3072]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.7.intermediate.dense.bias\"<FLOAT,[3072]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.8.intermediate.dense.bias\"<FLOAT,[3072]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.9.intermediate.dense.bias\"<FLOAT,[3072]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.10.intermediate.dense.bias\"<FLOAT,[3072]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.11.intermediate.dense.bias\"<FLOAT,[3072]>{TorchTensor(...)},\n",
       "                %\"bert.pooler.dense.weight\"<FLOAT,[768,768]>{TorchTensor(...)},\n",
       "                %\"classifier.weight\"<FLOAT,[2,768]>{TorchTensor(...)},\n",
       "                %\"val_4\"<INT64,[1]>{Tensor<INT64,[1]>(array([0]), name='val_4')},\n",
       "                %\"val_11\"<INT64,[1]>{Tensor<INT64,[1]>(array([1]), name='val_11')},\n",
       "                %\"clone_1\"<FLOAT,[]>{Tensor<FLOAT,[]>(array(1., dtype=float32), name='clone_1')},\n",
       "                %\"val_36\"<FLOAT,[]>{Tensor<FLOAT,[]>(array(-3.4028235e+38, dtype=float32), name='val_36')},\n",
       "                %\"val_37\"<FLOAT,[768,768]>{Tensor(...)},\n",
       "                %\"val_44\"<INT64,[4]>{Tensor<INT64,[4]>(array([ 1, -1, 12, 64]), name='val_44')},\n",
       "                %\"val_45\"<FLOAT,[768,768]>{Tensor(...)},\n",
       "                %\"val_53\"<FLOAT,[768,768]>{Tensor(...)},\n",
       "                %\"val_84\"<FLOAT,[1]>{Tensor<FLOAT,[1]>(array([0.35355338], dtype=float32), name='val_84')},\n",
       "                %\"val_96\"<FLOAT,[768,768]>{Tensor(...)},\n",
       "                %\"val_100\"<FLOAT,[768,3072]>{Tensor(...)},\n",
       "                %\"val_109\"<FLOAT,[3072,768]>{Tensor(...)},\n",
       "                %\"val_113\"<FLOAT,[768,768]>{Tensor(...)},\n",
       "                %\"val_121\"<FLOAT,[768,768]>{Tensor(...)},\n",
       "                %\"val_129\"<FLOAT,[768,768]>{Tensor(...)},\n",
       "                %\"val_170\"<FLOAT,[768,768]>{Tensor(...)},\n",
       "                %\"val_174\"<FLOAT,[768,3072]>{Tensor(...)},\n",
       "                %\"val_183\"<FLOAT,[3072,768]>{Tensor(...)},\n",
       "                %\"val_187\"<FLOAT,[768,768]>{Tensor(...)},\n",
       "                %\"val_195\"<FLOAT,[768,768]>{Tensor(...)},\n",
       "                %\"val_203\"<FLOAT,[768,768]>{Tensor(...)},\n",
       "                %\"val_244\"<FLOAT,[768,768]>{Tensor(...)},\n",
       "                %\"val_248\"<FLOAT,[768,3072]>{Tensor(...)},\n",
       "                %\"val_257\"<FLOAT,[3072,768]>{Tensor(...)},\n",
       "                %\"val_261\"<FLOAT,[768,768]>{Tensor(...)},\n",
       "                %\"val_269\"<FLOAT,[768,768]>{Tensor(...)},\n",
       "                %\"val_277\"<FLOAT,[768,768]>{Tensor(...)},\n",
       "                %\"val_318\"<FLOAT,[768,768]>{Tensor(...)},\n",
       "                %\"val_322\"<FLOAT,[768,3072]>{Tensor(...)},\n",
       "                %\"val_331\"<FLOAT,[3072,768]>{Tensor(...)},\n",
       "                %\"val_335\"<FLOAT,[768,768]>{Tensor(...)},\n",
       "                %\"val_343\"<FLOAT,[768,768]>{Tensor(...)},\n",
       "                %\"val_351\"<FLOAT,[768,768]>{Tensor(...)},\n",
       "                %\"val_392\"<FLOAT,[768,768]>{Tensor(...)},\n",
       "                %\"val_396\"<FLOAT,[768,3072]>{Tensor(...)},\n",
       "                %\"val_405\"<FLOAT,[3072,768]>{Tensor(...)},\n",
       "                %\"val_409\"<FLOAT,[768,768]>{Tensor(...)},\n",
       "                %\"val_417\"<FLOAT,[768,768]>{Tensor(...)},\n",
       "                %\"val_425\"<FLOAT,[768,768]>{Tensor(...)},\n",
       "                %\"val_466\"<FLOAT,[768,768]>{Tensor(...)},\n",
       "                %\"val_470\"<FLOAT,[768,3072]>{Tensor(...)},\n",
       "                %\"val_479\"<FLOAT,[3072,768]>{Tensor(...)},\n",
       "                %\"val_483\"<FLOAT,[768,768]>{Tensor(...)},\n",
       "                %\"val_491\"<FLOAT,[768,768]>{Tensor(...)},\n",
       "                %\"val_499\"<FLOAT,[768,768]>{Tensor(...)},\n",
       "                %\"val_540\"<FLOAT,[768,768]>{Tensor(...)},\n",
       "                %\"val_544\"<FLOAT,[768,3072]>{Tensor(...)},\n",
       "                %\"val_553\"<FLOAT,[3072,768]>{Tensor(...)},\n",
       "                %\"val_557\"<FLOAT,[768,768]>{Tensor(...)},\n",
       "                %\"val_565\"<FLOAT,[768,768]>{Tensor(...)},\n",
       "                %\"val_573\"<FLOAT,[768,768]>{Tensor(...)},\n",
       "                %\"val_614\"<FLOAT,[768,768]>{Tensor(...)},\n",
       "                %\"val_618\"<FLOAT,[768,3072]>{Tensor(...)},\n",
       "                %\"val_627\"<FLOAT,[3072,768]>{Tensor(...)},\n",
       "                %\"val_631\"<FLOAT,[768,768]>{Tensor(...)},\n",
       "                %\"val_639\"<FLOAT,[768,768]>{Tensor(...)},\n",
       "                %\"val_647\"<FLOAT,[768,768]>{Tensor(...)},\n",
       "                %\"val_688\"<FLOAT,[768,768]>{Tensor(...)},\n",
       "                %\"val_692\"<FLOAT,[768,3072]>{Tensor(...)},\n",
       "                %\"val_701\"<FLOAT,[3072,768]>{Tensor(...)},\n",
       "                %\"val_705\"<FLOAT,[768,768]>{Tensor(...)},\n",
       "                %\"val_713\"<FLOAT,[768,768]>{Tensor(...)},\n",
       "                %\"val_721\"<FLOAT,[768,768]>{Tensor(...)},\n",
       "                %\"val_762\"<FLOAT,[768,768]>{Tensor(...)},\n",
       "                %\"val_766\"<FLOAT,[768,3072]>{Tensor(...)},\n",
       "                %\"val_775\"<FLOAT,[3072,768]>{Tensor(...)},\n",
       "                %\"val_779\"<FLOAT,[768,768]>{Tensor(...)},\n",
       "                %\"val_787\"<FLOAT,[768,768]>{Tensor(...)},\n",
       "                %\"val_795\"<FLOAT,[768,768]>{Tensor(...)},\n",
       "                %\"val_836\"<FLOAT,[768,768]>{Tensor(...)},\n",
       "                %\"val_840\"<FLOAT,[768,3072]>{Tensor(...)},\n",
       "                %\"val_849\"<FLOAT,[3072,768]>{Tensor(...)},\n",
       "                %\"val_853\"<FLOAT,[768,768]>{Tensor(...)},\n",
       "                %\"val_861\"<FLOAT,[768,768]>{Tensor(...)},\n",
       "                %\"val_869\"<FLOAT,[768,768]>{Tensor(...)},\n",
       "                %\"val_910\"<FLOAT,[768,768]>{Tensor(...)},\n",
       "                %\"val_914\"<FLOAT,[768,3072]>{Tensor(...)},\n",
       "                %\"val_923\"<FLOAT,[3072,768]>{Tensor(...)},\n",
       "                %\"val_1\"<INT64,[]>{TensorProtoTensor<INT64,[]>(array(0), name='val_1')},\n",
       "                %\"val_927\"<INT64,[2]>{Tensor<INT64,[2]>(array([1, 2]), name='val_927')},\n",
       "                %\"val_71\"<INT64,[1]>{Tensor<INT64,[1]>(array([9223372036854775807]), name='val_71')},\n",
       "                %\"val_72\"<INT64,[1]>{TensorProtoTensor<INT64,[1]>(array([-1]), name='val_72')},\n",
       "                %\"val_74\"<INT64,[1]>{TensorProtoTensor<INT64,[1]>(array([-2]), name='val_74')},\n",
       "                %\"val_76\"<INT64,[1]>{Tensor<INT64,[1]>(array([-9223372036854775808]), name='val_76')},\n",
       "                %\"val_94\"<INT64,[1]>{Tensor<INT64,[1]>(array([768]), name='val_94')},\n",
       "                %\"val_102\"<FLOAT,[]>{TensorProtoTensor<FLOAT,[]>(array(1.4142135, dtype=float32), name='val_102')},\n",
       "                %\"val_107\"<FLOAT,[]>{TensorProtoTensor<FLOAT,[]>(array(0.5, dtype=float32), name='val_107')}\n",
       "            ),\n",
       "        ) {\n",
       "              0 |  # node_Shape_0\n",
       "                   %\"val_0\"<INT64,[1]> ⬅️ ::Shape(%\"token_type_ids\") {start=1, end=2}\n",
       "              1 |  # node_slice_1\n",
       "                   %\"slice_1\"<INT64,[1,s41]> ⬅️ ::Slice(%\"bert.embeddings.position_ids\"{...}, %\"val_4\"{[0]}, %\"val_0\", %\"val_11\"{[1]}, %\"val_11\"{[1]})\n",
       "              2 |  # node_embedding\n",
       "                   %\"embedding\"<FLOAT,[1,s41,768]> ⬅️ ::Gather(%\"bert.embeddings.word_embeddings.weight\"{...}, %\"input_ids\") {axis=0}\n",
       "              3 |  # node_embedding_1\n",
       "                   %\"embedding_1\"<FLOAT,[1,s41,768]> ⬅️ ::Gather(%\"bert.embeddings.token_type_embeddings.weight\"{...}, %\"token_type_ids\") {axis=0}\n",
       "              4 |  # node_add_8\n",
       "                   %\"add_8\"<FLOAT,[1,s41,768]> ⬅️ ::Add(%\"embedding\", %\"embedding_1\")\n",
       "              5 |  # node_embedding_2\n",
       "                   %\"embedding_2\"<FLOAT,[1,s41,768]> ⬅️ ::Gather(%\"bert.embeddings.position_embeddings.weight\"{...}, %\"slice_1\") {axis=0}\n",
       "              6 |  # node_add_21\n",
       "                   %\"add_21\"<FLOAT,[1,s41,768]> ⬅️ ::Add(%\"add_8\", %\"embedding_2\")\n",
       "              7 |  # node_layer_norm\n",
       "                   %\"layer_norm\"<FLOAT,[1,s41,768]>, %\"\"<FLOAT,[1,s41,1]>, %\"\"<FLOAT,[1,s41,1]> ⬅️ ::LayerNormalization(%\"add_21\", %\"bert.embeddings.LayerNorm.weight\"{...}, %\"bert.embeddings.LayerNorm.bias\"{...}) {axis=-1, epsilon=9.999999960041972e-13, stash_type=1}\n",
       "              8 |  # node_Unsqueeze_72\n",
       "                   %\"unsqueeze_1\"<INT64,[1,1,1,s41]> ⬅️ ::Unsqueeze(%\"attention_mask\", %\"val_927\"{[1, 2]})\n",
       "              9 |  # node_Concat_32\n",
       "                   %\"val_34\"<INT64,[4]> ⬅️ ::Concat(%\"val_11\"{[1]}, %\"val_11\"{[1]}, %\"val_0\", %\"val_0\") {axis=0}\n",
       "             10 |  # node_expand\n",
       "                   %\"expand\"<INT64,[1,1,s41,s41]> ⬅️ ::Expand(%\"unsqueeze_1\", %\"val_34\")\n",
       "             11 |  # node__to_copy\n",
       "                   %\"_to_copy\"<FLOAT,[1,1,s41,s41]> ⬅️ ::Cast(%\"expand\") {to=1}\n",
       "             12 |  # node_sub_17\n",
       "                   %\"sub_17\"<FLOAT,[1,1,s41,s41]> ⬅️ ::Sub(%\"clone_1\"{1.0}, %\"_to_copy\")\n",
       "             13 |  # node__to_copy_1\n",
       "                   %\"_to_copy_1\"<BOOL,[1,1,s41,s41]> ⬅️ ::Cast(%\"sub_17\") {to=9}\n",
       "             14 |  # node_masked_fill\n",
       "                   %\"masked_fill\"<FLOAT,[1,1,s41,s41]> ⬅️ ::Where(%\"_to_copy_1\", %\"val_36\"{-3.4028234663852886e+38}, %\"sub_17\")\n",
       "             15 |  # node_MatMul_36\n",
       "                   %\"val_38\"<FLOAT,[1,s41,768]> ⬅️ ::MatMul(%\"layer_norm\", %\"val_37\"{...})\n",
       "             16 |  # node_linear\n",
       "                   %\"linear\"<FLOAT,[1,s41,768]> ⬅️ ::Add(%\"val_38\", %\"bert.encoder.layer.0.attention.self.query.bias\"{...})\n",
       "             17 |  # node_view\n",
       "                   %\"view\"<FLOAT,[1,s41,12,64]> ⬅️ ::Reshape(%\"linear\", %\"val_44\"{[1, -1, 12, 64]}) {allowzero=1}\n",
       "             18 |  # node_transpose\n",
       "                   %\"transpose\"<FLOAT,[1,12,s41,64]> ⬅️ ::Transpose(%\"view\") {perm=(0, 2, 1, 3)}\n",
       "             19 |  # node_MatMul_44\n",
       "                   %\"val_46\"<FLOAT,[1,s41,768]> ⬅️ ::MatMul(%\"layer_norm\", %\"val_45\"{...})\n",
       "             20 |  # node_linear_1\n",
       "                   %\"linear_1\"<FLOAT,[1,s41,768]> ⬅️ ::Add(%\"val_46\", %\"bert.encoder.layer.0.attention.self.key.bias\"{...})\n",
       "             21 |  # node_view_1\n",
       "                   %\"view_1\"<FLOAT,[1,s41,12,64]> ⬅️ ::Reshape(%\"linear_1\", %\"val_44\"{[1, -1, 12, 64]}) {allowzero=1}\n",
       "             22 |  # node_transpose_1\n",
       "                   %\"transpose_1\"<FLOAT,[1,12,s41,64]> ⬅️ ::Transpose(%\"view_1\") {perm=(0, 2, 1, 3)}\n",
       "             23 |  # node_MatMul_52\n",
       "                   %\"val_54\"<FLOAT,[1,s41,768]> ⬅️ ::MatMul(%\"layer_norm\", %\"val_53\"{...})\n",
       "             24 |  # node_linear_2\n",
       "                   %\"linear_2\"<FLOAT,[1,s41,768]> ⬅️ ::Add(%\"val_54\", %\"bert.encoder.layer.0.attention.self.value.bias\"{...})\n",
       "             25 |  # node_view_2\n",
       "                   %\"view_2\"<FLOAT,[1,s41,12,64]> ⬅️ ::Reshape(%\"linear_2\", %\"val_44\"{[1, -1, 12, 64]}) {allowzero=1}\n",
       "             26 |  # node_transpose_2\n",
       "                   %\"transpose_2\"<FLOAT,[1,12,s41,64]> ⬅️ ::Transpose(%\"view_2\") {perm=(0, 2, 1, 3)}\n",
       "             27 |  # node_Shape_68\n",
       "                   %\"val_70\"<INT64,[4]> ⬅️ ::Shape(%\"transpose_1\") {start=0}\n",
       "             28 |  # node_Slice_71\n",
       "                   %\"val_73\"<INT64,[1]> ⬅️ ::Slice(%\"val_70\", %\"val_72\"{[-1]}, %\"val_71\"{[9223372036854775807]})\n",
       "             29 |  # node_Slice_73\n",
       "                   %\"val_75\"<INT64,[1]> ⬅️ ::Slice(%\"val_70\", %\"val_74\"{[-2]}, %\"val_72\"{[-1]})\n",
       "             30 |  # node_Slice_75\n",
       "                   %\"val_77\"<INT64,[2]> ⬅️ ::Slice(%\"val_70\", %\"val_76\"{[-9223372036854775808]}, %\"val_74\"{[-2]})\n",
       "             31 |  # node_Concat_77\n",
       "                   %\"val_79\"<INT64,[3]> ⬅️ ::Concat(%\"val_72\"{[-1]}, %\"val_75\", %\"val_73\") {axis=0}\n",
       "             32 |  # node_Reshape_78\n",
       "                   %\"val_80\"<FLOAT,[unk__22,unk__23,unk__24]> ⬅️ ::Reshape(%\"transpose_1\", %\"val_79\") {allowzero=0}\n",
       "             33 |  # node_Transpose_79\n",
       "                   %\"val_81\"<FLOAT,[unk__22,unk__24,unk__23]> ⬅️ ::Transpose(%\"val_80\") {perm=(0, 2, 1)}\n",
       "             34 |  # node_Concat_80\n",
       "                   %\"val_82\"<INT64,[4]> ⬅️ ::Concat(%\"val_77\", %\"val_73\", %\"val_75\") {axis=0}\n",
       "             35 |  # node_Reshape_81\n",
       "                   %\"val_83\"<FLOAT,[unk__25,unk__26,unk__27,unk__28]> ⬅️ ::Reshape(%\"val_81\", %\"val_82\") {allowzero=0}\n",
       "             36 |  # node_Mul_83\n",
       "                   %\"val_85\"<FLOAT,[1,12,s41,64]> ⬅️ ::Mul(%\"transpose\", %\"val_84\"{[0.3535533845424652]})\n",
       "             37 |  # node_Mul_85\n",
       "                   %\"val_87\"<FLOAT,[unk__25,unk__26,unk__27,unk__28]> ⬅️ ::Mul(%\"val_83\", %\"val_84\"{[0.3535533845424652]})\n",
       "             38 |  # node_MatMul_86\n",
       "                   %\"val_88\"<FLOAT,[unk__25,12,s41,unk__28]> ⬅️ ::MatMul(%\"val_85\", %\"val_87\")\n",
       "             39 |  # node_Add_87\n",
       "                   %\"val_89\"<FLOAT,[unk__25,12,s41,unk__29]> ⬅️ ::Add(%\"val_88\", %\"masked_fill\")\n",
       "             40 |  # node_Softmax_88\n",
       "                   %\"val_90\"<FLOAT,[unk__25,12,s41,unk__29]> ⬅️ ::Softmax(%\"val_89\") {axis=-1}\n",
       "             41 |  # node_scaled_dot_product_attention\n",
       "                   %\"scaled_dot_product_attention\"<FLOAT,[1,12,s41,64]> ⬅️ ::MatMul(%\"val_90\", %\"transpose_2\")\n",
       "             42 |  # node_transpose_3\n",
       "                   %\"transpose_3\"<FLOAT,[1,s41,12,64]> ⬅️ ::Transpose(%\"scaled_dot_product_attention\") {perm=(0, 2, 1, 3)}\n",
       "             43 |  # node_Concat_93\n",
       "                   %\"val_95\"<INT64,[3]> ⬅️ ::Concat(%\"val_11\"{[1]}, %\"val_0\", %\"val_94\"{[768]}) {axis=0}\n",
       "             44 |  # node_view_3\n",
       "                   %\"view_3\"<FLOAT,[1,s41,768]> ⬅️ ::Reshape(%\"transpose_3\", %\"val_95\") {allowzero=1}\n",
       "             45 |  # node_MatMul_95\n",
       "                   %\"val_97\"<FLOAT,[1,s41,768]> ⬅️ ::MatMul(%\"view_3\", %\"val_96\"{...})\n",
       "             46 |  # node_linear_3\n",
       "                   %\"linear_3\"<FLOAT,[1,s41,768]> ⬅️ ::Add(%\"val_97\", %\"bert.encoder.layer.0.attention.output.dense.bias\"{...})\n",
       "             47 |  # node_add_97\n",
       "                   %\"add_97\"<FLOAT,[1,s41,768]> ⬅️ ::Add(%\"linear_3\", %\"layer_norm\")\n",
       "             48 |  # node_layer_norm_1\n",
       "                   %\"layer_norm_1\"<FLOAT,[1,s41,768]>, %\"\"<FLOAT,[1,s41,1]>, %\"\"<FLOAT,[1,s41,1]> ⬅️ ::LayerNormalization(%\"add_97\", %\"bert.encoder.layer.0.attention.output.LayerNorm.weight\"{...}, %\"bert.encoder.layer.0.attention.output.LayerNorm.bias\"{...}) {axis=-1, epsilon=9.999999960041972e-13, stash_type=1}\n",
       "             49 |  # node_MatMul_97\n",
       "                   %\"val_101\"<FLOAT,[1,s41,3072]> ⬅️ ::MatMul(%\"layer_norm_1\", %\"val_100\"{...})\n",
       "             50 |  # node_linear_4\n",
       "                   %\"linear_4\"<FLOAT,[1,s41,3072]> ⬅️ ::Add(%\"val_101\", %\"bert.encoder.layer.0.intermediate.dense.bias\"{...})\n",
       "             51 |  # node_Div_99\n",
       "                   %\"val_103\"<FLOAT,[1,s41,3072]> ⬅️ ::Div(%\"linear_4\", %\"val_102\"{1.4142135381698608})\n",
       "             52 |  # node_Erf_100\n",
       "                   %\"val_104\"<FLOAT,[1,s41,3072]> ⬅️ ::Erf(%\"val_103\")\n",
       "             53 |  # node_Add_102\n",
       "                   %\"val_106\"<FLOAT,[1,s41,3072]> ⬅️ ::Add(%\"val_104\", %\"clone_1\"{1.0})\n",
       "             54 |  # node_Mul_104\n",
       "                   %\"val_108\"<FLOAT,[1,s41,3072]> ⬅️ ::Mul(%\"val_107\"{0.5}, %\"val_106\")\n",
       "             55 |  # node_gelu\n",
       "                   %\"gelu\"<FLOAT,[1,s41,3072]> ⬅️ ::Mul(%\"linear_4\", %\"val_108\")\n",
       "             56 |  # node_MatMul_106\n",
       "                   %\"val_110\"<FLOAT,[1,s41,768]> ⬅️ ::MatMul(%\"gelu\", %\"val_109\"{...})\n",
       "             57 |  # node_linear_5\n",
       "                   %\"linear_5\"<FLOAT,[1,s41,768]> ⬅️ ::Add(%\"val_110\", %\"bert.encoder.layer.0.output.dense.bias\"{...})\n",
       "             58 |  # node_add_116\n",
       "                   %\"add_116\"<FLOAT,[1,s41,768]> ⬅️ ::Add(%\"linear_5\", %\"layer_norm_1\")\n",
       "             59 |  # node_layer_norm_2\n",
       "                   %\"layer_norm_2\"<FLOAT,[1,s41,768]>, %\"\"<FLOAT,[1,s41,1]>, %\"\"<FLOAT,[1,s41,1]> ⬅️ ::LayerNormalization(%\"add_116\", %\"bert.encoder.layer.0.output.LayerNorm.weight\"{...}, %\"bert.encoder.layer.0.output.LayerNorm.bias\"{...}) {axis=-1, epsilon=9.999999960041972e-13, stash_type=1}\n",
       "             60 |  # node_MatMul_108\n",
       "                   %\"val_114\"<FLOAT,[1,s41,768]> ⬅️ ::MatMul(%\"layer_norm_2\", %\"val_113\"{...})\n",
       "             61 |  # node_linear_6\n",
       "                   %\"linear_6\"<FLOAT,[1,s41,768]> ⬅️ ::Add(%\"val_114\", %\"bert.encoder.layer.1.attention.self.query.bias\"{...})\n",
       "             62 |  # node_view_4\n",
       "                   %\"view_4\"<FLOAT,[1,s41,12,64]> ⬅️ ::Reshape(%\"linear_6\", %\"val_44\"{[1, -1, 12, 64]}) {allowzero=1}\n",
       "             63 |  # node_transpose_4\n",
       "                   %\"transpose_4\"<FLOAT,[1,12,s41,64]> ⬅️ ::Transpose(%\"view_4\") {perm=(0, 2, 1, 3)}\n",
       "             64 |  # node_MatMul_116\n",
       "                   %\"val_122\"<FLOAT,[1,s41,768]> ⬅️ ::MatMul(%\"layer_norm_2\", %\"val_121\"{...})\n",
       "             65 |  # node_linear_7\n",
       "                   %\"linear_7\"<FLOAT,[1,s41,768]> ⬅️ ::Add(%\"val_122\", %\"bert.encoder.layer.1.attention.self.key.bias\"{...})\n",
       "             66 |  # node_view_5\n",
       "                   %\"view_5\"<FLOAT,[1,s41,12,64]> ⬅️ ::Reshape(%\"linear_7\", %\"val_44\"{[1, -1, 12, 64]}) {allowzero=1}\n",
       "             67 |  # node_transpose_5\n",
       "                   %\"transpose_5\"<FLOAT,[1,12,s41,64]> ⬅️ ::Transpose(%\"view_5\") {perm=(0, 2, 1, 3)}\n",
       "             68 |  # node_MatMul_124\n",
       "                   %\"val_130\"<FLOAT,[1,s41,768]> ⬅️ ::MatMul(%\"layer_norm_2\", %\"val_129\"{...})\n",
       "             69 |  # node_linear_8\n",
       "                   %\"linear_8\"<FLOAT,[1,s41,768]> ⬅️ ::Add(%\"val_130\", %\"bert.encoder.layer.1.attention.self.value.bias\"{...})\n",
       "             70 |  # node_view_6\n",
       "                   %\"view_6\"<FLOAT,[1,s41,12,64]> ⬅️ ::Reshape(%\"linear_8\", %\"val_44\"{[1, -1, 12, 64]}) {allowzero=1}\n",
       "             71 |  # node_transpose_6\n",
       "                   %\"transpose_6\"<FLOAT,[1,12,s41,64]> ⬅️ ::Transpose(%\"view_6\") {perm=(0, 2, 1, 3)}\n",
       "             72 |  # node_Shape_140\n",
       "                   %\"val_146\"<INT64,[4]> ⬅️ ::Shape(%\"transpose_5\") {start=0}\n",
       "             73 |  # node_Slice_142\n",
       "                   %\"val_148\"<INT64,[1]> ⬅️ ::Slice(%\"val_146\", %\"val_72\"{[-1]}, %\"val_71\"{[9223372036854775807]})\n",
       "             74 |  # node_Slice_143\n",
       "                   %\"val_149\"<INT64,[1]> ⬅️ ::Slice(%\"val_146\", %\"val_74\"{[-2]}, %\"val_72\"{[-1]})\n",
       "             75 |  # node_Slice_145\n",
       "                   %\"val_151\"<INT64,[2]> ⬅️ ::Slice(%\"val_146\", %\"val_76\"{[-9223372036854775808]}, %\"val_74\"{[-2]})\n",
       "             76 |  # node_Concat_147\n",
       "                   %\"val_153\"<INT64,[3]> ⬅️ ::Concat(%\"val_72\"{[-1]}, %\"val_149\", %\"val_148\") {axis=0}\n",
       "             77 |  # node_Reshape_148\n",
       "                   %\"val_154\"<FLOAT,[unk__45,unk__46,unk__47]> ⬅️ ::Reshape(%\"transpose_5\", %\"val_153\") {allowzero=0}\n",
       "             78 |  # node_Transpose_149\n",
       "                   %\"val_155\"<FLOAT,[unk__45,unk__47,unk__46]> ⬅️ ::Transpose(%\"val_154\") {perm=(0, 2, 1)}\n",
       "             79 |  # node_Concat_150\n",
       "                   %\"val_156\"<INT64,[4]> ⬅️ ::Concat(%\"val_151\", %\"val_148\", %\"val_149\") {axis=0}\n",
       "             80 |  # node_Reshape_151\n",
       "                   %\"val_157\"<FLOAT,[unk__48,unk__49,unk__50,unk__51]> ⬅️ ::Reshape(%\"val_155\", %\"val_156\") {allowzero=0}\n",
       "             81 |  # node_Mul_153\n",
       "                   %\"val_159\"<FLOAT,[1,12,s41,64]> ⬅️ ::Mul(%\"transpose_4\", %\"val_84\"{[0.3535533845424652]})\n",
       "             82 |  # node_Mul_155\n",
       "                   %\"val_161\"<FLOAT,[unk__48,unk__49,unk__50,unk__51]> ⬅️ ::Mul(%\"val_157\", %\"val_84\"{[0.3535533845424652]})\n",
       "             83 |  # node_MatMul_156\n",
       "                   %\"val_162\"<FLOAT,[unk__48,12,s41,unk__51]> ⬅️ ::MatMul(%\"val_159\", %\"val_161\")\n",
       "             84 |  # node_Add_157\n",
       "                   %\"val_163\"<FLOAT,[unk__48,12,s41,unk__52]> ⬅️ ::Add(%\"val_162\", %\"masked_fill\")\n",
       "             85 |  # node_Softmax_158\n",
       "                   %\"val_164\"<FLOAT,[unk__48,12,s41,unk__52]> ⬅️ ::Softmax(%\"val_163\") {axis=-1}\n",
       "             86 |  # node_scaled_dot_product_attention_1\n",
       "                   %\"scaled_dot_product_attention_1\"<FLOAT,[1,12,s41,64]> ⬅️ ::MatMul(%\"val_164\", %\"transpose_6\")\n",
       "             87 |  # node_transpose_7\n",
       "                   %\"transpose_7\"<FLOAT,[1,s41,12,64]> ⬅️ ::Transpose(%\"scaled_dot_product_attention_1\") {perm=(0, 2, 1, 3)}\n",
       "             88 |  # node_view_7\n",
       "                   %\"view_7\"<FLOAT,[1,s41,768]> ⬅️ ::Reshape(%\"transpose_7\", %\"val_95\") {allowzero=1}\n",
       "             89 |  # node_MatMul_165\n",
       "                   %\"val_171\"<FLOAT,[1,s41,768]> ⬅️ ::MatMul(%\"view_7\", %\"val_170\"{...})\n",
       "             90 |  # node_linear_9\n",
       "                   %\"linear_9\"<FLOAT,[1,s41,768]> ⬅️ ::Add(%\"val_171\", %\"bert.encoder.layer.1.attention.output.dense.bias\"{...})\n",
       "             91 |  # node_add_169\n",
       "                   %\"add_169\"<FLOAT,[1,s41,768]> ⬅️ ::Add(%\"linear_9\", %\"layer_norm_2\")\n",
       "             92 |  # node_layer_norm_3\n",
       "                   %\"layer_norm_3\"<FLOAT,[1,s41,768]>, %\"\"<FLOAT,[1,s41,1]>, %\"\"<FLOAT,[1,s41,1]> ⬅️ ::LayerNormalization(%\"add_169\", %\"bert.encoder.layer.1.attention.output.LayerNorm.weight\"{...}, %\"bert.encoder.layer.1.attention.output.LayerNorm.bias\"{...}) {axis=-1, epsilon=9.999999960041972e-13, stash_type=1}\n",
       "             93 |  # node_MatMul_167\n",
       "                   %\"val_175\"<FLOAT,[1,s41,3072]> ⬅️ ::MatMul(%\"layer_norm_3\", %\"val_174\"{...})\n",
       "             94 |  # node_linear_10\n",
       "                   %\"linear_10\"<FLOAT,[1,s41,3072]> ⬅️ ::Add(%\"val_175\", %\"bert.encoder.layer.1.intermediate.dense.bias\"{...})\n",
       "             95 |  # node_Div_169\n",
       "                   %\"val_177\"<FLOAT,[1,s41,3072]> ⬅️ ::Div(%\"linear_10\", %\"val_102\"{1.4142135381698608})\n",
       "             96 |  # node_Erf_170\n",
       "                   %\"val_178\"<FLOAT,[1,s41,3072]> ⬅️ ::Erf(%\"val_177\")\n",
       "             97 |  # node_Add_172\n",
       "                   %\"val_180\"<FLOAT,[1,s41,3072]> ⬅️ ::Add(%\"val_178\", %\"clone_1\"{1.0})\n",
       "             98 |  # node_Mul_174\n",
       "                   %\"val_182\"<FLOAT,[1,s41,3072]> ⬅️ ::Mul(%\"val_107\"{0.5}, %\"val_180\")\n",
       "             99 |  # node_gelu_1\n",
       "                   %\"gelu_1\"<FLOAT,[1,s41,3072]> ⬅️ ::Mul(%\"linear_10\", %\"val_182\")\n",
       "            100 |  # node_MatMul_176\n",
       "                   %\"val_184\"<FLOAT,[1,s41,768]> ⬅️ ::MatMul(%\"gelu_1\", %\"val_183\"{...})\n",
       "            101 |  # node_linear_11\n",
       "                   %\"linear_11\"<FLOAT,[1,s41,768]> ⬅️ ::Add(%\"val_184\", %\"bert.encoder.layer.1.output.dense.bias\"{...})\n",
       "            102 |  # node_add_188\n",
       "                   %\"add_188\"<FLOAT,[1,s41,768]> ⬅️ ::Add(%\"linear_11\", %\"layer_norm_3\")\n",
       "            103 |  # node_layer_norm_4\n",
       "                   %\"layer_norm_4\"<FLOAT,[1,s41,768]>, %\"\"<FLOAT,[1,s41,1]>, %\"\"<FLOAT,[1,s41,1]> ⬅️ ::LayerNormalization(%\"add_188\", %\"bert.encoder.layer.1.output.LayerNorm.weight\"{...}, %\"bert.encoder.layer.1.output.LayerNorm.bias\"{...}) {axis=-1, epsilon=9.999999960041972e-13, stash_type=1}\n",
       "            104 |  # node_MatMul_178\n",
       "                   %\"val_188\"<FLOAT,[1,s41,768]> ⬅️ ::MatMul(%\"layer_norm_4\", %\"val_187\"{...})\n",
       "            105 |  # node_linear_12\n",
       "                   %\"linear_12\"<FLOAT,[1,s41,768]> ⬅️ ::Add(%\"val_188\", %\"bert.encoder.layer.2.attention.self.query.bias\"{...})\n",
       "            106 |  # node_view_8\n",
       "                   %\"view_8\"<FLOAT,[1,s41,12,64]> ⬅️ ::Reshape(%\"linear_12\", %\"val_44\"{[1, -1, 12, 64]}) {allowzero=1}\n",
       "            107 |  # node_transpose_8\n",
       "                   %\"transpose_8\"<FLOAT,[1,12,s41,64]> ⬅️ ::Transpose(%\"view_8\") {perm=(0, 2, 1, 3)}\n",
       "            108 |  # node_MatMul_186\n",
       "                   %\"val_196\"<FLOAT,[1,s41,768]> ⬅️ ::MatMul(%\"layer_norm_4\", %\"val_195\"{...})\n",
       "            109 |  # node_linear_13\n",
       "                   %\"linear_13\"<FLOAT,[1,s41,768]> ⬅️ ::Add(%\"val_196\", %\"bert.encoder.layer.2.attention.self.key.bias\"{...})\n",
       "            110 |  # node_view_9\n",
       "                   %\"view_9\"<FLOAT,[1,s41,12,64]> ⬅️ ::Reshape(%\"linear_13\", %\"val_44\"{[1, -1, 12, 64]}) {allowzero=1}\n",
       "            111 |  # node_transpose_9\n",
       "                   %\"transpose_9\"<FLOAT,[1,12,s41,64]> ⬅️ ::Transpose(%\"view_9\") {perm=(0, 2, 1, 3)}\n",
       "            112 |  # node_MatMul_194\n",
       "                   %\"val_204\"<FLOAT,[1,s41,768]> ⬅️ ::MatMul(%\"layer_norm_4\", %\"val_203\"{...})\n",
       "            113 |  # node_linear_14\n",
       "                   %\"linear_14\"<FLOAT,[1,s41,768]> ⬅️ ::Add(%\"val_204\", %\"bert.encoder.layer.2.attention.self.value.bias\"{...})\n",
       "            114 |  # node_view_10\n",
       "                   %\"view_10\"<FLOAT,[1,s41,12,64]> ⬅️ ::Reshape(%\"linear_14\", %\"val_44\"{[1, -1, 12, 64]}) {allowzero=1}\n",
       "            115 |  # node_transpose_10\n",
       "                   %\"transpose_10\"<FLOAT,[1,12,s41,64]> ⬅️ ::Transpose(%\"view_10\") {perm=(0, 2, 1, 3)}\n",
       "            116 |  # node_Shape_210\n",
       "                   %\"val_220\"<INT64,[4]> ⬅️ ::Shape(%\"transpose_9\") {start=0}\n",
       "            117 |  # node_Slice_212\n",
       "                   %\"val_222\"<INT64,[1]> ⬅️ ::Slice(%\"val_220\", %\"val_72\"{[-1]}, %\"val_71\"{[9223372036854775807]})\n",
       "            118 |  # node_Slice_213\n",
       "                   %\"val_223\"<INT64,[1]> ⬅️ ::Slice(%\"val_220\", %\"val_74\"{[-2]}, %\"val_72\"{[-1]})\n",
       "            119 |  # node_Slice_215\n",
       "                   %\"val_225\"<INT64,[2]> ⬅️ ::Slice(%\"val_220\", %\"val_76\"{[-9223372036854775808]}, %\"val_74\"{[-2]})\n",
       "            120 |  # node_Concat_217\n",
       "                   %\"val_227\"<INT64,[3]> ⬅️ ::Concat(%\"val_72\"{[-1]}, %\"val_223\", %\"val_222\") {axis=0}\n",
       "            121 |  # node_Reshape_218\n",
       "                   %\"val_228\"<FLOAT,[unk__68,unk__69,unk__70]> ⬅️ ::Reshape(%\"transpose_9\", %\"val_227\") {allowzero=0}\n",
       "            122 |  # node_Transpose_219\n",
       "                   %\"val_229\"<FLOAT,[unk__68,unk__70,unk__69]> ⬅️ ::Transpose(%\"val_228\") {perm=(0, 2, 1)}\n",
       "            123 |  # node_Concat_220\n",
       "                   %\"val_230\"<INT64,[4]> ⬅️ ::Concat(%\"val_225\", %\"val_222\", %\"val_223\") {axis=0}\n",
       "            124 |  # node_Reshape_221\n",
       "                   %\"val_231\"<FLOAT,[unk__71,unk__72,unk__73,unk__74]> ⬅️ ::Reshape(%\"val_229\", %\"val_230\") {allowzero=0}\n",
       "            125 |  # node_Mul_223\n",
       "                   %\"val_233\"<FLOAT,[1,12,s41,64]> ⬅️ ::Mul(%\"transpose_8\", %\"val_84\"{[0.3535533845424652]})\n",
       "            126 |  # node_Mul_225\n",
       "                   %\"val_235\"<FLOAT,[unk__71,unk__72,unk__73,unk__74]> ⬅️ ::Mul(%\"val_231\", %\"val_84\"{[0.3535533845424652]})\n",
       "            127 |  # node_MatMul_226\n",
       "                   %\"val_236\"<FLOAT,[unk__71,12,s41,unk__74]> ⬅️ ::MatMul(%\"val_233\", %\"val_235\")\n",
       "            128 |  # node_Add_227\n",
       "                   %\"val_237\"<FLOAT,[unk__71,12,s41,unk__75]> ⬅️ ::Add(%\"val_236\", %\"masked_fill\")\n",
       "            129 |  # node_Softmax_228\n",
       "                   %\"val_238\"<FLOAT,[unk__71,12,s41,unk__75]> ⬅️ ::Softmax(%\"val_237\") {axis=-1}\n",
       "            130 |  # node_scaled_dot_product_attention_2\n",
       "                   %\"scaled_dot_product_attention_2\"<FLOAT,[1,12,s41,64]> ⬅️ ::MatMul(%\"val_238\", %\"transpose_10\")\n",
       "            131 |  # node_transpose_11\n",
       "                   %\"transpose_11\"<FLOAT,[1,s41,12,64]> ⬅️ ::Transpose(%\"scaled_dot_product_attention_2\") {perm=(0, 2, 1, 3)}\n",
       "            132 |  # node_view_11\n",
       "                   %\"view_11\"<FLOAT,[1,s41,768]> ⬅️ ::Reshape(%\"transpose_11\", %\"val_95\") {allowzero=1}\n",
       "            133 |  # node_MatMul_235\n",
       "                   %\"val_245\"<FLOAT,[1,s41,768]> ⬅️ ::MatMul(%\"view_11\", %\"val_244\"{...})\n",
       "            134 |  # node_linear_15\n",
       "                   %\"linear_15\"<FLOAT,[1,s41,768]> ⬅️ ::Add(%\"val_245\", %\"bert.encoder.layer.2.attention.output.dense.bias\"{...})\n",
       "            135 |  # node_add_241\n",
       "                   %\"add_241\"<FLOAT,[1,s41,768]> ⬅️ ::Add(%\"linear_15\", %\"layer_norm_4\")\n",
       "            136 |  # node_layer_norm_5\n",
       "                   %\"layer_norm_5\"<FLOAT,[1,s41,768]>, %\"\"<FLOAT,[1,s41,1]>, %\"\"<FLOAT,[1,s41,1]> ⬅️ ::LayerNormalization(%\"add_241\", %\"bert.encoder.layer.2.attention.output.LayerNorm.weight\"{...}, %\"bert.encoder.layer.2.attention.output.LayerNorm.bias\"{...}) {axis=-1, epsilon=9.999999960041972e-13, stash_type=1}\n",
       "            137 |  # node_MatMul_237\n",
       "                   %\"val_249\"<FLOAT,[1,s41,3072]> ⬅️ ::MatMul(%\"layer_norm_5\", %\"val_248\"{...})\n",
       "            138 |  # node_linear_16\n",
       "                   %\"linear_16\"<FLOAT,[1,s41,3072]> ⬅️ ::Add(%\"val_249\", %\"bert.encoder.layer.2.intermediate.dense.bias\"{...})\n",
       "            139 |  # node_Div_239\n",
       "                   %\"val_251\"<FLOAT,[1,s41,3072]> ⬅️ ::Div(%\"linear_16\", %\"val_102\"{1.4142135381698608})\n",
       "            140 |  # node_Erf_240\n",
       "                   %\"val_252\"<FLOAT,[1,s41,3072]> ⬅️ ::Erf(%\"val_251\")\n",
       "            141 |  # node_Add_242\n",
       "                   %\"val_254\"<FLOAT,[1,s41,3072]> ⬅️ ::Add(%\"val_252\", %\"clone_1\"{1.0})\n",
       "            142 |  # node_Mul_244\n",
       "                   %\"val_256\"<FLOAT,[1,s41,3072]> ⬅️ ::Mul(%\"val_107\"{0.5}, %\"val_254\")\n",
       "            143 |  # node_gelu_2\n",
       "                   %\"gelu_2\"<FLOAT,[1,s41,3072]> ⬅️ ::Mul(%\"linear_16\", %\"val_256\")\n",
       "            144 |  # node_MatMul_246\n",
       "                   %\"val_258\"<FLOAT,[1,s41,768]> ⬅️ ::MatMul(%\"gelu_2\", %\"val_257\"{...})\n",
       "            145 |  # node_linear_17\n",
       "                   %\"linear_17\"<FLOAT,[1,s41,768]> ⬅️ ::Add(%\"val_258\", %\"bert.encoder.layer.2.output.dense.bias\"{...})\n",
       "            146 |  # node_add_260\n",
       "                   %\"add_260\"<FLOAT,[1,s41,768]> ⬅️ ::Add(%\"linear_17\", %\"layer_norm_5\")\n",
       "            147 |  # node_layer_norm_6\n",
       "                   %\"layer_norm_6\"<FLOAT,[1,s41,768]>, %\"\"<FLOAT,[1,s41,1]>, %\"\"<FLOAT,[1,s41,1]> ⬅️ ::LayerNormalization(%\"add_260\", %\"bert.encoder.layer.2.output.LayerNorm.weight\"{...}, %\"bert.encoder.layer.2.output.LayerNorm.bias\"{...}) {axis=-1, epsilon=9.999999960041972e-13, stash_type=1}\n",
       "            148 |  # node_MatMul_248\n",
       "                   %\"val_262\"<FLOAT,[1,s41,768]> ⬅️ ::MatMul(%\"layer_norm_6\", %\"val_261\"{...})\n",
       "            149 |  # node_linear_18\n",
       "                   %\"linear_18\"<FLOAT,[1,s41,768]> ⬅️ ::Add(%\"val_262\", %\"bert.encoder.layer.3.attention.self.query.bias\"{...})\n",
       "            150 |  # node_view_12\n",
       "                   %\"view_12\"<FLOAT,[1,s41,12,64]> ⬅️ ::Reshape(%\"linear_18\", %\"val_44\"{[1, -1, 12, 64]}) {allowzero=1}\n",
       "            151 |  # node_transpose_12\n",
       "                   %\"transpose_12\"<FLOAT,[1,12,s41,64]> ⬅️ ::Transpose(%\"view_12\") {perm=(0, 2, 1, 3)}\n",
       "            152 |  # node_MatMul_256\n",
       "                   %\"val_270\"<FLOAT,[1,s41,768]> ⬅️ ::MatMul(%\"layer_norm_6\", %\"val_269\"{...})\n",
       "            153 |  # node_linear_19\n",
       "                   %\"linear_19\"<FLOAT,[1,s41,768]> ⬅️ ::Add(%\"val_270\", %\"bert.encoder.layer.3.attention.self.key.bias\"{...})\n",
       "            154 |  # node_view_13\n",
       "                   %\"view_13\"<FLOAT,[1,s41,12,64]> ⬅️ ::Reshape(%\"linear_19\", %\"val_44\"{[1, -1, 12, 64]}) {allowzero=1}\n",
       "            155 |  # node_transpose_13\n",
       "                   %\"transpose_13\"<FLOAT,[1,12,s41,64]> ⬅️ ::Transpose(%\"view_13\") {perm=(0, 2, 1, 3)}\n",
       "            156 |  # node_MatMul_264\n",
       "                   %\"val_278\"<FLOAT,[1,s41,768]> ⬅️ ::MatMul(%\"layer_norm_6\", %\"val_277\"{...})\n",
       "            157 |  # node_linear_20\n",
       "                   %\"linear_20\"<FLOAT,[1,s41,768]> ⬅️ ::Add(%\"val_278\", %\"bert.encoder.layer.3.attention.self.value.bias\"{...})\n",
       "            158 |  # node_view_14\n",
       "                   %\"view_14\"<FLOAT,[1,s41,12,64]> ⬅️ ::Reshape(%\"linear_20\", %\"val_44\"{[1, -1, 12, 64]}) {allowzero=1}\n",
       "            159 |  # node_transpose_14\n",
       "                   %\"transpose_14\"<FLOAT,[1,12,s41,64]> ⬅️ ::Transpose(%\"view_14\") {perm=(0, 2, 1, 3)}\n",
       "            160 |  # node_Shape_280\n",
       "                   %\"val_294\"<INT64,[4]> ⬅️ ::Shape(%\"transpose_13\") {start=0}\n",
       "            161 |  # node_Slice_282\n",
       "                   %\"val_296\"<INT64,[1]> ⬅️ ::Slice(%\"val_294\", %\"val_72\"{[-1]}, %\"val_71\"{[9223372036854775807]})\n",
       "            162 |  # node_Slice_283\n",
       "                   %\"val_297\"<INT64,[1]> ⬅️ ::Slice(%\"val_294\", %\"val_74\"{[-2]}, %\"val_72\"{[-1]})\n",
       "            163 |  # node_Slice_285\n",
       "                   %\"val_299\"<INT64,[2]> ⬅️ ::Slice(%\"val_294\", %\"val_76\"{[-9223372036854775808]}, %\"val_74\"{[-2]})\n",
       "            164 |  # node_Concat_287\n",
       "                   %\"val_301\"<INT64,[3]> ⬅️ ::Concat(%\"val_72\"{[-1]}, %\"val_297\", %\"val_296\") {axis=0}\n",
       "            165 |  # node_Reshape_288\n",
       "                   %\"val_302\"<FLOAT,[unk__91,unk__92,unk__93]> ⬅️ ::Reshape(%\"transpose_13\", %\"val_301\") {allowzero=0}\n",
       "            166 |  # node_Transpose_289\n",
       "                   %\"val_303\"<FLOAT,[unk__91,unk__93,unk__92]> ⬅️ ::Transpose(%\"val_302\") {perm=(0, 2, 1)}\n",
       "            167 |  # node_Concat_290\n",
       "                   %\"val_304\"<INT64,[4]> ⬅️ ::Concat(%\"val_299\", %\"val_296\", %\"val_297\") {axis=0}\n",
       "            168 |  # node_Reshape_291\n",
       "                   %\"val_305\"<FLOAT,[unk__94,unk__95,unk__96,unk__97]> ⬅️ ::Reshape(%\"val_303\", %\"val_304\") {allowzero=0}\n",
       "            169 |  # node_Mul_293\n",
       "                   %\"val_307\"<FLOAT,[1,12,s41,64]> ⬅️ ::Mul(%\"transpose_12\", %\"val_84\"{[0.3535533845424652]})\n",
       "            170 |  # node_Mul_295\n",
       "                   %\"val_309\"<FLOAT,[unk__94,unk__95,unk__96,unk__97]> ⬅️ ::Mul(%\"val_305\", %\"val_84\"{[0.3535533845424652]})\n",
       "            171 |  # node_MatMul_296\n",
       "                   %\"val_310\"<FLOAT,[unk__94,12,s41,unk__97]> ⬅️ ::MatMul(%\"val_307\", %\"val_309\")\n",
       "            172 |  # node_Add_297\n",
       "                   %\"val_311\"<FLOAT,[unk__94,12,s41,unk__98]> ⬅️ ::Add(%\"val_310\", %\"masked_fill\")\n",
       "            173 |  # node_Softmax_298\n",
       "                   %\"val_312\"<FLOAT,[unk__94,12,s41,unk__98]> ⬅️ ::Softmax(%\"val_311\") {axis=-1}\n",
       "            174 |  # node_scaled_dot_product_attention_3\n",
       "                   %\"scaled_dot_product_attention_3\"<FLOAT,[1,12,s41,64]> ⬅️ ::MatMul(%\"val_312\", %\"transpose_14\")\n",
       "            175 |  # node_transpose_15\n",
       "                   %\"transpose_15\"<FLOAT,[1,s41,12,64]> ⬅️ ::Transpose(%\"scaled_dot_product_attention_3\") {perm=(0, 2, 1, 3)}\n",
       "            176 |  # node_view_15\n",
       "                   %\"view_15\"<FLOAT,[1,s41,768]> ⬅️ ::Reshape(%\"transpose_15\", %\"val_95\") {allowzero=1}\n",
       "            177 |  # node_MatMul_305\n",
       "                   %\"val_319\"<FLOAT,[1,s41,768]> ⬅️ ::MatMul(%\"view_15\", %\"val_318\"{...})\n",
       "            178 |  # node_linear_21\n",
       "                   %\"linear_21\"<FLOAT,[1,s41,768]> ⬅️ ::Add(%\"val_319\", %\"bert.encoder.layer.3.attention.output.dense.bias\"{...})\n",
       "            179 |  # node_add_313\n",
       "                   %\"add_313\"<FLOAT,[1,s41,768]> ⬅️ ::Add(%\"linear_21\", %\"layer_norm_6\")\n",
       "            180 |  # node_layer_norm_7\n",
       "                   %\"layer_norm_7\"<FLOAT,[1,s41,768]>, %\"\"<FLOAT,[1,s41,1]>, %\"\"<FLOAT,[1,s41,1]> ⬅️ ::LayerNormalization(%\"add_313\", %\"bert.encoder.layer.3.attention.output.LayerNorm.weight\"{...}, %\"bert.encoder.layer.3.attention.output.LayerNorm.bias\"{...}) {axis=-1, epsilon=9.999999960041972e-13, stash_type=1}\n",
       "            181 |  # node_MatMul_307\n",
       "                   %\"val_323\"<FLOAT,[1,s41,3072]> ⬅️ ::MatMul(%\"layer_norm_7\", %\"val_322\"{...})\n",
       "            182 |  # node_linear_22\n",
       "                   %\"linear_22\"<FLOAT,[1,s41,3072]> ⬅️ ::Add(%\"val_323\", %\"bert.encoder.layer.3.intermediate.dense.bias\"{...})\n",
       "            183 |  # node_Div_309\n",
       "                   %\"val_325\"<FLOAT,[1,s41,3072]> ⬅️ ::Div(%\"linear_22\", %\"val_102\"{1.4142135381698608})\n",
       "            184 |  # node_Erf_310\n",
       "                   %\"val_326\"<FLOAT,[1,s41,3072]> ⬅️ ::Erf(%\"val_325\")\n",
       "            185 |  # node_Add_312\n",
       "                   %\"val_328\"<FLOAT,[1,s41,3072]> ⬅️ ::Add(%\"val_326\", %\"clone_1\"{1.0})\n",
       "            186 |  # node_Mul_314\n",
       "                   %\"val_330\"<FLOAT,[1,s41,3072]> ⬅️ ::Mul(%\"val_107\"{0.5}, %\"val_328\")\n",
       "            187 |  # node_gelu_3\n",
       "                   %\"gelu_3\"<FLOAT,[1,s41,3072]> ⬅️ ::Mul(%\"linear_22\", %\"val_330\")\n",
       "            188 |  # node_MatMul_316\n",
       "                   %\"val_332\"<FLOAT,[1,s41,768]> ⬅️ ::MatMul(%\"gelu_3\", %\"val_331\"{...})\n",
       "            189 |  # node_linear_23\n",
       "                   %\"linear_23\"<FLOAT,[1,s41,768]> ⬅️ ::Add(%\"val_332\", %\"bert.encoder.layer.3.output.dense.bias\"{...})\n",
       "            190 |  # node_add_332\n",
       "                   %\"add_332\"<FLOAT,[1,s41,768]> ⬅️ ::Add(%\"linear_23\", %\"layer_norm_7\")\n",
       "            191 |  # node_layer_norm_8\n",
       "                   %\"layer_norm_8\"<FLOAT,[1,s41,768]>, %\"\"<FLOAT,[1,s41,1]>, %\"\"<FLOAT,[1,s41,1]> ⬅️ ::LayerNormalization(%\"add_332\", %\"bert.encoder.layer.3.output.LayerNorm.weight\"{...}, %\"bert.encoder.layer.3.output.LayerNorm.bias\"{...}) {axis=-1, epsilon=9.999999960041972e-13, stash_type=1}\n",
       "            192 |  # node_MatMul_318\n",
       "                   %\"val_336\"<FLOAT,[1,s41,768]> ⬅️ ::MatMul(%\"layer_norm_8\", %\"val_335\"{...})\n",
       "            193 |  # node_linear_24\n",
       "                   %\"linear_24\"<FLOAT,[1,s41,768]> ⬅️ ::Add(%\"val_336\", %\"bert.encoder.layer.4.attention.self.query.bias\"{...})\n",
       "            194 |  # node_view_16\n",
       "                   %\"view_16\"<FLOAT,[1,s41,12,64]> ⬅️ ::Reshape(%\"linear_24\", %\"val_44\"{[1, -1, 12, 64]}) {allowzero=1}\n",
       "            195 |  # node_transpose_16\n",
       "                   %\"transpose_16\"<FLOAT,[1,12,s41,64]> ⬅️ ::Transpose(%\"view_16\") {perm=(0, 2, 1, 3)}\n",
       "            196 |  # node_MatMul_326\n",
       "                   %\"val_344\"<FLOAT,[1,s41,768]> ⬅️ ::MatMul(%\"layer_norm_8\", %\"val_343\"{...})\n",
       "            197 |  # node_linear_25\n",
       "                   %\"linear_25\"<FLOAT,[1,s41,768]> ⬅️ ::Add(%\"val_344\", %\"bert.encoder.layer.4.attention.self.key.bias\"{...})\n",
       "            198 |  # node_view_17\n",
       "                   %\"view_17\"<FLOAT,[1,s41,12,64]> ⬅️ ::Reshape(%\"linear_25\", %\"val_44\"{[1, -1, 12, 64]}) {allowzero=1}\n",
       "            199 |  # node_transpose_17\n",
       "                   %\"transpose_17\"<FLOAT,[1,12,s41,64]> ⬅️ ::Transpose(%\"view_17\") {perm=(0, 2, 1, 3)}\n",
       "            200 |  # node_MatMul_334\n",
       "                   %\"val_352\"<FLOAT,[1,s41,768]> ⬅️ ::MatMul(%\"layer_norm_8\", %\"val_351\"{...})\n",
       "            201 |  # node_linear_26\n",
       "                   %\"linear_26\"<FLOAT,[1,s41,768]> ⬅️ ::Add(%\"val_352\", %\"bert.encoder.layer.4.attention.self.value.bias\"{...})\n",
       "            202 |  # node_view_18\n",
       "                   %\"view_18\"<FLOAT,[1,s41,12,64]> ⬅️ ::Reshape(%\"linear_26\", %\"val_44\"{[1, -1, 12, 64]}) {allowzero=1}\n",
       "            203 |  # node_transpose_18\n",
       "                   %\"transpose_18\"<FLOAT,[1,12,s41,64]> ⬅️ ::Transpose(%\"view_18\") {perm=(0, 2, 1, 3)}\n",
       "            204 |  # node_Shape_350\n",
       "                   %\"val_368\"<INT64,[4]> ⬅️ ::Shape(%\"transpose_17\") {start=0}\n",
       "            205 |  # node_Slice_352\n",
       "                   %\"val_370\"<INT64,[1]> ⬅️ ::Slice(%\"val_368\", %\"val_72\"{[-1]}, %\"val_71\"{[9223372036854775807]})\n",
       "            206 |  # node_Slice_353\n",
       "                   %\"val_371\"<INT64,[1]> ⬅️ ::Slice(%\"val_368\", %\"val_74\"{[-2]}, %\"val_72\"{[-1]})\n",
       "            207 |  # node_Slice_355\n",
       "                   %\"val_373\"<INT64,[2]> ⬅️ ::Slice(%\"val_368\", %\"val_76\"{[-9223372036854775808]}, %\"val_74\"{[-2]})\n",
       "            208 |  # node_Concat_357\n",
       "                   %\"val_375\"<INT64,[3]> ⬅️ ::Concat(%\"val_72\"{[-1]}, %\"val_371\", %\"val_370\") {axis=0}\n",
       "            209 |  # node_Reshape_358\n",
       "                   %\"val_376\"<FLOAT,[unk__114,unk__115,unk__116]> ⬅️ ::Reshape(%\"transpose_17\", %\"val_375\") {allowzero=0}\n",
       "            210 |  # node_Transpose_359\n",
       "                   %\"val_377\"<FLOAT,[unk__114,unk__116,unk__115]> ⬅️ ::Transpose(%\"val_376\") {perm=(0, 2, 1)}\n",
       "            211 |  # node_Concat_360\n",
       "                   %\"val_378\"<INT64,[4]> ⬅️ ::Concat(%\"val_373\", %\"val_370\", %\"val_371\") {axis=0}\n",
       "            212 |  # node_Reshape_361\n",
       "                   %\"val_379\"<FLOAT,[unk__117,unk__118,unk__119,unk__120]> ⬅️ ::Reshape(%\"val_377\", %\"val_378\") {allowzero=0}\n",
       "            213 |  # node_Mul_363\n",
       "                   %\"val_381\"<FLOAT,[1,12,s41,64]> ⬅️ ::Mul(%\"transpose_16\", %\"val_84\"{[0.3535533845424652]})\n",
       "            214 |  # node_Mul_365\n",
       "                   %\"val_383\"<FLOAT,[unk__117,unk__118,unk__119,unk__120]> ⬅️ ::Mul(%\"val_379\", %\"val_84\"{[0.3535533845424652]})\n",
       "            215 |  # node_MatMul_366\n",
       "                   %\"val_384\"<FLOAT,[unk__117,12,s41,unk__120]> ⬅️ ::MatMul(%\"val_381\", %\"val_383\")\n",
       "            216 |  # node_Add_367\n",
       "                   %\"val_385\"<FLOAT,[unk__117,12,s41,unk__121]> ⬅️ ::Add(%\"val_384\", %\"masked_fill\")\n",
       "            217 |  # node_Softmax_368\n",
       "                   %\"val_386\"<FLOAT,[unk__117,12,s41,unk__121]> ⬅️ ::Softmax(%\"val_385\") {axis=-1}\n",
       "            218 |  # node_scaled_dot_product_attention_4\n",
       "                   %\"scaled_dot_product_attention_4\"<FLOAT,[1,12,s41,64]> ⬅️ ::MatMul(%\"val_386\", %\"transpose_18\")\n",
       "            219 |  # node_transpose_19\n",
       "                   %\"transpose_19\"<FLOAT,[1,s41,12,64]> ⬅️ ::Transpose(%\"scaled_dot_product_attention_4\") {perm=(0, 2, 1, 3)}\n",
       "            220 |  # node_view_19\n",
       "                   %\"view_19\"<FLOAT,[1,s41,768]> ⬅️ ::Reshape(%\"transpose_19\", %\"val_95\") {allowzero=1}\n",
       "            221 |  # node_MatMul_375\n",
       "                   %\"val_393\"<FLOAT,[1,s41,768]> ⬅️ ::MatMul(%\"view_19\", %\"val_392\"{...})\n",
       "            222 |  # node_linear_27\n",
       "                   %\"linear_27\"<FLOAT,[1,s41,768]> ⬅️ ::Add(%\"val_393\", %\"bert.encoder.layer.4.attention.output.dense.bias\"{...})\n",
       "            223 |  # node_add_385\n",
       "                   %\"add_385\"<FLOAT,[1,s41,768]> ⬅️ ::Add(%\"linear_27\", %\"layer_norm_8\")\n",
       "            224 |  # node_layer_norm_9\n",
       "                   %\"layer_norm_9\"<FLOAT,[1,s41,768]>, %\"\"<FLOAT,[1,s41,1]>, %\"\"<FLOAT,[1,s41,1]> ⬅️ ::LayerNormalization(%\"add_385\", %\"bert.encoder.layer.4.attention.output.LayerNorm.weight\"{...}, %\"bert.encoder.layer.4.attention.output.LayerNorm.bias\"{...}) {axis=-1, epsilon=9.999999960041972e-13, stash_type=1}\n",
       "            225 |  # node_MatMul_377\n",
       "                   %\"val_397\"<FLOAT,[1,s41,3072]> ⬅️ ::MatMul(%\"layer_norm_9\", %\"val_396\"{...})\n",
       "            226 |  # node_linear_28\n",
       "                   %\"linear_28\"<FLOAT,[1,s41,3072]> ⬅️ ::Add(%\"val_397\", %\"bert.encoder.layer.4.intermediate.dense.bias\"{...})\n",
       "            227 |  # node_Div_379\n",
       "                   %\"val_399\"<FLOAT,[1,s41,3072]> ⬅️ ::Div(%\"linear_28\", %\"val_102\"{1.4142135381698608})\n",
       "            228 |  # node_Erf_380\n",
       "                   %\"val_400\"<FLOAT,[1,s41,3072]> ⬅️ ::Erf(%\"val_399\")\n",
       "            229 |  # node_Add_382\n",
       "                   %\"val_402\"<FLOAT,[1,s41,3072]> ⬅️ ::Add(%\"val_400\", %\"clone_1\"{1.0})\n",
       "            230 |  # node_Mul_384\n",
       "                   %\"val_404\"<FLOAT,[1,s41,3072]> ⬅️ ::Mul(%\"val_107\"{0.5}, %\"val_402\")\n",
       "            231 |  # node_gelu_4\n",
       "                   %\"gelu_4\"<FLOAT,[1,s41,3072]> ⬅️ ::Mul(%\"linear_28\", %\"val_404\")\n",
       "            232 |  # node_MatMul_386\n",
       "                   %\"val_406\"<FLOAT,[1,s41,768]> ⬅️ ::MatMul(%\"gelu_4\", %\"val_405\"{...})\n",
       "            233 |  # node_linear_29\n",
       "                   %\"linear_29\"<FLOAT,[1,s41,768]> ⬅️ ::Add(%\"val_406\", %\"bert.encoder.layer.4.output.dense.bias\"{...})\n",
       "            234 |  # node_add_404\n",
       "                   %\"add_404\"<FLOAT,[1,s41,768]> ⬅️ ::Add(%\"linear_29\", %\"layer_norm_9\")\n",
       "            235 |  # node_layer_norm_10\n",
       "                   %\"layer_norm_10\"<FLOAT,[1,s41,768]>, %\"\"<FLOAT,[1,s41,1]>, %\"\"<FLOAT,[1,s41,1]> ⬅️ ::LayerNormalization(%\"add_404\", %\"bert.encoder.layer.4.output.LayerNorm.weight\"{...}, %\"bert.encoder.layer.4.output.LayerNorm.bias\"{...}) {axis=-1, epsilon=9.999999960041972e-13, stash_type=1}\n",
       "            236 |  # node_MatMul_388\n",
       "                   %\"val_410\"<FLOAT,[1,s41,768]> ⬅️ ::MatMul(%\"layer_norm_10\", %\"val_409\"{...})\n",
       "            237 |  # node_linear_30\n",
       "                   %\"linear_30\"<FLOAT,[1,s41,768]> ⬅️ ::Add(%\"val_410\", %\"bert.encoder.layer.5.attention.self.query.bias\"{...})\n",
       "            238 |  # node_view_20\n",
       "                   %\"view_20\"<FLOAT,[1,s41,12,64]> ⬅️ ::Reshape(%\"linear_30\", %\"val_44\"{[1, -1, 12, 64]}) {allowzero=1}\n",
       "            239 |  # node_transpose_20\n",
       "                   %\"transpose_20\"<FLOAT,[1,12,s41,64]> ⬅️ ::Transpose(%\"view_20\") {perm=(0, 2, 1, 3)}\n",
       "            240 |  # node_MatMul_396\n",
       "                   %\"val_418\"<FLOAT,[1,s41,768]> ⬅️ ::MatMul(%\"layer_norm_10\", %\"val_417\"{...})\n",
       "            241 |  # node_linear_31\n",
       "                   %\"linear_31\"<FLOAT,[1,s41,768]> ⬅️ ::Add(%\"val_418\", %\"bert.encoder.layer.5.attention.self.key.bias\"{...})\n",
       "            242 |  # node_view_21\n",
       "                   %\"view_21\"<FLOAT,[1,s41,12,64]> ⬅️ ::Reshape(%\"linear_31\", %\"val_44\"{[1, -1, 12, 64]}) {allowzero=1}\n",
       "            243 |  # node_transpose_21\n",
       "                   %\"transpose_21\"<FLOAT,[1,12,s41,64]> ⬅️ ::Transpose(%\"view_21\") {perm=(0, 2, 1, 3)}\n",
       "            244 |  # node_MatMul_404\n",
       "                   %\"val_426\"<FLOAT,[1,s41,768]> ⬅️ ::MatMul(%\"layer_norm_10\", %\"val_425\"{...})\n",
       "            245 |  # node_linear_32\n",
       "                   %\"linear_32\"<FLOAT,[1,s41,768]> ⬅️ ::Add(%\"val_426\", %\"bert.encoder.layer.5.attention.self.value.bias\"{...})\n",
       "            246 |  # node_view_22\n",
       "                   %\"view_22\"<FLOAT,[1,s41,12,64]> ⬅️ ::Reshape(%\"linear_32\", %\"val_44\"{[1, -1, 12, 64]}) {allowzero=1}\n",
       "            247 |  # node_transpose_22\n",
       "                   %\"transpose_22\"<FLOAT,[1,12,s41,64]> ⬅️ ::Transpose(%\"view_22\") {perm=(0, 2, 1, 3)}\n",
       "            248 |  # node_Shape_420\n",
       "                   %\"val_442\"<INT64,[4]> ⬅️ ::Shape(%\"transpose_21\") {start=0}\n",
       "            249 |  # node_Slice_422\n",
       "                   %\"val_444\"<INT64,[1]> ⬅️ ::Slice(%\"val_442\", %\"val_72\"{[-1]}, %\"val_71\"{[9223372036854775807]})\n",
       "            250 |  # node_Slice_423\n",
       "                   %\"val_445\"<INT64,[1]> ⬅️ ::Slice(%\"val_442\", %\"val_74\"{[-2]}, %\"val_72\"{[-1]})\n",
       "            251 |  # node_Slice_425\n",
       "                   %\"val_447\"<INT64,[2]> ⬅️ ::Slice(%\"val_442\", %\"val_76\"{[-9223372036854775808]}, %\"val_74\"{[-2]})\n",
       "            252 |  # node_Concat_427\n",
       "                   %\"val_449\"<INT64,[3]> ⬅️ ::Concat(%\"val_72\"{[-1]}, %\"val_445\", %\"val_444\") {axis=0}\n",
       "            253 |  # node_Reshape_428\n",
       "                   %\"val_450\"<FLOAT,[unk__137,unk__138,unk__139]> ⬅️ ::Reshape(%\"transpose_21\", %\"val_449\") {allowzero=0}\n",
       "            254 |  # node_Transpose_429\n",
       "                   %\"val_451\"<FLOAT,[unk__137,unk__139,unk__138]> ⬅️ ::Transpose(%\"val_450\") {perm=(0, 2, 1)}\n",
       "            255 |  # node_Concat_430\n",
       "                   %\"val_452\"<INT64,[4]> ⬅️ ::Concat(%\"val_447\", %\"val_444\", %\"val_445\") {axis=0}\n",
       "            256 |  # node_Reshape_431\n",
       "                   %\"val_453\"<FLOAT,[unk__140,unk__141,unk__142,unk__143]> ⬅️ ::Reshape(%\"val_451\", %\"val_452\") {allowzero=0}\n",
       "            257 |  # node_Mul_433\n",
       "                   %\"val_455\"<FLOAT,[1,12,s41,64]> ⬅️ ::Mul(%\"transpose_20\", %\"val_84\"{[0.3535533845424652]})\n",
       "            258 |  # node_Mul_435\n",
       "                   %\"val_457\"<FLOAT,[unk__140,unk__141,unk__142,unk__143]> ⬅️ ::Mul(%\"val_453\", %\"val_84\"{[0.3535533845424652]})\n",
       "            259 |  # node_MatMul_436\n",
       "                   %\"val_458\"<FLOAT,[unk__140,12,s41,unk__143]> ⬅️ ::MatMul(%\"val_455\", %\"val_457\")\n",
       "            260 |  # node_Add_437\n",
       "                   %\"val_459\"<FLOAT,[unk__140,12,s41,unk__144]> ⬅️ ::Add(%\"val_458\", %\"masked_fill\")\n",
       "            261 |  # node_Softmax_438\n",
       "                   %\"val_460\"<FLOAT,[unk__140,12,s41,unk__144]> ⬅️ ::Softmax(%\"val_459\") {axis=-1}\n",
       "            262 |  # node_scaled_dot_product_attention_5\n",
       "                   %\"scaled_dot_product_attention_5\"<FLOAT,[1,12,s41,64]> ⬅️ ::MatMul(%\"val_460\", %\"transpose_22\")\n",
       "            263 |  # node_transpose_23\n",
       "                   %\"transpose_23\"<FLOAT,[1,s41,12,64]> ⬅️ ::Transpose(%\"scaled_dot_product_attention_5\") {perm=(0, 2, 1, 3)}\n",
       "            264 |  # node_view_23\n",
       "                   %\"view_23\"<FLOAT,[1,s41,768]> ⬅️ ::Reshape(%\"transpose_23\", %\"val_95\") {allowzero=1}\n",
       "            265 |  # node_MatMul_445\n",
       "                   %\"val_467\"<FLOAT,[1,s41,768]> ⬅️ ::MatMul(%\"view_23\", %\"val_466\"{...})\n",
       "            266 |  # node_linear_33\n",
       "                   %\"linear_33\"<FLOAT,[1,s41,768]> ⬅️ ::Add(%\"val_467\", %\"bert.encoder.layer.5.attention.output.dense.bias\"{...})\n",
       "            267 |  # node_add_457\n",
       "                   %\"add_457\"<FLOAT,[1,s41,768]> ⬅️ ::Add(%\"linear_33\", %\"layer_norm_10\")\n",
       "            268 |  # node_layer_norm_11\n",
       "                   %\"layer_norm_11\"<FLOAT,[1,s41,768]>, %\"\"<FLOAT,[1,s41,1]>, %\"\"<FLOAT,[1,s41,1]> ⬅️ ::LayerNormalization(%\"add_457\", %\"bert.encoder.layer.5.attention.output.LayerNorm.weight\"{...}, %\"bert.encoder.layer.5.attention.output.LayerNorm.bias\"{...}) {axis=-1, epsilon=9.999999960041972e-13, stash_type=1}\n",
       "            269 |  # node_MatMul_447\n",
       "                   %\"val_471\"<FLOAT,[1,s41,3072]> ⬅️ ::MatMul(%\"layer_norm_11\", %\"val_470\"{...})\n",
       "            270 |  # node_linear_34\n",
       "                   %\"linear_34\"<FLOAT,[1,s41,3072]> ⬅️ ::Add(%\"val_471\", %\"bert.encoder.layer.5.intermediate.dense.bias\"{...})\n",
       "            271 |  # node_Div_449\n",
       "                   %\"val_473\"<FLOAT,[1,s41,3072]> ⬅️ ::Div(%\"linear_34\", %\"val_102\"{1.4142135381698608})\n",
       "            272 |  # node_Erf_450\n",
       "                   %\"val_474\"<FLOAT,[1,s41,3072]> ⬅️ ::Erf(%\"val_473\")\n",
       "            273 |  # node_Add_452\n",
       "                   %\"val_476\"<FLOAT,[1,s41,3072]> ⬅️ ::Add(%\"val_474\", %\"clone_1\"{1.0})\n",
       "            274 |  # node_Mul_454\n",
       "                   %\"val_478\"<FLOAT,[1,s41,3072]> ⬅️ ::Mul(%\"val_107\"{0.5}, %\"val_476\")\n",
       "            275 |  # node_gelu_5\n",
       "                   %\"gelu_5\"<FLOAT,[1,s41,3072]> ⬅️ ::Mul(%\"linear_34\", %\"val_478\")\n",
       "            276 |  # node_MatMul_456\n",
       "                   %\"val_480\"<FLOAT,[1,s41,768]> ⬅️ ::MatMul(%\"gelu_5\", %\"val_479\"{...})\n",
       "            277 |  # node_linear_35\n",
       "                   %\"linear_35\"<FLOAT,[1,s41,768]> ⬅️ ::Add(%\"val_480\", %\"bert.encoder.layer.5.output.dense.bias\"{...})\n",
       "            278 |  # node_add_476\n",
       "                   %\"add_476\"<FLOAT,[1,s41,768]> ⬅️ ::Add(%\"linear_35\", %\"layer_norm_11\")\n",
       "            279 |  # node_layer_norm_12\n",
       "                   %\"layer_norm_12\"<FLOAT,[1,s41,768]>, %\"\"<FLOAT,[1,s41,1]>, %\"\"<FLOAT,[1,s41,1]> ⬅️ ::LayerNormalization(%\"add_476\", %\"bert.encoder.layer.5.output.LayerNorm.weight\"{...}, %\"bert.encoder.layer.5.output.LayerNorm.bias\"{...}) {axis=-1, epsilon=9.999999960041972e-13, stash_type=1}\n",
       "            280 |  # node_MatMul_458\n",
       "                   %\"val_484\"<FLOAT,[1,s41,768]> ⬅️ ::MatMul(%\"layer_norm_12\", %\"val_483\"{...})\n",
       "            281 |  # node_linear_36\n",
       "                   %\"linear_36\"<FLOAT,[1,s41,768]> ⬅️ ::Add(%\"val_484\", %\"bert.encoder.layer.6.attention.self.query.bias\"{...})\n",
       "            282 |  # node_view_24\n",
       "                   %\"view_24\"<FLOAT,[1,s41,12,64]> ⬅️ ::Reshape(%\"linear_36\", %\"val_44\"{[1, -1, 12, 64]}) {allowzero=1}\n",
       "            283 |  # node_transpose_24\n",
       "                   %\"transpose_24\"<FLOAT,[1,12,s41,64]> ⬅️ ::Transpose(%\"view_24\") {perm=(0, 2, 1, 3)}\n",
       "            284 |  # node_MatMul_466\n",
       "                   %\"val_492\"<FLOAT,[1,s41,768]> ⬅️ ::MatMul(%\"layer_norm_12\", %\"val_491\"{...})\n",
       "            285 |  # node_linear_37\n",
       "                   %\"linear_37\"<FLOAT,[1,s41,768]> ⬅️ ::Add(%\"val_492\", %\"bert.encoder.layer.6.attention.self.key.bias\"{...})\n",
       "            286 |  # node_view_25\n",
       "                   %\"view_25\"<FLOAT,[1,s41,12,64]> ⬅️ ::Reshape(%\"linear_37\", %\"val_44\"{[1, -1, 12, 64]}) {allowzero=1}\n",
       "            287 |  # node_transpose_25\n",
       "                   %\"transpose_25\"<FLOAT,[1,12,s41,64]> ⬅️ ::Transpose(%\"view_25\") {perm=(0, 2, 1, 3)}\n",
       "            288 |  # node_MatMul_474\n",
       "                   %\"val_500\"<FLOAT,[1,s41,768]> ⬅️ ::MatMul(%\"layer_norm_12\", %\"val_499\"{...})\n",
       "            289 |  # node_linear_38\n",
       "                   %\"linear_38\"<FLOAT,[1,s41,768]> ⬅️ ::Add(%\"val_500\", %\"bert.encoder.layer.6.attention.self.value.bias\"{...})\n",
       "            290 |  # node_view_26\n",
       "                   %\"view_26\"<FLOAT,[1,s41,12,64]> ⬅️ ::Reshape(%\"linear_38\", %\"val_44\"{[1, -1, 12, 64]}) {allowzero=1}\n",
       "            291 |  # node_transpose_26\n",
       "                   %\"transpose_26\"<FLOAT,[1,12,s41,64]> ⬅️ ::Transpose(%\"view_26\") {perm=(0, 2, 1, 3)}\n",
       "            292 |  # node_Shape_490\n",
       "                   %\"val_516\"<INT64,[4]> ⬅️ ::Shape(%\"transpose_25\") {start=0}\n",
       "            293 |  # node_Slice_492\n",
       "                   %\"val_518\"<INT64,[1]> ⬅️ ::Slice(%\"val_516\", %\"val_72\"{[-1]}, %\"val_71\"{[9223372036854775807]})\n",
       "            294 |  # node_Slice_493\n",
       "                   %\"val_519\"<INT64,[1]> ⬅️ ::Slice(%\"val_516\", %\"val_74\"{[-2]}, %\"val_72\"{[-1]})\n",
       "            295 |  # node_Slice_495\n",
       "                   %\"val_521\"<INT64,[2]> ⬅️ ::Slice(%\"val_516\", %\"val_76\"{[-9223372036854775808]}, %\"val_74\"{[-2]})\n",
       "            296 |  # node_Concat_497\n",
       "                   %\"val_523\"<INT64,[3]> ⬅️ ::Concat(%\"val_72\"{[-1]}, %\"val_519\", %\"val_518\") {axis=0}\n",
       "            297 |  # node_Reshape_498\n",
       "                   %\"val_524\"<FLOAT,[unk__160,unk__161,unk__162]> ⬅️ ::Reshape(%\"transpose_25\", %\"val_523\") {allowzero=0}\n",
       "            298 |  # node_Transpose_499\n",
       "                   %\"val_525\"<FLOAT,[unk__160,unk__162,unk__161]> ⬅️ ::Transpose(%\"val_524\") {perm=(0, 2, 1)}\n",
       "            299 |  # node_Concat_500\n",
       "                   %\"val_526\"<INT64,[4]> ⬅️ ::Concat(%\"val_521\", %\"val_518\", %\"val_519\") {axis=0}\n",
       "            300 |  # node_Reshape_501\n",
       "                   %\"val_527\"<FLOAT,[unk__163,unk__164,unk__165,unk__166]> ⬅️ ::Reshape(%\"val_525\", %\"val_526\") {allowzero=0}\n",
       "            301 |  # node_Mul_503\n",
       "                   %\"val_529\"<FLOAT,[1,12,s41,64]> ⬅️ ::Mul(%\"transpose_24\", %\"val_84\"{[0.3535533845424652]})\n",
       "            302 |  # node_Mul_505\n",
       "                   %\"val_531\"<FLOAT,[unk__163,unk__164,unk__165,unk__166]> ⬅️ ::Mul(%\"val_527\", %\"val_84\"{[0.3535533845424652]})\n",
       "            303 |  # node_MatMul_506\n",
       "                   %\"val_532\"<FLOAT,[unk__163,12,s41,unk__166]> ⬅️ ::MatMul(%\"val_529\", %\"val_531\")\n",
       "            304 |  # node_Add_507\n",
       "                   %\"val_533\"<FLOAT,[unk__163,12,s41,unk__167]> ⬅️ ::Add(%\"val_532\", %\"masked_fill\")\n",
       "            305 |  # node_Softmax_508\n",
       "                   %\"val_534\"<FLOAT,[unk__163,12,s41,unk__167]> ⬅️ ::Softmax(%\"val_533\") {axis=-1}\n",
       "            306 |  # node_scaled_dot_product_attention_6\n",
       "                   %\"scaled_dot_product_attention_6\"<FLOAT,[1,12,s41,64]> ⬅️ ::MatMul(%\"val_534\", %\"transpose_26\")\n",
       "            307 |  # node_transpose_27\n",
       "                   %\"transpose_27\"<FLOAT,[1,s41,12,64]> ⬅️ ::Transpose(%\"scaled_dot_product_attention_6\") {perm=(0, 2, 1, 3)}\n",
       "            308 |  # node_view_27\n",
       "                   %\"view_27\"<FLOAT,[1,s41,768]> ⬅️ ::Reshape(%\"transpose_27\", %\"val_95\") {allowzero=1}\n",
       "            309 |  # node_MatMul_515\n",
       "                   %\"val_541\"<FLOAT,[1,s41,768]> ⬅️ ::MatMul(%\"view_27\", %\"val_540\"{...})\n",
       "            310 |  # node_linear_39\n",
       "                   %\"linear_39\"<FLOAT,[1,s41,768]> ⬅️ ::Add(%\"val_541\", %\"bert.encoder.layer.6.attention.output.dense.bias\"{...})\n",
       "            311 |  # node_add_529\n",
       "                   %\"add_529\"<FLOAT,[1,s41,768]> ⬅️ ::Add(%\"linear_39\", %\"layer_norm_12\")\n",
       "            312 |  # node_layer_norm_13\n",
       "                   %\"layer_norm_13\"<FLOAT,[1,s41,768]>, %\"\"<FLOAT,[1,s41,1]>, %\"\"<FLOAT,[1,s41,1]> ⬅️ ::LayerNormalization(%\"add_529\", %\"bert.encoder.layer.6.attention.output.LayerNorm.weight\"{...}, %\"bert.encoder.layer.6.attention.output.LayerNorm.bias\"{...}) {axis=-1, epsilon=9.999999960041972e-13, stash_type=1}\n",
       "            313 |  # node_MatMul_517\n",
       "                   %\"val_545\"<FLOAT,[1,s41,3072]> ⬅️ ::MatMul(%\"layer_norm_13\", %\"val_544\"{...})\n",
       "            314 |  # node_linear_40\n",
       "                   %\"linear_40\"<FLOAT,[1,s41,3072]> ⬅️ ::Add(%\"val_545\", %\"bert.encoder.layer.6.intermediate.dense.bias\"{...})\n",
       "            315 |  # node_Div_519\n",
       "                   %\"val_547\"<FLOAT,[1,s41,3072]> ⬅️ ::Div(%\"linear_40\", %\"val_102\"{1.4142135381698608})\n",
       "            316 |  # node_Erf_520\n",
       "                   %\"val_548\"<FLOAT,[1,s41,3072]> ⬅️ ::Erf(%\"val_547\")\n",
       "            317 |  # node_Add_522\n",
       "                   %\"val_550\"<FLOAT,[1,s41,3072]> ⬅️ ::Add(%\"val_548\", %\"clone_1\"{1.0})\n",
       "            318 |  # node_Mul_524\n",
       "                   %\"val_552\"<FLOAT,[1,s41,3072]> ⬅️ ::Mul(%\"val_107\"{0.5}, %\"val_550\")\n",
       "            319 |  # node_gelu_6\n",
       "                   %\"gelu_6\"<FLOAT,[1,s41,3072]> ⬅️ ::Mul(%\"linear_40\", %\"val_552\")\n",
       "            320 |  # node_MatMul_526\n",
       "                   %\"val_554\"<FLOAT,[1,s41,768]> ⬅️ ::MatMul(%\"gelu_6\", %\"val_553\"{...})\n",
       "            321 |  # node_linear_41\n",
       "                   %\"linear_41\"<FLOAT,[1,s41,768]> ⬅️ ::Add(%\"val_554\", %\"bert.encoder.layer.6.output.dense.bias\"{...})\n",
       "            322 |  # node_add_548\n",
       "                   %\"add_548\"<FLOAT,[1,s41,768]> ⬅️ ::Add(%\"linear_41\", %\"layer_norm_13\")\n",
       "            323 |  # node_layer_norm_14\n",
       "                   %\"layer_norm_14\"<FLOAT,[1,s41,768]>, %\"\"<FLOAT,[1,s41,1]>, %\"\"<FLOAT,[1,s41,1]> ⬅️ ::LayerNormalization(%\"add_548\", %\"bert.encoder.layer.6.output.LayerNorm.weight\"{...}, %\"bert.encoder.layer.6.output.LayerNorm.bias\"{...}) {axis=-1, epsilon=9.999999960041972e-13, stash_type=1}\n",
       "            324 |  # node_MatMul_528\n",
       "                   %\"val_558\"<FLOAT,[1,s41,768]> ⬅️ ::MatMul(%\"layer_norm_14\", %\"val_557\"{...})\n",
       "            325 |  # node_linear_42\n",
       "                   %\"linear_42\"<FLOAT,[1,s41,768]> ⬅️ ::Add(%\"val_558\", %\"bert.encoder.layer.7.attention.self.query.bias\"{...})\n",
       "            326 |  # node_view_28\n",
       "                   %\"view_28\"<FLOAT,[1,s41,12,64]> ⬅️ ::Reshape(%\"linear_42\", %\"val_44\"{[1, -1, 12, 64]}) {allowzero=1}\n",
       "            327 |  # node_transpose_28\n",
       "                   %\"transpose_28\"<FLOAT,[1,12,s41,64]> ⬅️ ::Transpose(%\"view_28\") {perm=(0, 2, 1, 3)}\n",
       "            328 |  # node_MatMul_536\n",
       "                   %\"val_566\"<FLOAT,[1,s41,768]> ⬅️ ::MatMul(%\"layer_norm_14\", %\"val_565\"{...})\n",
       "            329 |  # node_linear_43\n",
       "                   %\"linear_43\"<FLOAT,[1,s41,768]> ⬅️ ::Add(%\"val_566\", %\"bert.encoder.layer.7.attention.self.key.bias\"{...})\n",
       "            330 |  # node_view_29\n",
       "                   %\"view_29\"<FLOAT,[1,s41,12,64]> ⬅️ ::Reshape(%\"linear_43\", %\"val_44\"{[1, -1, 12, 64]}) {allowzero=1}\n",
       "            331 |  # node_transpose_29\n",
       "                   %\"transpose_29\"<FLOAT,[1,12,s41,64]> ⬅️ ::Transpose(%\"view_29\") {perm=(0, 2, 1, 3)}\n",
       "            332 |  # node_MatMul_544\n",
       "                   %\"val_574\"<FLOAT,[1,s41,768]> ⬅️ ::MatMul(%\"layer_norm_14\", %\"val_573\"{...})\n",
       "            333 |  # node_linear_44\n",
       "                   %\"linear_44\"<FLOAT,[1,s41,768]> ⬅️ ::Add(%\"val_574\", %\"bert.encoder.layer.7.attention.self.value.bias\"{...})\n",
       "            334 |  # node_view_30\n",
       "                   %\"view_30\"<FLOAT,[1,s41,12,64]> ⬅️ ::Reshape(%\"linear_44\", %\"val_44\"{[1, -1, 12, 64]}) {allowzero=1}\n",
       "            335 |  # node_transpose_30\n",
       "                   %\"transpose_30\"<FLOAT,[1,12,s41,64]> ⬅️ ::Transpose(%\"view_30\") {perm=(0, 2, 1, 3)}\n",
       "            336 |  # node_Shape_560\n",
       "                   %\"val_590\"<INT64,[4]> ⬅️ ::Shape(%\"transpose_29\") {start=0}\n",
       "            337 |  # node_Slice_562\n",
       "                   %\"val_592\"<INT64,[1]> ⬅️ ::Slice(%\"val_590\", %\"val_72\"{[-1]}, %\"val_71\"{[9223372036854775807]})\n",
       "            338 |  # node_Slice_563\n",
       "                   %\"val_593\"<INT64,[1]> ⬅️ ::Slice(%\"val_590\", %\"val_74\"{[-2]}, %\"val_72\"{[-1]})\n",
       "            339 |  # node_Slice_565\n",
       "                   %\"val_595\"<INT64,[2]> ⬅️ ::Slice(%\"val_590\", %\"val_76\"{[-9223372036854775808]}, %\"val_74\"{[-2]})\n",
       "            340 |  # node_Concat_567\n",
       "                   %\"val_597\"<INT64,[3]> ⬅️ ::Concat(%\"val_72\"{[-1]}, %\"val_593\", %\"val_592\") {axis=0}\n",
       "            341 |  # node_Reshape_568\n",
       "                   %\"val_598\"<FLOAT,[unk__183,unk__184,unk__185]> ⬅️ ::Reshape(%\"transpose_29\", %\"val_597\") {allowzero=0}\n",
       "            342 |  # node_Transpose_569\n",
       "                   %\"val_599\"<FLOAT,[unk__183,unk__185,unk__184]> ⬅️ ::Transpose(%\"val_598\") {perm=(0, 2, 1)}\n",
       "            343 |  # node_Concat_570\n",
       "                   %\"val_600\"<INT64,[4]> ⬅️ ::Concat(%\"val_595\", %\"val_592\", %\"val_593\") {axis=0}\n",
       "            344 |  # node_Reshape_571\n",
       "                   %\"val_601\"<FLOAT,[unk__186,unk__187,unk__188,unk__189]> ⬅️ ::Reshape(%\"val_599\", %\"val_600\") {allowzero=0}\n",
       "            345 |  # node_Mul_573\n",
       "                   %\"val_603\"<FLOAT,[1,12,s41,64]> ⬅️ ::Mul(%\"transpose_28\", %\"val_84\"{[0.3535533845424652]})\n",
       "            346 |  # node_Mul_575\n",
       "                   %\"val_605\"<FLOAT,[unk__186,unk__187,unk__188,unk__189]> ⬅️ ::Mul(%\"val_601\", %\"val_84\"{[0.3535533845424652]})\n",
       "            347 |  # node_MatMul_576\n",
       "                   %\"val_606\"<FLOAT,[unk__186,12,s41,unk__189]> ⬅️ ::MatMul(%\"val_603\", %\"val_605\")\n",
       "            348 |  # node_Add_577\n",
       "                   %\"val_607\"<FLOAT,[unk__186,12,s41,unk__190]> ⬅️ ::Add(%\"val_606\", %\"masked_fill\")\n",
       "            349 |  # node_Softmax_578\n",
       "                   %\"val_608\"<FLOAT,[unk__186,12,s41,unk__190]> ⬅️ ::Softmax(%\"val_607\") {axis=-1}\n",
       "            350 |  # node_scaled_dot_product_attention_7\n",
       "                   %\"scaled_dot_product_attention_7\"<FLOAT,[1,12,s41,64]> ⬅️ ::MatMul(%\"val_608\", %\"transpose_30\")\n",
       "            351 |  # node_transpose_31\n",
       "                   %\"transpose_31\"<FLOAT,[1,s41,12,64]> ⬅️ ::Transpose(%\"scaled_dot_product_attention_7\") {perm=(0, 2, 1, 3)}\n",
       "            352 |  # node_view_31\n",
       "                   %\"view_31\"<FLOAT,[1,s41,768]> ⬅️ ::Reshape(%\"transpose_31\", %\"val_95\") {allowzero=1}\n",
       "            353 |  # node_MatMul_585\n",
       "                   %\"val_615\"<FLOAT,[1,s41,768]> ⬅️ ::MatMul(%\"view_31\", %\"val_614\"{...})\n",
       "            354 |  # node_linear_45\n",
       "                   %\"linear_45\"<FLOAT,[1,s41,768]> ⬅️ ::Add(%\"val_615\", %\"bert.encoder.layer.7.attention.output.dense.bias\"{...})\n",
       "            355 |  # node_add_601\n",
       "                   %\"add_601\"<FLOAT,[1,s41,768]> ⬅️ ::Add(%\"linear_45\", %\"layer_norm_14\")\n",
       "            356 |  # node_layer_norm_15\n",
       "                   %\"layer_norm_15\"<FLOAT,[1,s41,768]>, %\"\"<FLOAT,[1,s41,1]>, %\"\"<FLOAT,[1,s41,1]> ⬅️ ::LayerNormalization(%\"add_601\", %\"bert.encoder.layer.7.attention.output.LayerNorm.weight\"{...}, %\"bert.encoder.layer.7.attention.output.LayerNorm.bias\"{...}) {axis=-1, epsilon=9.999999960041972e-13, stash_type=1}\n",
       "            357 |  # node_MatMul_587\n",
       "                   %\"val_619\"<FLOAT,[1,s41,3072]> ⬅️ ::MatMul(%\"layer_norm_15\", %\"val_618\"{...})\n",
       "            358 |  # node_linear_46\n",
       "                   %\"linear_46\"<FLOAT,[1,s41,3072]> ⬅️ ::Add(%\"val_619\", %\"bert.encoder.layer.7.intermediate.dense.bias\"{...})\n",
       "            359 |  # node_Div_589\n",
       "                   %\"val_621\"<FLOAT,[1,s41,3072]> ⬅️ ::Div(%\"linear_46\", %\"val_102\"{1.4142135381698608})\n",
       "            360 |  # node_Erf_590\n",
       "                   %\"val_622\"<FLOAT,[1,s41,3072]> ⬅️ ::Erf(%\"val_621\")\n",
       "            361 |  # node_Add_592\n",
       "                   %\"val_624\"<FLOAT,[1,s41,3072]> ⬅️ ::Add(%\"val_622\", %\"clone_1\"{1.0})\n",
       "            362 |  # node_Mul_594\n",
       "                   %\"val_626\"<FLOAT,[1,s41,3072]> ⬅️ ::Mul(%\"val_107\"{0.5}, %\"val_624\")\n",
       "            363 |  # node_gelu_7\n",
       "                   %\"gelu_7\"<FLOAT,[1,s41,3072]> ⬅️ ::Mul(%\"linear_46\", %\"val_626\")\n",
       "            364 |  # node_MatMul_596\n",
       "                   %\"val_628\"<FLOAT,[1,s41,768]> ⬅️ ::MatMul(%\"gelu_7\", %\"val_627\"{...})\n",
       "            365 |  # node_linear_47\n",
       "                   %\"linear_47\"<FLOAT,[1,s41,768]> ⬅️ ::Add(%\"val_628\", %\"bert.encoder.layer.7.output.dense.bias\"{...})\n",
       "            366 |  # node_add_620\n",
       "                   %\"add_620\"<FLOAT,[1,s41,768]> ⬅️ ::Add(%\"linear_47\", %\"layer_norm_15\")\n",
       "            367 |  # node_layer_norm_16\n",
       "                   %\"layer_norm_16\"<FLOAT,[1,s41,768]>, %\"\"<FLOAT,[1,s41,1]>, %\"\"<FLOAT,[1,s41,1]> ⬅️ ::LayerNormalization(%\"add_620\", %\"bert.encoder.layer.7.output.LayerNorm.weight\"{...}, %\"bert.encoder.layer.7.output.LayerNorm.bias\"{...}) {axis=-1, epsilon=9.999999960041972e-13, stash_type=1}\n",
       "            368 |  # node_MatMul_598\n",
       "                   %\"val_632\"<FLOAT,[1,s41,768]> ⬅️ ::MatMul(%\"layer_norm_16\", %\"val_631\"{...})\n",
       "            369 |  # node_linear_48\n",
       "                   %\"linear_48\"<FLOAT,[1,s41,768]> ⬅️ ::Add(%\"val_632\", %\"bert.encoder.layer.8.attention.self.query.bias\"{...})\n",
       "            370 |  # node_view_32\n",
       "                   %\"view_32\"<FLOAT,[1,s41,12,64]> ⬅️ ::Reshape(%\"linear_48\", %\"val_44\"{[1, -1, 12, 64]}) {allowzero=1}\n",
       "            371 |  # node_transpose_32\n",
       "                   %\"transpose_32\"<FLOAT,[1,12,s41,64]> ⬅️ ::Transpose(%\"view_32\") {perm=(0, 2, 1, 3)}\n",
       "            372 |  # node_MatMul_606\n",
       "                   %\"val_640\"<FLOAT,[1,s41,768]> ⬅️ ::MatMul(%\"layer_norm_16\", %\"val_639\"{...})\n",
       "            373 |  # node_linear_49\n",
       "                   %\"linear_49\"<FLOAT,[1,s41,768]> ⬅️ ::Add(%\"val_640\", %\"bert.encoder.layer.8.attention.self.key.bias\"{...})\n",
       "            374 |  # node_view_33\n",
       "                   %\"view_33\"<FLOAT,[1,s41,12,64]> ⬅️ ::Reshape(%\"linear_49\", %\"val_44\"{[1, -1, 12, 64]}) {allowzero=1}\n",
       "            375 |  # node_transpose_33\n",
       "                   %\"transpose_33\"<FLOAT,[1,12,s41,64]> ⬅️ ::Transpose(%\"view_33\") {perm=(0, 2, 1, 3)}\n",
       "            376 |  # node_MatMul_614\n",
       "                   %\"val_648\"<FLOAT,[1,s41,768]> ⬅️ ::MatMul(%\"layer_norm_16\", %\"val_647\"{...})\n",
       "            377 |  # node_linear_50\n",
       "                   %\"linear_50\"<FLOAT,[1,s41,768]> ⬅️ ::Add(%\"val_648\", %\"bert.encoder.layer.8.attention.self.value.bias\"{...})\n",
       "            378 |  # node_view_34\n",
       "                   %\"view_34\"<FLOAT,[1,s41,12,64]> ⬅️ ::Reshape(%\"linear_50\", %\"val_44\"{[1, -1, 12, 64]}) {allowzero=1}\n",
       "            379 |  # node_transpose_34\n",
       "                   %\"transpose_34\"<FLOAT,[1,12,s41,64]> ⬅️ ::Transpose(%\"view_34\") {perm=(0, 2, 1, 3)}\n",
       "            380 |  # node_Shape_630\n",
       "                   %\"val_664\"<INT64,[4]> ⬅️ ::Shape(%\"transpose_33\") {start=0}\n",
       "            381 |  # node_Slice_632\n",
       "                   %\"val_666\"<INT64,[1]> ⬅️ ::Slice(%\"val_664\", %\"val_72\"{[-1]}, %\"val_71\"{[9223372036854775807]})\n",
       "            382 |  # node_Slice_633\n",
       "                   %\"val_667\"<INT64,[1]> ⬅️ ::Slice(%\"val_664\", %\"val_74\"{[-2]}, %\"val_72\"{[-1]})\n",
       "            383 |  # node_Slice_635\n",
       "                   %\"val_669\"<INT64,[2]> ⬅️ ::Slice(%\"val_664\", %\"val_76\"{[-9223372036854775808]}, %\"val_74\"{[-2]})\n",
       "            384 |  # node_Concat_637\n",
       "                   %\"val_671\"<INT64,[3]> ⬅️ ::Concat(%\"val_72\"{[-1]}, %\"val_667\", %\"val_666\") {axis=0}\n",
       "            385 |  # node_Reshape_638\n",
       "                   %\"val_672\"<FLOAT,[unk__206,unk__207,unk__208]> ⬅️ ::Reshape(%\"transpose_33\", %\"val_671\") {allowzero=0}\n",
       "            386 |  # node_Transpose_639\n",
       "                   %\"val_673\"<FLOAT,[unk__206,unk__208,unk__207]> ⬅️ ::Transpose(%\"val_672\") {perm=(0, 2, 1)}\n",
       "            387 |  # node_Concat_640\n",
       "                   %\"val_674\"<INT64,[4]> ⬅️ ::Concat(%\"val_669\", %\"val_666\", %\"val_667\") {axis=0}\n",
       "            388 |  # node_Reshape_641\n",
       "                   %\"val_675\"<FLOAT,[unk__209,unk__210,unk__211,unk__212]> ⬅️ ::Reshape(%\"val_673\", %\"val_674\") {allowzero=0}\n",
       "            389 |  # node_Mul_643\n",
       "                   %\"val_677\"<FLOAT,[1,12,s41,64]> ⬅️ ::Mul(%\"transpose_32\", %\"val_84\"{[0.3535533845424652]})\n",
       "            390 |  # node_Mul_645\n",
       "                   %\"val_679\"<FLOAT,[unk__209,unk__210,unk__211,unk__212]> ⬅️ ::Mul(%\"val_675\", %\"val_84\"{[0.3535533845424652]})\n",
       "            391 |  # node_MatMul_646\n",
       "                   %\"val_680\"<FLOAT,[unk__209,12,s41,unk__212]> ⬅️ ::MatMul(%\"val_677\", %\"val_679\")\n",
       "            392 |  # node_Add_647\n",
       "                   %\"val_681\"<FLOAT,[unk__209,12,s41,unk__213]> ⬅️ ::Add(%\"val_680\", %\"masked_fill\")\n",
       "            393 |  # node_Softmax_648\n",
       "                   %\"val_682\"<FLOAT,[unk__209,12,s41,unk__213]> ⬅️ ::Softmax(%\"val_681\") {axis=-1}\n",
       "            394 |  # node_scaled_dot_product_attention_8\n",
       "                   %\"scaled_dot_product_attention_8\"<FLOAT,[1,12,s41,64]> ⬅️ ::MatMul(%\"val_682\", %\"transpose_34\")\n",
       "            395 |  # node_transpose_35\n",
       "                   %\"transpose_35\"<FLOAT,[1,s41,12,64]> ⬅️ ::Transpose(%\"scaled_dot_product_attention_8\") {perm=(0, 2, 1, 3)}\n",
       "            396 |  # node_view_35\n",
       "                   %\"view_35\"<FLOAT,[1,s41,768]> ⬅️ ::Reshape(%\"transpose_35\", %\"val_95\") {allowzero=1}\n",
       "            397 |  # node_MatMul_655\n",
       "                   %\"val_689\"<FLOAT,[1,s41,768]> ⬅️ ::MatMul(%\"view_35\", %\"val_688\"{...})\n",
       "            398 |  # node_linear_51\n",
       "                   %\"linear_51\"<FLOAT,[1,s41,768]> ⬅️ ::Add(%\"val_689\", %\"bert.encoder.layer.8.attention.output.dense.bias\"{...})\n",
       "            399 |  # node_add_673\n",
       "                   %\"add_673\"<FLOAT,[1,s41,768]> ⬅️ ::Add(%\"linear_51\", %\"layer_norm_16\")\n",
       "            400 |  # node_layer_norm_17\n",
       "                   %\"layer_norm_17\"<FLOAT,[1,s41,768]>, %\"\"<FLOAT,[1,s41,1]>, %\"\"<FLOAT,[1,s41,1]> ⬅️ ::LayerNormalization(%\"add_673\", %\"bert.encoder.layer.8.attention.output.LayerNorm.weight\"{...}, %\"bert.encoder.layer.8.attention.output.LayerNorm.bias\"{...}) {axis=-1, epsilon=9.999999960041972e-13, stash_type=1}\n",
       "            401 |  # node_MatMul_657\n",
       "                   %\"val_693\"<FLOAT,[1,s41,3072]> ⬅️ ::MatMul(%\"layer_norm_17\", %\"val_692\"{...})\n",
       "            402 |  # node_linear_52\n",
       "                   %\"linear_52\"<FLOAT,[1,s41,3072]> ⬅️ ::Add(%\"val_693\", %\"bert.encoder.layer.8.intermediate.dense.bias\"{...})\n",
       "            403 |  # node_Div_659\n",
       "                   %\"val_695\"<FLOAT,[1,s41,3072]> ⬅️ ::Div(%\"linear_52\", %\"val_102\"{1.4142135381698608})\n",
       "            404 |  # node_Erf_660\n",
       "                   %\"val_696\"<FLOAT,[1,s41,3072]> ⬅️ ::Erf(%\"val_695\")\n",
       "            405 |  # node_Add_662\n",
       "                   %\"val_698\"<FLOAT,[1,s41,3072]> ⬅️ ::Add(%\"val_696\", %\"clone_1\"{1.0})\n",
       "            406 |  # node_Mul_664\n",
       "                   %\"val_700\"<FLOAT,[1,s41,3072]> ⬅️ ::Mul(%\"val_107\"{0.5}, %\"val_698\")\n",
       "            407 |  # node_gelu_8\n",
       "                   %\"gelu_8\"<FLOAT,[1,s41,3072]> ⬅️ ::Mul(%\"linear_52\", %\"val_700\")\n",
       "            408 |  # node_MatMul_666\n",
       "                   %\"val_702\"<FLOAT,[1,s41,768]> ⬅️ ::MatMul(%\"gelu_8\", %\"val_701\"{...})\n",
       "            409 |  # node_linear_53\n",
       "                   %\"linear_53\"<FLOAT,[1,s41,768]> ⬅️ ::Add(%\"val_702\", %\"bert.encoder.layer.8.output.dense.bias\"{...})\n",
       "            410 |  # node_add_692\n",
       "                   %\"add_692\"<FLOAT,[1,s41,768]> ⬅️ ::Add(%\"linear_53\", %\"layer_norm_17\")\n",
       "            411 |  # node_layer_norm_18\n",
       "                   %\"layer_norm_18\"<FLOAT,[1,s41,768]>, %\"\"<FLOAT,[1,s41,1]>, %\"\"<FLOAT,[1,s41,1]> ⬅️ ::LayerNormalization(%\"add_692\", %\"bert.encoder.layer.8.output.LayerNorm.weight\"{...}, %\"bert.encoder.layer.8.output.LayerNorm.bias\"{...}) {axis=-1, epsilon=9.999999960041972e-13, stash_type=1}\n",
       "            412 |  # node_MatMul_668\n",
       "                   %\"val_706\"<FLOAT,[1,s41,768]> ⬅️ ::MatMul(%\"layer_norm_18\", %\"val_705\"{...})\n",
       "            413 |  # node_linear_54\n",
       "                   %\"linear_54\"<FLOAT,[1,s41,768]> ⬅️ ::Add(%\"val_706\", %\"bert.encoder.layer.9.attention.self.query.bias\"{...})\n",
       "            414 |  # node_view_36\n",
       "                   %\"view_36\"<FLOAT,[1,s41,12,64]> ⬅️ ::Reshape(%\"linear_54\", %\"val_44\"{[1, -1, 12, 64]}) {allowzero=1}\n",
       "            415 |  # node_transpose_36\n",
       "                   %\"transpose_36\"<FLOAT,[1,12,s41,64]> ⬅️ ::Transpose(%\"view_36\") {perm=(0, 2, 1, 3)}\n",
       "            416 |  # node_MatMul_676\n",
       "                   %\"val_714\"<FLOAT,[1,s41,768]> ⬅️ ::MatMul(%\"layer_norm_18\", %\"val_713\"{...})\n",
       "            417 |  # node_linear_55\n",
       "                   %\"linear_55\"<FLOAT,[1,s41,768]> ⬅️ ::Add(%\"val_714\", %\"bert.encoder.layer.9.attention.self.key.bias\"{...})\n",
       "            418 |  # node_view_37\n",
       "                   %\"view_37\"<FLOAT,[1,s41,12,64]> ⬅️ ::Reshape(%\"linear_55\", %\"val_44\"{[1, -1, 12, 64]}) {allowzero=1}\n",
       "            419 |  # node_transpose_37\n",
       "                   %\"transpose_37\"<FLOAT,[1,12,s41,64]> ⬅️ ::Transpose(%\"view_37\") {perm=(0, 2, 1, 3)}\n",
       "            420 |  # node_MatMul_684\n",
       "                   %\"val_722\"<FLOAT,[1,s41,768]> ⬅️ ::MatMul(%\"layer_norm_18\", %\"val_721\"{...})\n",
       "            421 |  # node_linear_56\n",
       "                   %\"linear_56\"<FLOAT,[1,s41,768]> ⬅️ ::Add(%\"val_722\", %\"bert.encoder.layer.9.attention.self.value.bias\"{...})\n",
       "            422 |  # node_view_38\n",
       "                   %\"view_38\"<FLOAT,[1,s41,12,64]> ⬅️ ::Reshape(%\"linear_56\", %\"val_44\"{[1, -1, 12, 64]}) {allowzero=1}\n",
       "            423 |  # node_transpose_38\n",
       "                   %\"transpose_38\"<FLOAT,[1,12,s41,64]> ⬅️ ::Transpose(%\"view_38\") {perm=(0, 2, 1, 3)}\n",
       "            424 |  # node_Shape_700\n",
       "                   %\"val_738\"<INT64,[4]> ⬅️ ::Shape(%\"transpose_37\") {start=0}\n",
       "            425 |  # node_Slice_702\n",
       "                   %\"val_740\"<INT64,[1]> ⬅️ ::Slice(%\"val_738\", %\"val_72\"{[-1]}, %\"val_71\"{[9223372036854775807]})\n",
       "            426 |  # node_Slice_703\n",
       "                   %\"val_741\"<INT64,[1]> ⬅️ ::Slice(%\"val_738\", %\"val_74\"{[-2]}, %\"val_72\"{[-1]})\n",
       "            427 |  # node_Slice_705\n",
       "                   %\"val_743\"<INT64,[2]> ⬅️ ::Slice(%\"val_738\", %\"val_76\"{[-9223372036854775808]}, %\"val_74\"{[-2]})\n",
       "            428 |  # node_Concat_707\n",
       "                   %\"val_745\"<INT64,[3]> ⬅️ ::Concat(%\"val_72\"{[-1]}, %\"val_741\", %\"val_740\") {axis=0}\n",
       "            429 |  # node_Reshape_708\n",
       "                   %\"val_746\"<FLOAT,[unk__229,unk__230,unk__231]> ⬅️ ::Reshape(%\"transpose_37\", %\"val_745\") {allowzero=0}\n",
       "            430 |  # node_Transpose_709\n",
       "                   %\"val_747\"<FLOAT,[unk__229,unk__231,unk__230]> ⬅️ ::Transpose(%\"val_746\") {perm=(0, 2, 1)}\n",
       "            431 |  # node_Concat_710\n",
       "                   %\"val_748\"<INT64,[4]> ⬅️ ::Concat(%\"val_743\", %\"val_740\", %\"val_741\") {axis=0}\n",
       "            432 |  # node_Reshape_711\n",
       "                   %\"val_749\"<FLOAT,[unk__232,unk__233,unk__234,unk__235]> ⬅️ ::Reshape(%\"val_747\", %\"val_748\") {allowzero=0}\n",
       "            433 |  # node_Mul_713\n",
       "                   %\"val_751\"<FLOAT,[1,12,s41,64]> ⬅️ ::Mul(%\"transpose_36\", %\"val_84\"{[0.3535533845424652]})\n",
       "            434 |  # node_Mul_715\n",
       "                   %\"val_753\"<FLOAT,[unk__232,unk__233,unk__234,unk__235]> ⬅️ ::Mul(%\"val_749\", %\"val_84\"{[0.3535533845424652]})\n",
       "            435 |  # node_MatMul_716\n",
       "                   %\"val_754\"<FLOAT,[unk__232,12,s41,unk__235]> ⬅️ ::MatMul(%\"val_751\", %\"val_753\")\n",
       "            436 |  # node_Add_717\n",
       "                   %\"val_755\"<FLOAT,[unk__232,12,s41,unk__236]> ⬅️ ::Add(%\"val_754\", %\"masked_fill\")\n",
       "            437 |  # node_Softmax_718\n",
       "                   %\"val_756\"<FLOAT,[unk__232,12,s41,unk__236]> ⬅️ ::Softmax(%\"val_755\") {axis=-1}\n",
       "            438 |  # node_scaled_dot_product_attention_9\n",
       "                   %\"scaled_dot_product_attention_9\"<FLOAT,[1,12,s41,64]> ⬅️ ::MatMul(%\"val_756\", %\"transpose_38\")\n",
       "            439 |  # node_transpose_39\n",
       "                   %\"transpose_39\"<FLOAT,[1,s41,12,64]> ⬅️ ::Transpose(%\"scaled_dot_product_attention_9\") {perm=(0, 2, 1, 3)}\n",
       "            440 |  # node_view_39\n",
       "                   %\"view_39\"<FLOAT,[1,s41,768]> ⬅️ ::Reshape(%\"transpose_39\", %\"val_95\") {allowzero=1}\n",
       "            441 |  # node_MatMul_725\n",
       "                   %\"val_763\"<FLOAT,[1,s41,768]> ⬅️ ::MatMul(%\"view_39\", %\"val_762\"{...})\n",
       "            442 |  # node_linear_57\n",
       "                   %\"linear_57\"<FLOAT,[1,s41,768]> ⬅️ ::Add(%\"val_763\", %\"bert.encoder.layer.9.attention.output.dense.bias\"{...})\n",
       "            443 |  # node_add_745\n",
       "                   %\"add_745\"<FLOAT,[1,s41,768]> ⬅️ ::Add(%\"linear_57\", %\"layer_norm_18\")\n",
       "            444 |  # node_layer_norm_19\n",
       "                   %\"layer_norm_19\"<FLOAT,[1,s41,768]>, %\"\"<FLOAT,[1,s41,1]>, %\"\"<FLOAT,[1,s41,1]> ⬅️ ::LayerNormalization(%\"add_745\", %\"bert.encoder.layer.9.attention.output.LayerNorm.weight\"{...}, %\"bert.encoder.layer.9.attention.output.LayerNorm.bias\"{...}) {axis=-1, epsilon=9.999999960041972e-13, stash_type=1}\n",
       "            445 |  # node_MatMul_727\n",
       "                   %\"val_767\"<FLOAT,[1,s41,3072]> ⬅️ ::MatMul(%\"layer_norm_19\", %\"val_766\"{...})\n",
       "            446 |  # node_linear_58\n",
       "                   %\"linear_58\"<FLOAT,[1,s41,3072]> ⬅️ ::Add(%\"val_767\", %\"bert.encoder.layer.9.intermediate.dense.bias\"{...})\n",
       "            447 |  # node_Div_729\n",
       "                   %\"val_769\"<FLOAT,[1,s41,3072]> ⬅️ ::Div(%\"linear_58\", %\"val_102\"{1.4142135381698608})\n",
       "            448 |  # node_Erf_730\n",
       "                   %\"val_770\"<FLOAT,[1,s41,3072]> ⬅️ ::Erf(%\"val_769\")\n",
       "            449 |  # node_Add_732\n",
       "                   %\"val_772\"<FLOAT,[1,s41,3072]> ⬅️ ::Add(%\"val_770\", %\"clone_1\"{1.0})\n",
       "            450 |  # node_Mul_734\n",
       "                   %\"val_774\"<FLOAT,[1,s41,3072]> ⬅️ ::Mul(%\"val_107\"{0.5}, %\"val_772\")\n",
       "            451 |  # node_gelu_9\n",
       "                   %\"gelu_9\"<FLOAT,[1,s41,3072]> ⬅️ ::Mul(%\"linear_58\", %\"val_774\")\n",
       "            452 |  # node_MatMul_736\n",
       "                   %\"val_776\"<FLOAT,[1,s41,768]> ⬅️ ::MatMul(%\"gelu_9\", %\"val_775\"{...})\n",
       "            453 |  # node_linear_59\n",
       "                   %\"linear_59\"<FLOAT,[1,s41,768]> ⬅️ ::Add(%\"val_776\", %\"bert.encoder.layer.9.output.dense.bias\"{...})\n",
       "            454 |  # node_add_764\n",
       "                   %\"add_764\"<FLOAT,[1,s41,768]> ⬅️ ::Add(%\"linear_59\", %\"layer_norm_19\")\n",
       "            455 |  # node_layer_norm_20\n",
       "                   %\"layer_norm_20\"<FLOAT,[1,s41,768]>, %\"\"<FLOAT,[1,s41,1]>, %\"\"<FLOAT,[1,s41,1]> ⬅️ ::LayerNormalization(%\"add_764\", %\"bert.encoder.layer.9.output.LayerNorm.weight\"{...}, %\"bert.encoder.layer.9.output.LayerNorm.bias\"{...}) {axis=-1, epsilon=9.999999960041972e-13, stash_type=1}\n",
       "            456 |  # node_MatMul_738\n",
       "                   %\"val_780\"<FLOAT,[1,s41,768]> ⬅️ ::MatMul(%\"layer_norm_20\", %\"val_779\"{...})\n",
       "            457 |  # node_linear_60\n",
       "                   %\"linear_60\"<FLOAT,[1,s41,768]> ⬅️ ::Add(%\"val_780\", %\"bert.encoder.layer.10.attention.self.query.bias\"{...})\n",
       "            458 |  # node_view_40\n",
       "                   %\"view_40\"<FLOAT,[1,s41,12,64]> ⬅️ ::Reshape(%\"linear_60\", %\"val_44\"{[1, -1, 12, 64]}) {allowzero=1}\n",
       "            459 |  # node_transpose_40\n",
       "                   %\"transpose_40\"<FLOAT,[1,12,s41,64]> ⬅️ ::Transpose(%\"view_40\") {perm=(0, 2, 1, 3)}\n",
       "            460 |  # node_MatMul_746\n",
       "                   %\"val_788\"<FLOAT,[1,s41,768]> ⬅️ ::MatMul(%\"layer_norm_20\", %\"val_787\"{...})\n",
       "            461 |  # node_linear_61\n",
       "                   %\"linear_61\"<FLOAT,[1,s41,768]> ⬅️ ::Add(%\"val_788\", %\"bert.encoder.layer.10.attention.self.key.bias\"{...})\n",
       "            462 |  # node_view_41\n",
       "                   %\"view_41\"<FLOAT,[1,s41,12,64]> ⬅️ ::Reshape(%\"linear_61\", %\"val_44\"{[1, -1, 12, 64]}) {allowzero=1}\n",
       "            463 |  # node_transpose_41\n",
       "                   %\"transpose_41\"<FLOAT,[1,12,s41,64]> ⬅️ ::Transpose(%\"view_41\") {perm=(0, 2, 1, 3)}\n",
       "            464 |  # node_MatMul_754\n",
       "                   %\"val_796\"<FLOAT,[1,s41,768]> ⬅️ ::MatMul(%\"layer_norm_20\", %\"val_795\"{...})\n",
       "            465 |  # node_linear_62\n",
       "                   %\"linear_62\"<FLOAT,[1,s41,768]> ⬅️ ::Add(%\"val_796\", %\"bert.encoder.layer.10.attention.self.value.bias\"{...})\n",
       "            466 |  # node_view_42\n",
       "                   %\"view_42\"<FLOAT,[1,s41,12,64]> ⬅️ ::Reshape(%\"linear_62\", %\"val_44\"{[1, -1, 12, 64]}) {allowzero=1}\n",
       "            467 |  # node_transpose_42\n",
       "                   %\"transpose_42\"<FLOAT,[1,12,s41,64]> ⬅️ ::Transpose(%\"view_42\") {perm=(0, 2, 1, 3)}\n",
       "            468 |  # node_Shape_770\n",
       "                   %\"val_812\"<INT64,[4]> ⬅️ ::Shape(%\"transpose_41\") {start=0}\n",
       "            469 |  # node_Slice_772\n",
       "                   %\"val_814\"<INT64,[1]> ⬅️ ::Slice(%\"val_812\", %\"val_72\"{[-1]}, %\"val_71\"{[9223372036854775807]})\n",
       "            470 |  # node_Slice_773\n",
       "                   %\"val_815\"<INT64,[1]> ⬅️ ::Slice(%\"val_812\", %\"val_74\"{[-2]}, %\"val_72\"{[-1]})\n",
       "            471 |  # node_Slice_775\n",
       "                   %\"val_817\"<INT64,[2]> ⬅️ ::Slice(%\"val_812\", %\"val_76\"{[-9223372036854775808]}, %\"val_74\"{[-2]})\n",
       "            472 |  # node_Concat_777\n",
       "                   %\"val_819\"<INT64,[3]> ⬅️ ::Concat(%\"val_72\"{[-1]}, %\"val_815\", %\"val_814\") {axis=0}\n",
       "            473 |  # node_Reshape_778\n",
       "                   %\"val_820\"<FLOAT,[unk__252,unk__253,unk__254]> ⬅️ ::Reshape(%\"transpose_41\", %\"val_819\") {allowzero=0}\n",
       "            474 |  # node_Transpose_779\n",
       "                   %\"val_821\"<FLOAT,[unk__252,unk__254,unk__253]> ⬅️ ::Transpose(%\"val_820\") {perm=(0, 2, 1)}\n",
       "            475 |  # node_Concat_780\n",
       "                   %\"val_822\"<INT64,[4]> ⬅️ ::Concat(%\"val_817\", %\"val_814\", %\"val_815\") {axis=0}\n",
       "            476 |  # node_Reshape_781\n",
       "                   %\"val_823\"<FLOAT,[unk__255,unk__256,unk__257,unk__258]> ⬅️ ::Reshape(%\"val_821\", %\"val_822\") {allowzero=0}\n",
       "            477 |  # node_Mul_783\n",
       "                   %\"val_825\"<FLOAT,[1,12,s41,64]> ⬅️ ::Mul(%\"transpose_40\", %\"val_84\"{[0.3535533845424652]})\n",
       "            478 |  # node_Mul_785\n",
       "                   %\"val_827\"<FLOAT,[unk__255,unk__256,unk__257,unk__258]> ⬅️ ::Mul(%\"val_823\", %\"val_84\"{[0.3535533845424652]})\n",
       "            479 |  # node_MatMul_786\n",
       "                   %\"val_828\"<FLOAT,[unk__255,12,s41,unk__258]> ⬅️ ::MatMul(%\"val_825\", %\"val_827\")\n",
       "            480 |  # node_Add_787\n",
       "                   %\"val_829\"<FLOAT,[unk__255,12,s41,unk__259]> ⬅️ ::Add(%\"val_828\", %\"masked_fill\")\n",
       "            481 |  # node_Softmax_788\n",
       "                   %\"val_830\"<FLOAT,[unk__255,12,s41,unk__259]> ⬅️ ::Softmax(%\"val_829\") {axis=-1}\n",
       "            482 |  # node_scaled_dot_product_attention_10\n",
       "                   %\"scaled_dot_product_attention_10\"<FLOAT,[1,12,s41,64]> ⬅️ ::MatMul(%\"val_830\", %\"transpose_42\")\n",
       "            483 |  # node_transpose_43\n",
       "                   %\"transpose_43\"<FLOAT,[1,s41,12,64]> ⬅️ ::Transpose(%\"scaled_dot_product_attention_10\") {perm=(0, 2, 1, 3)}\n",
       "            484 |  # node_view_43\n",
       "                   %\"view_43\"<FLOAT,[1,s41,768]> ⬅️ ::Reshape(%\"transpose_43\", %\"val_95\") {allowzero=1}\n",
       "            485 |  # node_MatMul_795\n",
       "                   %\"val_837\"<FLOAT,[1,s41,768]> ⬅️ ::MatMul(%\"view_43\", %\"val_836\"{...})\n",
       "            486 |  # node_linear_63\n",
       "                   %\"linear_63\"<FLOAT,[1,s41,768]> ⬅️ ::Add(%\"val_837\", %\"bert.encoder.layer.10.attention.output.dense.bias\"{...})\n",
       "            487 |  # node_add_817\n",
       "                   %\"add_817\"<FLOAT,[1,s41,768]> ⬅️ ::Add(%\"linear_63\", %\"layer_norm_20\")\n",
       "            488 |  # node_layer_norm_21\n",
       "                   %\"layer_norm_21\"<FLOAT,[1,s41,768]>, %\"\"<FLOAT,[1,s41,1]>, %\"\"<FLOAT,[1,s41,1]> ⬅️ ::LayerNormalization(%\"add_817\", %\"bert.encoder.layer.10.attention.output.LayerNorm.weight\"{...}, %\"bert.encoder.layer.10.attention.output.LayerNorm.bias\"{...}) {axis=-1, epsilon=9.999999960041972e-13, stash_type=1}\n",
       "            489 |  # node_MatMul_797\n",
       "                   %\"val_841\"<FLOAT,[1,s41,3072]> ⬅️ ::MatMul(%\"layer_norm_21\", %\"val_840\"{...})\n",
       "            490 |  # node_linear_64\n",
       "                   %\"linear_64\"<FLOAT,[1,s41,3072]> ⬅️ ::Add(%\"val_841\", %\"bert.encoder.layer.10.intermediate.dense.bias\"{...})\n",
       "            491 |  # node_Div_799\n",
       "                   %\"val_843\"<FLOAT,[1,s41,3072]> ⬅️ ::Div(%\"linear_64\", %\"val_102\"{1.4142135381698608})\n",
       "            492 |  # node_Erf_800\n",
       "                   %\"val_844\"<FLOAT,[1,s41,3072]> ⬅️ ::Erf(%\"val_843\")\n",
       "            493 |  # node_Add_802\n",
       "                   %\"val_846\"<FLOAT,[1,s41,3072]> ⬅️ ::Add(%\"val_844\", %\"clone_1\"{1.0})\n",
       "            494 |  # node_Mul_804\n",
       "                   %\"val_848\"<FLOAT,[1,s41,3072]> ⬅️ ::Mul(%\"val_107\"{0.5}, %\"val_846\")\n",
       "            495 |  # node_gelu_10\n",
       "                   %\"gelu_10\"<FLOAT,[1,s41,3072]> ⬅️ ::Mul(%\"linear_64\", %\"val_848\")\n",
       "            496 |  # node_MatMul_806\n",
       "                   %\"val_850\"<FLOAT,[1,s41,768]> ⬅️ ::MatMul(%\"gelu_10\", %\"val_849\"{...})\n",
       "            497 |  # node_linear_65\n",
       "                   %\"linear_65\"<FLOAT,[1,s41,768]> ⬅️ ::Add(%\"val_850\", %\"bert.encoder.layer.10.output.dense.bias\"{...})\n",
       "            498 |  # node_add_836\n",
       "                   %\"add_836\"<FLOAT,[1,s41,768]> ⬅️ ::Add(%\"linear_65\", %\"layer_norm_21\")\n",
       "            499 |  # node_layer_norm_22\n",
       "                   %\"layer_norm_22\"<FLOAT,[1,s41,768]>, %\"\"<FLOAT,[1,s41,1]>, %\"\"<FLOAT,[1,s41,1]> ⬅️ ::LayerNormalization(%\"add_836\", %\"bert.encoder.layer.10.output.LayerNorm.weight\"{...}, %\"bert.encoder.layer.10.output.LayerNorm.bias\"{...}) {axis=-1, epsilon=9.999999960041972e-13, stash_type=1}\n",
       "            500 |  # node_MatMul_808\n",
       "                   %\"val_854\"<FLOAT,[1,s41,768]> ⬅️ ::MatMul(%\"layer_norm_22\", %\"val_853\"{...})\n",
       "            501 |  # node_linear_66\n",
       "                   %\"linear_66\"<FLOAT,[1,s41,768]> ⬅️ ::Add(%\"val_854\", %\"bert.encoder.layer.11.attention.self.query.bias\"{...})\n",
       "            502 |  # node_view_44\n",
       "                   %\"view_44\"<FLOAT,[1,s41,12,64]> ⬅️ ::Reshape(%\"linear_66\", %\"val_44\"{[1, -1, 12, 64]}) {allowzero=1}\n",
       "            503 |  # node_transpose_44\n",
       "                   %\"transpose_44\"<FLOAT,[1,12,s41,64]> ⬅️ ::Transpose(%\"view_44\") {perm=(0, 2, 1, 3)}\n",
       "            504 |  # node_MatMul_816\n",
       "                   %\"val_862\"<FLOAT,[1,s41,768]> ⬅️ ::MatMul(%\"layer_norm_22\", %\"val_861\"{...})\n",
       "            505 |  # node_linear_67\n",
       "                   %\"linear_67\"<FLOAT,[1,s41,768]> ⬅️ ::Add(%\"val_862\", %\"bert.encoder.layer.11.attention.self.key.bias\"{...})\n",
       "            506 |  # node_view_45\n",
       "                   %\"view_45\"<FLOAT,[1,s41,12,64]> ⬅️ ::Reshape(%\"linear_67\", %\"val_44\"{[1, -1, 12, 64]}) {allowzero=1}\n",
       "            507 |  # node_transpose_45\n",
       "                   %\"transpose_45\"<FLOAT,[1,12,s41,64]> ⬅️ ::Transpose(%\"view_45\") {perm=(0, 2, 1, 3)}\n",
       "            508 |  # node_MatMul_824\n",
       "                   %\"val_870\"<FLOAT,[1,s41,768]> ⬅️ ::MatMul(%\"layer_norm_22\", %\"val_869\"{...})\n",
       "            509 |  # node_linear_68\n",
       "                   %\"linear_68\"<FLOAT,[1,s41,768]> ⬅️ ::Add(%\"val_870\", %\"bert.encoder.layer.11.attention.self.value.bias\"{...})\n",
       "            510 |  # node_view_46\n",
       "                   %\"view_46\"<FLOAT,[1,s41,12,64]> ⬅️ ::Reshape(%\"linear_68\", %\"val_44\"{[1, -1, 12, 64]}) {allowzero=1}\n",
       "            511 |  # node_transpose_46\n",
       "                   %\"transpose_46\"<FLOAT,[1,12,s41,64]> ⬅️ ::Transpose(%\"view_46\") {perm=(0, 2, 1, 3)}\n",
       "            512 |  # node_Shape_840\n",
       "                   %\"val_886\"<INT64,[4]> ⬅️ ::Shape(%\"transpose_45\") {start=0}\n",
       "            513 |  # node_Slice_842\n",
       "                   %\"val_888\"<INT64,[1]> ⬅️ ::Slice(%\"val_886\", %\"val_72\"{[-1]}, %\"val_71\"{[9223372036854775807]})\n",
       "            514 |  # node_Slice_843\n",
       "                   %\"val_889\"<INT64,[1]> ⬅️ ::Slice(%\"val_886\", %\"val_74\"{[-2]}, %\"val_72\"{[-1]})\n",
       "            515 |  # node_Slice_845\n",
       "                   %\"val_891\"<INT64,[2]> ⬅️ ::Slice(%\"val_886\", %\"val_76\"{[-9223372036854775808]}, %\"val_74\"{[-2]})\n",
       "            516 |  # node_Concat_847\n",
       "                   %\"val_893\"<INT64,[3]> ⬅️ ::Concat(%\"val_72\"{[-1]}, %\"val_889\", %\"val_888\") {axis=0}\n",
       "            517 |  # node_Reshape_848\n",
       "                   %\"val_894\"<FLOAT,[unk__275,unk__276,unk__277]> ⬅️ ::Reshape(%\"transpose_45\", %\"val_893\") {allowzero=0}\n",
       "            518 |  # node_Transpose_849\n",
       "                   %\"val_895\"<FLOAT,[unk__275,unk__277,unk__276]> ⬅️ ::Transpose(%\"val_894\") {perm=(0, 2, 1)}\n",
       "            519 |  # node_Concat_850\n",
       "                   %\"val_896\"<INT64,[4]> ⬅️ ::Concat(%\"val_891\", %\"val_888\", %\"val_889\") {axis=0}\n",
       "            520 |  # node_Reshape_851\n",
       "                   %\"val_897\"<FLOAT,[unk__278,unk__279,unk__280,unk__281]> ⬅️ ::Reshape(%\"val_895\", %\"val_896\") {allowzero=0}\n",
       "            521 |  # node_Mul_853\n",
       "                   %\"val_899\"<FLOAT,[1,12,s41,64]> ⬅️ ::Mul(%\"transpose_44\", %\"val_84\"{[0.3535533845424652]})\n",
       "            522 |  # node_Mul_855\n",
       "                   %\"val_901\"<FLOAT,[unk__278,unk__279,unk__280,unk__281]> ⬅️ ::Mul(%\"val_897\", %\"val_84\"{[0.3535533845424652]})\n",
       "            523 |  # node_MatMul_856\n",
       "                   %\"val_902\"<FLOAT,[unk__278,12,s41,unk__281]> ⬅️ ::MatMul(%\"val_899\", %\"val_901\")\n",
       "            524 |  # node_Add_857\n",
       "                   %\"val_903\"<FLOAT,[unk__278,12,s41,unk__282]> ⬅️ ::Add(%\"val_902\", %\"masked_fill\")\n",
       "            525 |  # node_Softmax_858\n",
       "                   %\"val_904\"<FLOAT,[unk__278,12,s41,unk__282]> ⬅️ ::Softmax(%\"val_903\") {axis=-1}\n",
       "            526 |  # node_scaled_dot_product_attention_11\n",
       "                   %\"scaled_dot_product_attention_11\"<FLOAT,[1,12,s41,64]> ⬅️ ::MatMul(%\"val_904\", %\"transpose_46\")\n",
       "            527 |  # node_transpose_47\n",
       "                   %\"transpose_47\"<FLOAT,[1,s41,12,64]> ⬅️ ::Transpose(%\"scaled_dot_product_attention_11\") {perm=(0, 2, 1, 3)}\n",
       "            528 |  # node_view_47\n",
       "                   %\"view_47\"<FLOAT,[1,s41,768]> ⬅️ ::Reshape(%\"transpose_47\", %\"val_95\") {allowzero=1}\n",
       "            529 |  # node_MatMul_865\n",
       "                   %\"val_911\"<FLOAT,[1,s41,768]> ⬅️ ::MatMul(%\"view_47\", %\"val_910\"{...})\n",
       "            530 |  # node_linear_69\n",
       "                   %\"linear_69\"<FLOAT,[1,s41,768]> ⬅️ ::Add(%\"val_911\", %\"bert.encoder.layer.11.attention.output.dense.bias\"{...})\n",
       "            531 |  # node_add_889\n",
       "                   %\"add_889\"<FLOAT,[1,s41,768]> ⬅️ ::Add(%\"linear_69\", %\"layer_norm_22\")\n",
       "            532 |  # node_layer_norm_23\n",
       "                   %\"layer_norm_23\"<FLOAT,[1,s41,768]>, %\"\"<FLOAT,[1,s41,1]>, %\"\"<FLOAT,[1,s41,1]> ⬅️ ::LayerNormalization(%\"add_889\", %\"bert.encoder.layer.11.attention.output.LayerNorm.weight\"{...}, %\"bert.encoder.layer.11.attention.output.LayerNorm.bias\"{...}) {axis=-1, epsilon=9.999999960041972e-13, stash_type=1}\n",
       "            533 |  # node_MatMul_867\n",
       "                   %\"val_915\"<FLOAT,[1,s41,3072]> ⬅️ ::MatMul(%\"layer_norm_23\", %\"val_914\"{...})\n",
       "            534 |  # node_linear_70\n",
       "                   %\"linear_70\"<FLOAT,[1,s41,3072]> ⬅️ ::Add(%\"val_915\", %\"bert.encoder.layer.11.intermediate.dense.bias\"{...})\n",
       "            535 |  # node_Div_869\n",
       "                   %\"val_917\"<FLOAT,[1,s41,3072]> ⬅️ ::Div(%\"linear_70\", %\"val_102\"{1.4142135381698608})\n",
       "            536 |  # node_Erf_870\n",
       "                   %\"val_918\"<FLOAT,[1,s41,3072]> ⬅️ ::Erf(%\"val_917\")\n",
       "            537 |  # node_Add_872\n",
       "                   %\"val_920\"<FLOAT,[1,s41,3072]> ⬅️ ::Add(%\"val_918\", %\"clone_1\"{1.0})\n",
       "            538 |  # node_Mul_874\n",
       "                   %\"val_922\"<FLOAT,[1,s41,3072]> ⬅️ ::Mul(%\"val_107\"{0.5}, %\"val_920\")\n",
       "            539 |  # node_gelu_11\n",
       "                   %\"gelu_11\"<FLOAT,[1,s41,3072]> ⬅️ ::Mul(%\"linear_70\", %\"val_922\")\n",
       "            540 |  # node_MatMul_876\n",
       "                   %\"val_924\"<FLOAT,[1,s41,768]> ⬅️ ::MatMul(%\"gelu_11\", %\"val_923\"{...})\n",
       "            541 |  # node_linear_71\n",
       "                   %\"linear_71\"<FLOAT,[1,s41,768]> ⬅️ ::Add(%\"val_924\", %\"bert.encoder.layer.11.output.dense.bias\"{...})\n",
       "            542 |  # node_add_908\n",
       "                   %\"add_908\"<FLOAT,[1,s41,768]> ⬅️ ::Add(%\"linear_71\", %\"layer_norm_23\")\n",
       "            543 |  # node_layer_norm_24\n",
       "                   %\"layer_norm_24\"<FLOAT,[1,s41,768]>, %\"\"<FLOAT,[1,s41,1]>, %\"\"<FLOAT,[1,s41,1]> ⬅️ ::LayerNormalization(%\"add_908\", %\"bert.encoder.layer.11.output.LayerNorm.weight\"{...}, %\"bert.encoder.layer.11.output.LayerNorm.bias\"{...}) {axis=-1, epsilon=9.999999960041972e-13, stash_type=1}\n",
       "            544 |  # node_select\n",
       "                   %\"select\"<FLOAT,[1,768]> ⬅️ ::Gather(%\"layer_norm_24\", %\"val_1\"{0}) {axis=1}\n",
       "            545 |  # node_linear_72\n",
       "                   %\"linear_72\"<FLOAT,[1,768]> ⬅️ ::Gemm(%\"select\", %\"bert.pooler.dense.weight\"{...}, %\"bert.pooler.dense.bias\"{...}) {transA=0, transB=1, alpha=1.0, beta=1.0}\n",
       "            546 |  # node_tanh\n",
       "                   %\"tanh\"<FLOAT,[1,768]> ⬅️ ::Tanh(%\"linear_72\")\n",
       "            547 |  # node_linear_73\n",
       "                   %\"logits\"<FLOAT,[1,2]> ⬅️ ::Gemm(%\"tanh\", %\"classifier.weight\"{...}, %\"classifier.bias\"{[0.0010369560914114118, -0.0010363702895119786]}) {transA=0, transB=1, alpha=1.0, beta=1.0}\n",
       "            return %\"logits\"<FLOAT,[1,2]>\n",
       "        }\n",
       "\n",
       "\n",
       "    ,\n",
       "    exported_program=\n",
       "        ExportedProgram:\n",
       "            class GraphModule(torch.nn.Module):\n",
       "                def forward(self, p_bert_embeddings_word_embeddings_weight: \"f32[30522, 768]\", p_bert_embeddings_position_embeddings_weight: \"f32[512, 768]\", p_bert_embeddings_token_type_embeddings_weight: \"f32[2, 768]\", p_bert_embeddings_layernorm_weight: \"f32[768]\", p_bert_embeddings_layernorm_bias: \"f32[768]\", p_bert_encoder_layer_0_attention_self_query_weight: \"f32[768, 768]\", p_bert_encoder_layer_0_attention_self_query_bias: \"f32[768]\", p_bert_encoder_layer_0_attention_self_key_weight: \"f32[768, 768]\", p_bert_encoder_layer_0_attention_self_key_bias: \"f32[768]\", p_bert_encoder_layer_0_attention_self_value_weight: \"f32[768, 768]\", p_bert_encoder_layer_0_attention_self_value_bias: \"f32[768]\", p_bert_encoder_layer_0_attention_output_dense_weight: \"f32[768, 768]\", p_bert_encoder_layer_0_attention_output_dense_bias: \"f32[768]\", p_bert_encoder_layer_0_attention_output_layernorm_weight: \"f32[768]\", p_bert_encoder_layer_0_attention_output_layernorm_bias: \"f32[768]\", p_bert_encoder_layer_0_intermediate_dense_weight: \"f32[3072, 768]\", p_bert_encoder_layer_0_intermediate_dense_bias: \"f32[3072]\", p_bert_encoder_layer_0_output_dense_weight: \"f32[768, 3072]\", p_bert_encoder_layer_0_output_dense_bias: \"f32[768]\", p_bert_encoder_layer_0_output_layernorm_weight: \"f32[768]\", p_bert_encoder_layer_0_output_layernorm_bias: \"f32[768]\", p_bert_encoder_layer_1_attention_self_query_weight: \"f32[768, 768]\", p_bert_encoder_layer_1_attention_self_query_bias: \"f32[768]\", p_bert_encoder_layer_1_attention_self_key_weight: \"f32[768, 768]\", p_bert_encoder_layer_1_attention_self_key_bias: \"f32[768]\", p_bert_encoder_layer_1_attention_self_value_weight: \"f32[768, 768]\", p_bert_encoder_layer_1_attention_self_value_bias: \"f32[768]\", p_bert_encoder_layer_1_attention_output_dense_weight: \"f32[768, 768]\", p_bert_encoder_layer_1_attention_output_dense_bias: \"f32[768]\", p_bert_encoder_layer_1_attention_output_layernorm_weight: \"f32[768]\", p_bert_encoder_layer_1_attention_output_layernorm_bias: \"f32[768]\", p_bert_encoder_layer_1_intermediate_dense_weight: \"f32[3072, 768]\", p_bert_encoder_layer_1_intermediate_dense_bias: \"f32[3072]\", p_bert_encoder_layer_1_output_dense_weight: \"f32[768, 3072]\", p_bert_encoder_layer_1_output_dense_bias: \"f32[768]\", p_bert_encoder_layer_1_output_layernorm_weight: \"f32[768]\", p_bert_encoder_layer_1_output_layernorm_bias: \"f32[768]\", p_bert_encoder_layer_2_attention_self_query_weight: \"f32[768, 768]\", p_bert_encoder_layer_2_attention_self_query_bias: \"f32[768]\", p_bert_encoder_layer_2_attention_self_key_weight: \"f32[768, 768]\", p_bert_encoder_layer_2_attention_self_key_bias: \"f32[768]\", p_bert_encoder_layer_2_attention_self_value_weight: \"f32[768, 768]\", p_bert_encoder_layer_2_attention_self_value_bias: \"f32[768]\", p_bert_encoder_layer_2_attention_output_dense_weight: \"f32[768, 768]\", p_bert_encoder_layer_2_attention_output_dense_bias: \"f32[768]\", p_bert_encoder_layer_2_attention_output_layernorm_weight: \"f32[768]\", p_bert_encoder_layer_2_attention_output_layernorm_bias: \"f32[768]\", p_bert_encoder_layer_2_intermediate_dense_weight: \"f32[3072, 768]\", p_bert_encoder_layer_2_intermediate_dense_bias: \"f32[3072]\", p_bert_encoder_layer_2_output_dense_weight: \"f32[768, 3072]\", p_bert_encoder_layer_2_output_dense_bias: \"f32[768]\", p_bert_encoder_layer_2_output_layernorm_weight: \"f32[768]\", p_bert_encoder_layer_2_output_layernorm_bias: \"f32[768]\", p_bert_encoder_layer_3_attention_self_query_weight: \"f32[768, 768]\", p_bert_encoder_layer_3_attention_self_query_bias: \"f32[768]\", p_bert_encoder_layer_3_attention_self_key_weight: \"f32[768, 768]\", p_bert_encoder_layer_3_attention_self_key_bias: \"f32[768]\", p_bert_encoder_layer_3_attention_self_value_weight: \"f32[768, 768]\", p_bert_encoder_layer_3_attention_self_value_bias: \"f32[768]\", p_bert_encoder_layer_3_attention_output_dense_weight: \"f32[768, 768]\", p_bert_encoder_layer_3_attention_output_dense_bias: \"f32[768]\", p_bert_encoder_layer_3_attention_output_layernorm_weight: \"f32[768]\", p_bert_encoder_layer_3_attention_output_layernorm_bias: \"f32[768]\", p_bert_encoder_layer_3_intermediate_dense_weight: \"f32[3072, 768]\", p_bert_encoder_layer_3_intermediate_dense_bias: \"f32[3072]\", p_bert_encoder_layer_3_output_dense_weight: \"f32[768, 3072]\", p_bert_encoder_layer_3_output_dense_bias: \"f32[768]\", p_bert_encoder_layer_3_output_layernorm_weight: \"f32[768]\", p_bert_encoder_layer_3_output_layernorm_bias: \"f32[768]\", p_bert_encoder_layer_4_attention_self_query_weight: \"f32[768, 768]\", p_bert_encoder_layer_4_attention_self_query_bias: \"f32[768]\", p_bert_encoder_layer_4_attention_self_key_weight: \"f32[768, 768]\", p_bert_encoder_layer_4_attention_self_key_bias: \"f32[768]\", p_bert_encoder_layer_4_attention_self_value_weight: \"f32[768, 768]\", p_bert_encoder_layer_4_attention_self_value_bias: \"f32[768]\", p_bert_encoder_layer_4_attention_output_dense_weight: \"f32[768, 768]\", p_bert_encoder_layer_4_attention_output_dense_bias: \"f32[768]\", p_bert_encoder_layer_4_attention_output_layernorm_weight: \"f32[768]\", p_bert_encoder_layer_4_attention_output_layernorm_bias: \"f32[768]\", p_bert_encoder_layer_4_intermediate_dense_weight: \"f32[3072, 768]\", p_bert_encoder_layer_4_intermediate_dense_bias: \"f32[3072]\", p_bert_encoder_layer_4_output_dense_weight: \"f32[768, 3072]\", p_bert_encoder_layer_4_output_dense_bias: \"f32[768]\", p_bert_encoder_layer_4_output_layernorm_weight: \"f32[768]\", p_bert_encoder_layer_4_output_layernorm_bias: \"f32[768]\", p_bert_encoder_layer_5_attention_self_query_weight: \"f32[768, 768]\", p_bert_encoder_layer_5_attention_self_query_bias: \"f32[768]\", p_bert_encoder_layer_5_attention_self_key_weight: \"f32[768, 768]\", p_bert_encoder_layer_5_attention_self_key_bias: \"f32[768]\", p_bert_encoder_layer_5_attention_self_value_weight: \"f32[768, 768]\", p_bert_encoder_layer_5_attention_self_value_bias: \"f32[768]\", p_bert_encoder_layer_5_attention_output_dense_weight: \"f32[768, 768]\", p_bert_encoder_layer_5_attention_output_dense_bias: \"f32[768]\", p_bert_encoder_layer_5_attention_output_layernorm_weight: \"f32[768]\", p_bert_encoder_layer_5_attention_output_layernorm_bias: \"f32[768]\", p_bert_encoder_layer_5_intermediate_dense_weight: \"f32[3072, 768]\", p_bert_encoder_layer_5_intermediate_dense_bias: \"f32[3072]\", p_bert_encoder_layer_5_output_dense_weight: \"f32[768, 3072]\", p_bert_encoder_layer_5_output_dense_bias: \"f32[768]\", p_bert_encoder_layer_5_output_layernorm_weight: \"f32[768]\", p_bert_encoder_layer_5_output_layernorm_bias: \"f32[768]\", p_bert_encoder_layer_6_attention_self_query_weight: \"f32[768, 768]\", p_bert_encoder_layer_6_attention_self_query_bias: \"f32[768]\", p_bert_encoder_layer_6_attention_self_key_weight: \"f32[768, 768]\", p_bert_encoder_layer_6_attention_self_key_bias: \"f32[768]\", p_bert_encoder_layer_6_attention_self_value_weight: \"f32[768, 768]\", p_bert_encoder_layer_6_attention_self_value_bias: \"f32[768]\", p_bert_encoder_layer_6_attention_output_dense_weight: \"f32[768, 768]\", p_bert_encoder_layer_6_attention_output_dense_bias: \"f32[768]\", p_bert_encoder_layer_6_attention_output_layernorm_weight: \"f32[768]\", p_bert_encoder_layer_6_attention_output_layernorm_bias: \"f32[768]\", p_bert_encoder_layer_6_intermediate_dense_weight: \"f32[3072, 768]\", p_bert_encoder_layer_6_intermediate_dense_bias: \"f32[3072]\", p_bert_encoder_layer_6_output_dense_weight: \"f32[768, 3072]\", p_bert_encoder_layer_6_output_dense_bias: \"f32[768]\", p_bert_encoder_layer_6_output_layernorm_weight: \"f32[768]\", p_bert_encoder_layer_6_output_layernorm_bias: \"f32[768]\", p_bert_encoder_layer_7_attention_self_query_weight: \"f32[768, 768]\", p_bert_encoder_layer_7_attention_self_query_bias: \"f32[768]\", p_bert_encoder_layer_7_attention_self_key_weight: \"f32[768, 768]\", p_bert_encoder_layer_7_attention_self_key_bias: \"f32[768]\", p_bert_encoder_layer_7_attention_self_value_weight: \"f32[768, 768]\", p_bert_encoder_layer_7_attention_self_value_bias: \"f32[768]\", p_bert_encoder_layer_7_attention_output_dense_weight: \"f32[768, 768]\", p_bert_encoder_layer_7_attention_output_dense_bias: \"f32[768]\", p_bert_encoder_layer_7_attention_output_layernorm_weight: \"f32[768]\", p_bert_encoder_layer_7_attention_output_layernorm_bias: \"f32[768]\", p_bert_encoder_layer_7_intermediate_dense_weight: \"f32[3072, 768]\", p_bert_encoder_layer_7_intermediate_dense_bias: \"f32[3072]\", p_bert_encoder_layer_7_output_dense_weight: \"f32[768, 3072]\", p_bert_encoder_layer_7_output_dense_bias: \"f32[768]\", p_bert_encoder_layer_7_output_layernorm_weight: \"f32[768]\", p_bert_encoder_layer_7_output_layernorm_bias: \"f32[768]\", p_bert_encoder_layer_8_attention_self_query_weight: \"f32[768, 768]\", p_bert_encoder_layer_8_attention_self_query_bias: \"f32[768]\", p_bert_encoder_layer_8_attention_self_key_weight: \"f32[768, 768]\", p_bert_encoder_layer_8_attention_self_key_bias: \"f32[768]\", p_bert_encoder_layer_8_attention_self_value_weight: \"f32[768, 768]\", p_bert_encoder_layer_8_attention_self_value_bias: \"f32[768]\", p_bert_encoder_layer_8_attention_output_dense_weight: \"f32[768, 768]\", p_bert_encoder_layer_8_attention_output_dense_bias: \"f32[768]\", p_bert_encoder_layer_8_attention_output_layernorm_weight: \"f32[768]\", p_bert_encoder_layer_8_attention_output_layernorm_bias: \"f32[768]\", p_bert_encoder_layer_8_intermediate_dense_weight: \"f32[3072, 768]\", p_bert_encoder_layer_8_intermediate_dense_bias: \"f32[3072]\", p_bert_encoder_layer_8_output_dense_weight: \"f32[768, 3072]\", p_bert_encoder_layer_8_output_dense_bias: \"f32[768]\", p_bert_encoder_layer_8_output_layernorm_weight: \"f32[768]\", p_bert_encoder_layer_8_output_layernorm_bias: \"f32[768]\", p_bert_encoder_layer_9_attention_self_query_weight: \"f32[768, 768]\", p_bert_encoder_layer_9_attention_self_query_bias: \"f32[768]\", p_bert_encoder_layer_9_attention_self_key_weight: \"f32[768, 768]\", p_bert_encoder_layer_9_attention_self_key_bias: \"f32[768]\", p_bert_encoder_layer_9_attention_self_value_weight: \"f32[768, 768]\", p_bert_encoder_layer_9_attention_self_value_bias: \"f32[768]\", p_bert_encoder_layer_9_attention_output_dense_weight: \"f32[768, 768]\", p_bert_encoder_layer_9_attention_output_dense_bias: \"f32[768]\", p_bert_encoder_layer_9_attention_output_layernorm_weight: \"f32[768]\", p_bert_encoder_layer_9_attention_output_layernorm_bias: \"f32[768]\", p_bert_encoder_layer_9_intermediate_dense_weight: \"f32[3072, 768]\", p_bert_encoder_layer_9_intermediate_dense_bias: \"f32[3072]\", p_bert_encoder_layer_9_output_dense_weight: \"f32[768, 3072]\", p_bert_encoder_layer_9_output_dense_bias: \"f32[768]\", p_bert_encoder_layer_9_output_layernorm_weight: \"f32[768]\", p_bert_encoder_layer_9_output_layernorm_bias: \"f32[768]\", p_bert_encoder_layer_10_attention_self_query_weight: \"f32[768, 768]\", p_bert_encoder_layer_10_attention_self_query_bias: \"f32[768]\", p_bert_encoder_layer_10_attention_self_key_weight: \"f32[768, 768]\", p_bert_encoder_layer_10_attention_self_key_bias: \"f32[768]\", p_bert_encoder_layer_10_attention_self_value_weight: \"f32[768, 768]\", p_bert_encoder_layer_10_attention_self_value_bias: \"f32[768]\", p_bert_encoder_layer_10_attention_output_dense_weight: \"f32[768, 768]\", p_bert_encoder_layer_10_attention_output_dense_bias: \"f32[768]\", p_bert_encoder_layer_10_attention_output_layernorm_weight: \"f32[768]\", p_bert_encoder_layer_10_attention_output_layernorm_bias: \"f32[768]\", p_bert_encoder_layer_10_intermediate_dense_weight: \"f32[3072, 768]\", p_bert_encoder_layer_10_intermediate_dense_bias: \"f32[3072]\", p_bert_encoder_layer_10_output_dense_weight: \"f32[768, 3072]\", p_bert_encoder_layer_10_output_dense_bias: \"f32[768]\", p_bert_encoder_layer_10_output_layernorm_weight: \"f32[768]\", p_bert_encoder_layer_10_output_layernorm_bias: \"f32[768]\", p_bert_encoder_layer_11_attention_self_query_weight: \"f32[768, 768]\", p_bert_encoder_layer_11_attention_self_query_bias: \"f32[768]\", p_bert_encoder_layer_11_attention_self_key_weight: \"f32[768, 768]\", p_bert_encoder_layer_11_attention_self_key_bias: \"f32[768]\", p_bert_encoder_layer_11_attention_self_value_weight: \"f32[768, 768]\", p_bert_encoder_layer_11_attention_self_value_bias: \"f32[768]\", p_bert_encoder_layer_11_attention_output_dense_weight: \"f32[768, 768]\", p_bert_encoder_layer_11_attention_output_dense_bias: \"f32[768]\", p_bert_encoder_layer_11_attention_output_layernorm_weight: \"f32[768]\", p_bert_encoder_layer_11_attention_output_layernorm_bias: \"f32[768]\", p_bert_encoder_layer_11_intermediate_dense_weight: \"f32[3072, 768]\", p_bert_encoder_layer_11_intermediate_dense_bias: \"f32[3072]\", p_bert_encoder_layer_11_output_dense_weight: \"f32[768, 3072]\", p_bert_encoder_layer_11_output_dense_bias: \"f32[768]\", p_bert_encoder_layer_11_output_layernorm_weight: \"f32[768]\", p_bert_encoder_layer_11_output_layernorm_bias: \"f32[768]\", p_bert_pooler_dense_weight: \"f32[768, 768]\", p_bert_pooler_dense_bias: \"f32[768]\", p_classifier_weight: \"f32[2, 768]\", p_classifier_bias: \"f32[2]\", c_bert_lifted_tensor_0: \"f32[]\", b_bert_embeddings_position_ids: \"i64[1, 512]\", b_bert_embeddings_token_type_ids: \"i64[1, 512]\", input_ids: \"i64[1, s41]\", attention_mask: \"i64[1, s41]\", token_type_ids: \"i64[1, s41]\"):\n",
       "                     # \n",
       "                    sym_size_int_79: \"Sym(s41)\" = torch.ops.aten.sym_size.int(token_type_ids, 1)\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:165 in forward, code: position_ids = self.position_ids[:, past_key_values_length : seq_length + past_key_values_length]\n",
       "                    slice_1: \"i64[1, s41]\" = torch.ops.aten.slice.Tensor(b_bert_embeddings_position_ids, 1, 0, sym_size_int_79);  b_bert_embeddings_position_ids = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\sparse.py:192 in forward, code: return F.embedding(\n",
       "                    embedding: \"f32[1, s41, 768]\" = torch.ops.aten.embedding.default(p_bert_embeddings_word_embeddings_weight, input_ids, 0);  p_bert_embeddings_word_embeddings_weight = input_ids = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\sparse.py:192 in forward, code: return F.embedding(\n",
       "                    embedding_1: \"f32[1, s41, 768]\" = torch.ops.aten.embedding.default(p_bert_embeddings_token_type_embeddings_weight, token_type_ids);  p_bert_embeddings_token_type_embeddings_weight = token_type_ids = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:182 in forward, code: embeddings = inputs_embeds + token_type_embeddings\n",
       "                    add_8: \"f32[1, s41, 768]\" = torch.ops.aten.add.Tensor(embedding, embedding_1);  embedding = embedding_1 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\sparse.py:192 in forward, code: return F.embedding(\n",
       "                    embedding_2: \"f32[1, s41, 768]\" = torch.ops.aten.embedding.default(p_bert_embeddings_position_embeddings_weight, slice_1);  p_bert_embeddings_position_embeddings_weight = slice_1 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:185 in forward, code: embeddings += position_embeddings\n",
       "                    add_21: \"f32[1, s41, 768]\" = torch.ops.aten.add.Tensor(add_8, embedding_2);  add_8 = embedding_2 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\normalization.py:229 in forward, code: return F.layer_norm(\n",
       "                    layer_norm: \"f32[1, s41, 768]\" = torch.ops.aten.layer_norm.default(add_21, [768], p_bert_embeddings_layernorm_weight, p_bert_embeddings_layernorm_bias, 1e-12);  add_21 = p_bert_embeddings_layernorm_weight = p_bert_embeddings_layernorm_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\dropout.py:73 in forward, code: return F.dropout(input, self.p, self.training, self.inplace)\n",
       "                    clone: \"f32[1, s41, 768]\" = torch.ops.aten.clone.default(layer_norm);  layer_norm = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:966 in forward, code: extended_attention_mask = _prepare_4d_attention_mask_for_sdpa(\n",
       "                    unsqueeze: \"i64[1, 1, s41]\" = torch.ops.aten.unsqueeze.default(attention_mask, 1);  attention_mask = None\n",
       "                    unsqueeze_1: \"i64[1, 1, 1, s41]\" = torch.ops.aten.unsqueeze.default(unsqueeze, 2);  unsqueeze = None\n",
       "                    slice_2: \"i64[1, 1, 1, s41]\" = torch.ops.aten.slice.Tensor(unsqueeze_1, 3, 0, 9223372036854775807);  unsqueeze_1 = None\n",
       "                    expand: \"i64[1, 1, s41, s41]\" = torch.ops.aten.expand.default(slice_2, [1, 1, sym_size_int_79, sym_size_int_79]);  slice_2 = None\n",
       "                    _to_copy: \"f32[1, 1, s41, s41]\" = torch.ops.aten._to_copy.default(expand, dtype = torch.float32);  expand = None\n",
       "                    clone_1: \"f32[]\" = torch.ops.aten.clone.default(c_bert_lifted_tensor_0);  c_bert_lifted_tensor_0 = None\n",
       "                    sub_17: \"f32[1, 1, s41, s41]\" = torch.ops.aten.sub.Tensor(clone_1, _to_copy);  clone_1 = _to_copy = None\n",
       "                    _to_copy_1: \"b8[1, 1, s41, s41]\" = torch.ops.aten._to_copy.default(sub_17, dtype = torch.bool)\n",
       "                    masked_fill: \"f32[1, 1, s41, s41]\" = torch.ops.aten.masked_fill.Scalar(sub_17, _to_copy_1, -3.4028234663852886e+38);  sub_17 = _to_copy_1 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear: \"f32[1, s41, 768]\" = torch.ops.aten.linear.default(clone, p_bert_encoder_layer_0_attention_self_query_weight, p_bert_encoder_layer_0_attention_self_query_bias);  p_bert_encoder_layer_0_attention_self_query_weight = p_bert_encoder_layer_0_attention_self_query_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:363 in forward, code: self.query(hidden_states).view(bsz, -1, self.num_attention_heads, self.attention_head_size).transpose(1, 2)\n",
       "                    view: \"f32[1, s41, 12, 64]\" = torch.ops.aten.view.default(linear, [1, -1, 12, 64]);  linear = None\n",
       "                    transpose: \"f32[1, 12, s41, 64]\" = torch.ops.aten.transpose.int(view, 1, 2);  view = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_1: \"f32[1, s41, 768]\" = torch.ops.aten.linear.default(clone, p_bert_encoder_layer_0_attention_self_key_weight, p_bert_encoder_layer_0_attention_self_key_bias);  p_bert_encoder_layer_0_attention_self_key_weight = p_bert_encoder_layer_0_attention_self_key_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:388 in forward, code: .view(bsz, -1, self.num_attention_heads, self.attention_head_size)\n",
       "                    view_1: \"f32[1, s41, 12, 64]\" = torch.ops.aten.view.default(linear_1, [1, -1, 12, 64]);  linear_1 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:389 in forward, code: .transpose(1, 2)\n",
       "                    transpose_1: \"f32[1, 12, s41, 64]\" = torch.ops.aten.transpose.int(view_1, 1, 2);  view_1 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_2: \"f32[1, s41, 768]\" = torch.ops.aten.linear.default(clone, p_bert_encoder_layer_0_attention_self_value_weight, p_bert_encoder_layer_0_attention_self_value_bias);  p_bert_encoder_layer_0_attention_self_value_weight = p_bert_encoder_layer_0_attention_self_value_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:393 in forward, code: .view(bsz, -1, self.num_attention_heads, self.attention_head_size)\n",
       "                    view_2: \"f32[1, s41, 12, 64]\" = torch.ops.aten.view.default(linear_2, [1, -1, 12, 64]);  linear_2 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:394 in forward, code: .transpose(1, 2)\n",
       "                    transpose_2: \"f32[1, 12, s41, 64]\" = torch.ops.aten.transpose.int(view_2, 1, 2);  view_2 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:413 in forward, code: attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
       "                    scaled_dot_product_attention: \"f32[1, 12, s41, 64]\" = torch.ops.aten.scaled_dot_product_attention.default(transpose, transpose_1, transpose_2, masked_fill);  transpose = transpose_1 = transpose_2 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:422 in forward, code: attn_output = attn_output.transpose(1, 2)\n",
       "                    transpose_3: \"f32[1, s41, 12, 64]\" = torch.ops.aten.transpose.int(scaled_dot_product_attention, 1, 2);  scaled_dot_product_attention = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:423 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.all_head_size)\n",
       "                    view_3: \"f32[1, s41, 768]\" = torch.ops.aten.view.default(transpose_3, [1, sym_size_int_79, 768]);  transpose_3 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_3: \"f32[1, s41, 768]\" = torch.ops.aten.linear.default(view_3, p_bert_encoder_layer_0_attention_output_dense_weight, p_bert_encoder_layer_0_attention_output_dense_bias);  view_3 = p_bert_encoder_layer_0_attention_output_dense_weight = p_bert_encoder_layer_0_attention_output_dense_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\dropout.py:73 in forward, code: return F.dropout(input, self.p, self.training, self.inplace)\n",
       "                    clone_2: \"f32[1, s41, 768]\" = torch.ops.aten.clone.default(linear_3);  linear_3 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:438 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
       "                    add_97: \"f32[1, s41, 768]\" = torch.ops.aten.add.Tensor(clone_2, clone);  clone_2 = clone = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\normalization.py:229 in forward, code: return F.layer_norm(\n",
       "                    layer_norm_1: \"f32[1, s41, 768]\" = torch.ops.aten.layer_norm.default(add_97, [768], p_bert_encoder_layer_0_attention_output_layernorm_weight, p_bert_encoder_layer_0_attention_output_layernorm_bias, 1e-12);  add_97 = p_bert_encoder_layer_0_attention_output_layernorm_weight = p_bert_encoder_layer_0_attention_output_layernorm_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_4: \"f32[1, s41, 3072]\" = torch.ops.aten.linear.default(layer_norm_1, p_bert_encoder_layer_0_intermediate_dense_weight, p_bert_encoder_layer_0_intermediate_dense_bias);  p_bert_encoder_layer_0_intermediate_dense_weight = p_bert_encoder_layer_0_intermediate_dense_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\activations.py:85 in forward, code: return self.act(input)\n",
       "                    gelu: \"f32[1, s41, 3072]\" = torch.ops.aten.gelu.default(linear_4);  linear_4 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_5: \"f32[1, s41, 768]\" = torch.ops.aten.linear.default(gelu, p_bert_encoder_layer_0_output_dense_weight, p_bert_encoder_layer_0_output_dense_bias);  gelu = p_bert_encoder_layer_0_output_dense_weight = p_bert_encoder_layer_0_output_dense_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\dropout.py:73 in forward, code: return F.dropout(input, self.p, self.training, self.inplace)\n",
       "                    clone_3: \"f32[1, s41, 768]\" = torch.ops.aten.clone.default(linear_5);  linear_5 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:527 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
       "                    add_116: \"f32[1, s41, 768]\" = torch.ops.aten.add.Tensor(clone_3, layer_norm_1);  clone_3 = layer_norm_1 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\normalization.py:229 in forward, code: return F.layer_norm(\n",
       "                    layer_norm_2: \"f32[1, s41, 768]\" = torch.ops.aten.layer_norm.default(add_116, [768], p_bert_encoder_layer_0_output_layernorm_weight, p_bert_encoder_layer_0_output_layernorm_bias, 1e-12);  add_116 = p_bert_encoder_layer_0_output_layernorm_weight = p_bert_encoder_layer_0_output_layernorm_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_6: \"f32[1, s41, 768]\" = torch.ops.aten.linear.default(layer_norm_2, p_bert_encoder_layer_1_attention_self_query_weight, p_bert_encoder_layer_1_attention_self_query_bias);  p_bert_encoder_layer_1_attention_self_query_weight = p_bert_encoder_layer_1_attention_self_query_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:363 in forward, code: self.query(hidden_states).view(bsz, -1, self.num_attention_heads, self.attention_head_size).transpose(1, 2)\n",
       "                    view_4: \"f32[1, s41, 12, 64]\" = torch.ops.aten.view.default(linear_6, [1, -1, 12, 64]);  linear_6 = None\n",
       "                    transpose_4: \"f32[1, 12, s41, 64]\" = torch.ops.aten.transpose.int(view_4, 1, 2);  view_4 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_7: \"f32[1, s41, 768]\" = torch.ops.aten.linear.default(layer_norm_2, p_bert_encoder_layer_1_attention_self_key_weight, p_bert_encoder_layer_1_attention_self_key_bias);  p_bert_encoder_layer_1_attention_self_key_weight = p_bert_encoder_layer_1_attention_self_key_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:388 in forward, code: .view(bsz, -1, self.num_attention_heads, self.attention_head_size)\n",
       "                    view_5: \"f32[1, s41, 12, 64]\" = torch.ops.aten.view.default(linear_7, [1, -1, 12, 64]);  linear_7 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:389 in forward, code: .transpose(1, 2)\n",
       "                    transpose_5: \"f32[1, 12, s41, 64]\" = torch.ops.aten.transpose.int(view_5, 1, 2);  view_5 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_8: \"f32[1, s41, 768]\" = torch.ops.aten.linear.default(layer_norm_2, p_bert_encoder_layer_1_attention_self_value_weight, p_bert_encoder_layer_1_attention_self_value_bias);  p_bert_encoder_layer_1_attention_self_value_weight = p_bert_encoder_layer_1_attention_self_value_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:393 in forward, code: .view(bsz, -1, self.num_attention_heads, self.attention_head_size)\n",
       "                    view_6: \"f32[1, s41, 12, 64]\" = torch.ops.aten.view.default(linear_8, [1, -1, 12, 64]);  linear_8 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:394 in forward, code: .transpose(1, 2)\n",
       "                    transpose_6: \"f32[1, 12, s41, 64]\" = torch.ops.aten.transpose.int(view_6, 1, 2);  view_6 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:413 in forward, code: attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
       "                    scaled_dot_product_attention_1: \"f32[1, 12, s41, 64]\" = torch.ops.aten.scaled_dot_product_attention.default(transpose_4, transpose_5, transpose_6, masked_fill);  transpose_4 = transpose_5 = transpose_6 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:422 in forward, code: attn_output = attn_output.transpose(1, 2)\n",
       "                    transpose_7: \"f32[1, s41, 12, 64]\" = torch.ops.aten.transpose.int(scaled_dot_product_attention_1, 1, 2);  scaled_dot_product_attention_1 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:423 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.all_head_size)\n",
       "                    view_7: \"f32[1, s41, 768]\" = torch.ops.aten.view.default(transpose_7, [1, sym_size_int_79, 768]);  transpose_7 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_9: \"f32[1, s41, 768]\" = torch.ops.aten.linear.default(view_7, p_bert_encoder_layer_1_attention_output_dense_weight, p_bert_encoder_layer_1_attention_output_dense_bias);  view_7 = p_bert_encoder_layer_1_attention_output_dense_weight = p_bert_encoder_layer_1_attention_output_dense_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\dropout.py:73 in forward, code: return F.dropout(input, self.p, self.training, self.inplace)\n",
       "                    clone_4: \"f32[1, s41, 768]\" = torch.ops.aten.clone.default(linear_9);  linear_9 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:438 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
       "                    add_169: \"f32[1, s41, 768]\" = torch.ops.aten.add.Tensor(clone_4, layer_norm_2);  clone_4 = layer_norm_2 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\normalization.py:229 in forward, code: return F.layer_norm(\n",
       "                    layer_norm_3: \"f32[1, s41, 768]\" = torch.ops.aten.layer_norm.default(add_169, [768], p_bert_encoder_layer_1_attention_output_layernorm_weight, p_bert_encoder_layer_1_attention_output_layernorm_bias, 1e-12);  add_169 = p_bert_encoder_layer_1_attention_output_layernorm_weight = p_bert_encoder_layer_1_attention_output_layernorm_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_10: \"f32[1, s41, 3072]\" = torch.ops.aten.linear.default(layer_norm_3, p_bert_encoder_layer_1_intermediate_dense_weight, p_bert_encoder_layer_1_intermediate_dense_bias);  p_bert_encoder_layer_1_intermediate_dense_weight = p_bert_encoder_layer_1_intermediate_dense_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\activations.py:85 in forward, code: return self.act(input)\n",
       "                    gelu_1: \"f32[1, s41, 3072]\" = torch.ops.aten.gelu.default(linear_10);  linear_10 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_11: \"f32[1, s41, 768]\" = torch.ops.aten.linear.default(gelu_1, p_bert_encoder_layer_1_output_dense_weight, p_bert_encoder_layer_1_output_dense_bias);  gelu_1 = p_bert_encoder_layer_1_output_dense_weight = p_bert_encoder_layer_1_output_dense_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\dropout.py:73 in forward, code: return F.dropout(input, self.p, self.training, self.inplace)\n",
       "                    clone_5: \"f32[1, s41, 768]\" = torch.ops.aten.clone.default(linear_11);  linear_11 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:527 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
       "                    add_188: \"f32[1, s41, 768]\" = torch.ops.aten.add.Tensor(clone_5, layer_norm_3);  clone_5 = layer_norm_3 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\normalization.py:229 in forward, code: return F.layer_norm(\n",
       "                    layer_norm_4: \"f32[1, s41, 768]\" = torch.ops.aten.layer_norm.default(add_188, [768], p_bert_encoder_layer_1_output_layernorm_weight, p_bert_encoder_layer_1_output_layernorm_bias, 1e-12);  add_188 = p_bert_encoder_layer_1_output_layernorm_weight = p_bert_encoder_layer_1_output_layernorm_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_12: \"f32[1, s41, 768]\" = torch.ops.aten.linear.default(layer_norm_4, p_bert_encoder_layer_2_attention_self_query_weight, p_bert_encoder_layer_2_attention_self_query_bias);  p_bert_encoder_layer_2_attention_self_query_weight = p_bert_encoder_layer_2_attention_self_query_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:363 in forward, code: self.query(hidden_states).view(bsz, -1, self.num_attention_heads, self.attention_head_size).transpose(1, 2)\n",
       "                    view_8: \"f32[1, s41, 12, 64]\" = torch.ops.aten.view.default(linear_12, [1, -1, 12, 64]);  linear_12 = None\n",
       "                    transpose_8: \"f32[1, 12, s41, 64]\" = torch.ops.aten.transpose.int(view_8, 1, 2);  view_8 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_13: \"f32[1, s41, 768]\" = torch.ops.aten.linear.default(layer_norm_4, p_bert_encoder_layer_2_attention_self_key_weight, p_bert_encoder_layer_2_attention_self_key_bias);  p_bert_encoder_layer_2_attention_self_key_weight = p_bert_encoder_layer_2_attention_self_key_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:388 in forward, code: .view(bsz, -1, self.num_attention_heads, self.attention_head_size)\n",
       "                    view_9: \"f32[1, s41, 12, 64]\" = torch.ops.aten.view.default(linear_13, [1, -1, 12, 64]);  linear_13 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:389 in forward, code: .transpose(1, 2)\n",
       "                    transpose_9: \"f32[1, 12, s41, 64]\" = torch.ops.aten.transpose.int(view_9, 1, 2);  view_9 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_14: \"f32[1, s41, 768]\" = torch.ops.aten.linear.default(layer_norm_4, p_bert_encoder_layer_2_attention_self_value_weight, p_bert_encoder_layer_2_attention_self_value_bias);  p_bert_encoder_layer_2_attention_self_value_weight = p_bert_encoder_layer_2_attention_self_value_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:393 in forward, code: .view(bsz, -1, self.num_attention_heads, self.attention_head_size)\n",
       "                    view_10: \"f32[1, s41, 12, 64]\" = torch.ops.aten.view.default(linear_14, [1, -1, 12, 64]);  linear_14 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:394 in forward, code: .transpose(1, 2)\n",
       "                    transpose_10: \"f32[1, 12, s41, 64]\" = torch.ops.aten.transpose.int(view_10, 1, 2);  view_10 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:413 in forward, code: attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
       "                    scaled_dot_product_attention_2: \"f32[1, 12, s41, 64]\" = torch.ops.aten.scaled_dot_product_attention.default(transpose_8, transpose_9, transpose_10, masked_fill);  transpose_8 = transpose_9 = transpose_10 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:422 in forward, code: attn_output = attn_output.transpose(1, 2)\n",
       "                    transpose_11: \"f32[1, s41, 12, 64]\" = torch.ops.aten.transpose.int(scaled_dot_product_attention_2, 1, 2);  scaled_dot_product_attention_2 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:423 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.all_head_size)\n",
       "                    view_11: \"f32[1, s41, 768]\" = torch.ops.aten.view.default(transpose_11, [1, sym_size_int_79, 768]);  transpose_11 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_15: \"f32[1, s41, 768]\" = torch.ops.aten.linear.default(view_11, p_bert_encoder_layer_2_attention_output_dense_weight, p_bert_encoder_layer_2_attention_output_dense_bias);  view_11 = p_bert_encoder_layer_2_attention_output_dense_weight = p_bert_encoder_layer_2_attention_output_dense_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\dropout.py:73 in forward, code: return F.dropout(input, self.p, self.training, self.inplace)\n",
       "                    clone_6: \"f32[1, s41, 768]\" = torch.ops.aten.clone.default(linear_15);  linear_15 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:438 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
       "                    add_241: \"f32[1, s41, 768]\" = torch.ops.aten.add.Tensor(clone_6, layer_norm_4);  clone_6 = layer_norm_4 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\normalization.py:229 in forward, code: return F.layer_norm(\n",
       "                    layer_norm_5: \"f32[1, s41, 768]\" = torch.ops.aten.layer_norm.default(add_241, [768], p_bert_encoder_layer_2_attention_output_layernorm_weight, p_bert_encoder_layer_2_attention_output_layernorm_bias, 1e-12);  add_241 = p_bert_encoder_layer_2_attention_output_layernorm_weight = p_bert_encoder_layer_2_attention_output_layernorm_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_16: \"f32[1, s41, 3072]\" = torch.ops.aten.linear.default(layer_norm_5, p_bert_encoder_layer_2_intermediate_dense_weight, p_bert_encoder_layer_2_intermediate_dense_bias);  p_bert_encoder_layer_2_intermediate_dense_weight = p_bert_encoder_layer_2_intermediate_dense_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\activations.py:85 in forward, code: return self.act(input)\n",
       "                    gelu_2: \"f32[1, s41, 3072]\" = torch.ops.aten.gelu.default(linear_16);  linear_16 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_17: \"f32[1, s41, 768]\" = torch.ops.aten.linear.default(gelu_2, p_bert_encoder_layer_2_output_dense_weight, p_bert_encoder_layer_2_output_dense_bias);  gelu_2 = p_bert_encoder_layer_2_output_dense_weight = p_bert_encoder_layer_2_output_dense_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\dropout.py:73 in forward, code: return F.dropout(input, self.p, self.training, self.inplace)\n",
       "                    clone_7: \"f32[1, s41, 768]\" = torch.ops.aten.clone.default(linear_17);  linear_17 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:527 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
       "                    add_260: \"f32[1, s41, 768]\" = torch.ops.aten.add.Tensor(clone_7, layer_norm_5);  clone_7 = layer_norm_5 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\normalization.py:229 in forward, code: return F.layer_norm(\n",
       "                    layer_norm_6: \"f32[1, s41, 768]\" = torch.ops.aten.layer_norm.default(add_260, [768], p_bert_encoder_layer_2_output_layernorm_weight, p_bert_encoder_layer_2_output_layernorm_bias, 1e-12);  add_260 = p_bert_encoder_layer_2_output_layernorm_weight = p_bert_encoder_layer_2_output_layernorm_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_18: \"f32[1, s41, 768]\" = torch.ops.aten.linear.default(layer_norm_6, p_bert_encoder_layer_3_attention_self_query_weight, p_bert_encoder_layer_3_attention_self_query_bias);  p_bert_encoder_layer_3_attention_self_query_weight = p_bert_encoder_layer_3_attention_self_query_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:363 in forward, code: self.query(hidden_states).view(bsz, -1, self.num_attention_heads, self.attention_head_size).transpose(1, 2)\n",
       "                    view_12: \"f32[1, s41, 12, 64]\" = torch.ops.aten.view.default(linear_18, [1, -1, 12, 64]);  linear_18 = None\n",
       "                    transpose_12: \"f32[1, 12, s41, 64]\" = torch.ops.aten.transpose.int(view_12, 1, 2);  view_12 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_19: \"f32[1, s41, 768]\" = torch.ops.aten.linear.default(layer_norm_6, p_bert_encoder_layer_3_attention_self_key_weight, p_bert_encoder_layer_3_attention_self_key_bias);  p_bert_encoder_layer_3_attention_self_key_weight = p_bert_encoder_layer_3_attention_self_key_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:388 in forward, code: .view(bsz, -1, self.num_attention_heads, self.attention_head_size)\n",
       "                    view_13: \"f32[1, s41, 12, 64]\" = torch.ops.aten.view.default(linear_19, [1, -1, 12, 64]);  linear_19 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:389 in forward, code: .transpose(1, 2)\n",
       "                    transpose_13: \"f32[1, 12, s41, 64]\" = torch.ops.aten.transpose.int(view_13, 1, 2);  view_13 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_20: \"f32[1, s41, 768]\" = torch.ops.aten.linear.default(layer_norm_6, p_bert_encoder_layer_3_attention_self_value_weight, p_bert_encoder_layer_3_attention_self_value_bias);  p_bert_encoder_layer_3_attention_self_value_weight = p_bert_encoder_layer_3_attention_self_value_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:393 in forward, code: .view(bsz, -1, self.num_attention_heads, self.attention_head_size)\n",
       "                    view_14: \"f32[1, s41, 12, 64]\" = torch.ops.aten.view.default(linear_20, [1, -1, 12, 64]);  linear_20 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:394 in forward, code: .transpose(1, 2)\n",
       "                    transpose_14: \"f32[1, 12, s41, 64]\" = torch.ops.aten.transpose.int(view_14, 1, 2);  view_14 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:413 in forward, code: attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
       "                    scaled_dot_product_attention_3: \"f32[1, 12, s41, 64]\" = torch.ops.aten.scaled_dot_product_attention.default(transpose_12, transpose_13, transpose_14, masked_fill);  transpose_12 = transpose_13 = transpose_14 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:422 in forward, code: attn_output = attn_output.transpose(1, 2)\n",
       "                    transpose_15: \"f32[1, s41, 12, 64]\" = torch.ops.aten.transpose.int(scaled_dot_product_attention_3, 1, 2);  scaled_dot_product_attention_3 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:423 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.all_head_size)\n",
       "                    view_15: \"f32[1, s41, 768]\" = torch.ops.aten.view.default(transpose_15, [1, sym_size_int_79, 768]);  transpose_15 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_21: \"f32[1, s41, 768]\" = torch.ops.aten.linear.default(view_15, p_bert_encoder_layer_3_attention_output_dense_weight, p_bert_encoder_layer_3_attention_output_dense_bias);  view_15 = p_bert_encoder_layer_3_attention_output_dense_weight = p_bert_encoder_layer_3_attention_output_dense_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\dropout.py:73 in forward, code: return F.dropout(input, self.p, self.training, self.inplace)\n",
       "                    clone_8: \"f32[1, s41, 768]\" = torch.ops.aten.clone.default(linear_21);  linear_21 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:438 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
       "                    add_313: \"f32[1, s41, 768]\" = torch.ops.aten.add.Tensor(clone_8, layer_norm_6);  clone_8 = layer_norm_6 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\normalization.py:229 in forward, code: return F.layer_norm(\n",
       "                    layer_norm_7: \"f32[1, s41, 768]\" = torch.ops.aten.layer_norm.default(add_313, [768], p_bert_encoder_layer_3_attention_output_layernorm_weight, p_bert_encoder_layer_3_attention_output_layernorm_bias, 1e-12);  add_313 = p_bert_encoder_layer_3_attention_output_layernorm_weight = p_bert_encoder_layer_3_attention_output_layernorm_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_22: \"f32[1, s41, 3072]\" = torch.ops.aten.linear.default(layer_norm_7, p_bert_encoder_layer_3_intermediate_dense_weight, p_bert_encoder_layer_3_intermediate_dense_bias);  p_bert_encoder_layer_3_intermediate_dense_weight = p_bert_encoder_layer_3_intermediate_dense_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\activations.py:85 in forward, code: return self.act(input)\n",
       "                    gelu_3: \"f32[1, s41, 3072]\" = torch.ops.aten.gelu.default(linear_22);  linear_22 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_23: \"f32[1, s41, 768]\" = torch.ops.aten.linear.default(gelu_3, p_bert_encoder_layer_3_output_dense_weight, p_bert_encoder_layer_3_output_dense_bias);  gelu_3 = p_bert_encoder_layer_3_output_dense_weight = p_bert_encoder_layer_3_output_dense_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\dropout.py:73 in forward, code: return F.dropout(input, self.p, self.training, self.inplace)\n",
       "                    clone_9: \"f32[1, s41, 768]\" = torch.ops.aten.clone.default(linear_23);  linear_23 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:527 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
       "                    add_332: \"f32[1, s41, 768]\" = torch.ops.aten.add.Tensor(clone_9, layer_norm_7);  clone_9 = layer_norm_7 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\normalization.py:229 in forward, code: return F.layer_norm(\n",
       "                    layer_norm_8: \"f32[1, s41, 768]\" = torch.ops.aten.layer_norm.default(add_332, [768], p_bert_encoder_layer_3_output_layernorm_weight, p_bert_encoder_layer_3_output_layernorm_bias, 1e-12);  add_332 = p_bert_encoder_layer_3_output_layernorm_weight = p_bert_encoder_layer_3_output_layernorm_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_24: \"f32[1, s41, 768]\" = torch.ops.aten.linear.default(layer_norm_8, p_bert_encoder_layer_4_attention_self_query_weight, p_bert_encoder_layer_4_attention_self_query_bias);  p_bert_encoder_layer_4_attention_self_query_weight = p_bert_encoder_layer_4_attention_self_query_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:363 in forward, code: self.query(hidden_states).view(bsz, -1, self.num_attention_heads, self.attention_head_size).transpose(1, 2)\n",
       "                    view_16: \"f32[1, s41, 12, 64]\" = torch.ops.aten.view.default(linear_24, [1, -1, 12, 64]);  linear_24 = None\n",
       "                    transpose_16: \"f32[1, 12, s41, 64]\" = torch.ops.aten.transpose.int(view_16, 1, 2);  view_16 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_25: \"f32[1, s41, 768]\" = torch.ops.aten.linear.default(layer_norm_8, p_bert_encoder_layer_4_attention_self_key_weight, p_bert_encoder_layer_4_attention_self_key_bias);  p_bert_encoder_layer_4_attention_self_key_weight = p_bert_encoder_layer_4_attention_self_key_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:388 in forward, code: .view(bsz, -1, self.num_attention_heads, self.attention_head_size)\n",
       "                    view_17: \"f32[1, s41, 12, 64]\" = torch.ops.aten.view.default(linear_25, [1, -1, 12, 64]);  linear_25 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:389 in forward, code: .transpose(1, 2)\n",
       "                    transpose_17: \"f32[1, 12, s41, 64]\" = torch.ops.aten.transpose.int(view_17, 1, 2);  view_17 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_26: \"f32[1, s41, 768]\" = torch.ops.aten.linear.default(layer_norm_8, p_bert_encoder_layer_4_attention_self_value_weight, p_bert_encoder_layer_4_attention_self_value_bias);  p_bert_encoder_layer_4_attention_self_value_weight = p_bert_encoder_layer_4_attention_self_value_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:393 in forward, code: .view(bsz, -1, self.num_attention_heads, self.attention_head_size)\n",
       "                    view_18: \"f32[1, s41, 12, 64]\" = torch.ops.aten.view.default(linear_26, [1, -1, 12, 64]);  linear_26 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:394 in forward, code: .transpose(1, 2)\n",
       "                    transpose_18: \"f32[1, 12, s41, 64]\" = torch.ops.aten.transpose.int(view_18, 1, 2);  view_18 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:413 in forward, code: attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
       "                    scaled_dot_product_attention_4: \"f32[1, 12, s41, 64]\" = torch.ops.aten.scaled_dot_product_attention.default(transpose_16, transpose_17, transpose_18, masked_fill);  transpose_16 = transpose_17 = transpose_18 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:422 in forward, code: attn_output = attn_output.transpose(1, 2)\n",
       "                    transpose_19: \"f32[1, s41, 12, 64]\" = torch.ops.aten.transpose.int(scaled_dot_product_attention_4, 1, 2);  scaled_dot_product_attention_4 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:423 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.all_head_size)\n",
       "                    view_19: \"f32[1, s41, 768]\" = torch.ops.aten.view.default(transpose_19, [1, sym_size_int_79, 768]);  transpose_19 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_27: \"f32[1, s41, 768]\" = torch.ops.aten.linear.default(view_19, p_bert_encoder_layer_4_attention_output_dense_weight, p_bert_encoder_layer_4_attention_output_dense_bias);  view_19 = p_bert_encoder_layer_4_attention_output_dense_weight = p_bert_encoder_layer_4_attention_output_dense_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\dropout.py:73 in forward, code: return F.dropout(input, self.p, self.training, self.inplace)\n",
       "                    clone_10: \"f32[1, s41, 768]\" = torch.ops.aten.clone.default(linear_27);  linear_27 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:438 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
       "                    add_385: \"f32[1, s41, 768]\" = torch.ops.aten.add.Tensor(clone_10, layer_norm_8);  clone_10 = layer_norm_8 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\normalization.py:229 in forward, code: return F.layer_norm(\n",
       "                    layer_norm_9: \"f32[1, s41, 768]\" = torch.ops.aten.layer_norm.default(add_385, [768], p_bert_encoder_layer_4_attention_output_layernorm_weight, p_bert_encoder_layer_4_attention_output_layernorm_bias, 1e-12);  add_385 = p_bert_encoder_layer_4_attention_output_layernorm_weight = p_bert_encoder_layer_4_attention_output_layernorm_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_28: \"f32[1, s41, 3072]\" = torch.ops.aten.linear.default(layer_norm_9, p_bert_encoder_layer_4_intermediate_dense_weight, p_bert_encoder_layer_4_intermediate_dense_bias);  p_bert_encoder_layer_4_intermediate_dense_weight = p_bert_encoder_layer_4_intermediate_dense_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\activations.py:85 in forward, code: return self.act(input)\n",
       "                    gelu_4: \"f32[1, s41, 3072]\" = torch.ops.aten.gelu.default(linear_28);  linear_28 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_29: \"f32[1, s41, 768]\" = torch.ops.aten.linear.default(gelu_4, p_bert_encoder_layer_4_output_dense_weight, p_bert_encoder_layer_4_output_dense_bias);  gelu_4 = p_bert_encoder_layer_4_output_dense_weight = p_bert_encoder_layer_4_output_dense_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\dropout.py:73 in forward, code: return F.dropout(input, self.p, self.training, self.inplace)\n",
       "                    clone_11: \"f32[1, s41, 768]\" = torch.ops.aten.clone.default(linear_29);  linear_29 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:527 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
       "                    add_404: \"f32[1, s41, 768]\" = torch.ops.aten.add.Tensor(clone_11, layer_norm_9);  clone_11 = layer_norm_9 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\normalization.py:229 in forward, code: return F.layer_norm(\n",
       "                    layer_norm_10: \"f32[1, s41, 768]\" = torch.ops.aten.layer_norm.default(add_404, [768], p_bert_encoder_layer_4_output_layernorm_weight, p_bert_encoder_layer_4_output_layernorm_bias, 1e-12);  add_404 = p_bert_encoder_layer_4_output_layernorm_weight = p_bert_encoder_layer_4_output_layernorm_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_30: \"f32[1, s41, 768]\" = torch.ops.aten.linear.default(layer_norm_10, p_bert_encoder_layer_5_attention_self_query_weight, p_bert_encoder_layer_5_attention_self_query_bias);  p_bert_encoder_layer_5_attention_self_query_weight = p_bert_encoder_layer_5_attention_self_query_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:363 in forward, code: self.query(hidden_states).view(bsz, -1, self.num_attention_heads, self.attention_head_size).transpose(1, 2)\n",
       "                    view_20: \"f32[1, s41, 12, 64]\" = torch.ops.aten.view.default(linear_30, [1, -1, 12, 64]);  linear_30 = None\n",
       "                    transpose_20: \"f32[1, 12, s41, 64]\" = torch.ops.aten.transpose.int(view_20, 1, 2);  view_20 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_31: \"f32[1, s41, 768]\" = torch.ops.aten.linear.default(layer_norm_10, p_bert_encoder_layer_5_attention_self_key_weight, p_bert_encoder_layer_5_attention_self_key_bias);  p_bert_encoder_layer_5_attention_self_key_weight = p_bert_encoder_layer_5_attention_self_key_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:388 in forward, code: .view(bsz, -1, self.num_attention_heads, self.attention_head_size)\n",
       "                    view_21: \"f32[1, s41, 12, 64]\" = torch.ops.aten.view.default(linear_31, [1, -1, 12, 64]);  linear_31 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:389 in forward, code: .transpose(1, 2)\n",
       "                    transpose_21: \"f32[1, 12, s41, 64]\" = torch.ops.aten.transpose.int(view_21, 1, 2);  view_21 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_32: \"f32[1, s41, 768]\" = torch.ops.aten.linear.default(layer_norm_10, p_bert_encoder_layer_5_attention_self_value_weight, p_bert_encoder_layer_5_attention_self_value_bias);  p_bert_encoder_layer_5_attention_self_value_weight = p_bert_encoder_layer_5_attention_self_value_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:393 in forward, code: .view(bsz, -1, self.num_attention_heads, self.attention_head_size)\n",
       "                    view_22: \"f32[1, s41, 12, 64]\" = torch.ops.aten.view.default(linear_32, [1, -1, 12, 64]);  linear_32 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:394 in forward, code: .transpose(1, 2)\n",
       "                    transpose_22: \"f32[1, 12, s41, 64]\" = torch.ops.aten.transpose.int(view_22, 1, 2);  view_22 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:413 in forward, code: attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
       "                    scaled_dot_product_attention_5: \"f32[1, 12, s41, 64]\" = torch.ops.aten.scaled_dot_product_attention.default(transpose_20, transpose_21, transpose_22, masked_fill);  transpose_20 = transpose_21 = transpose_22 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:422 in forward, code: attn_output = attn_output.transpose(1, 2)\n",
       "                    transpose_23: \"f32[1, s41, 12, 64]\" = torch.ops.aten.transpose.int(scaled_dot_product_attention_5, 1, 2);  scaled_dot_product_attention_5 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:423 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.all_head_size)\n",
       "                    view_23: \"f32[1, s41, 768]\" = torch.ops.aten.view.default(transpose_23, [1, sym_size_int_79, 768]);  transpose_23 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_33: \"f32[1, s41, 768]\" = torch.ops.aten.linear.default(view_23, p_bert_encoder_layer_5_attention_output_dense_weight, p_bert_encoder_layer_5_attention_output_dense_bias);  view_23 = p_bert_encoder_layer_5_attention_output_dense_weight = p_bert_encoder_layer_5_attention_output_dense_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\dropout.py:73 in forward, code: return F.dropout(input, self.p, self.training, self.inplace)\n",
       "                    clone_12: \"f32[1, s41, 768]\" = torch.ops.aten.clone.default(linear_33);  linear_33 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:438 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
       "                    add_457: \"f32[1, s41, 768]\" = torch.ops.aten.add.Tensor(clone_12, layer_norm_10);  clone_12 = layer_norm_10 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\normalization.py:229 in forward, code: return F.layer_norm(\n",
       "                    layer_norm_11: \"f32[1, s41, 768]\" = torch.ops.aten.layer_norm.default(add_457, [768], p_bert_encoder_layer_5_attention_output_layernorm_weight, p_bert_encoder_layer_5_attention_output_layernorm_bias, 1e-12);  add_457 = p_bert_encoder_layer_5_attention_output_layernorm_weight = p_bert_encoder_layer_5_attention_output_layernorm_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_34: \"f32[1, s41, 3072]\" = torch.ops.aten.linear.default(layer_norm_11, p_bert_encoder_layer_5_intermediate_dense_weight, p_bert_encoder_layer_5_intermediate_dense_bias);  p_bert_encoder_layer_5_intermediate_dense_weight = p_bert_encoder_layer_5_intermediate_dense_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\activations.py:85 in forward, code: return self.act(input)\n",
       "                    gelu_5: \"f32[1, s41, 3072]\" = torch.ops.aten.gelu.default(linear_34);  linear_34 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_35: \"f32[1, s41, 768]\" = torch.ops.aten.linear.default(gelu_5, p_bert_encoder_layer_5_output_dense_weight, p_bert_encoder_layer_5_output_dense_bias);  gelu_5 = p_bert_encoder_layer_5_output_dense_weight = p_bert_encoder_layer_5_output_dense_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\dropout.py:73 in forward, code: return F.dropout(input, self.p, self.training, self.inplace)\n",
       "                    clone_13: \"f32[1, s41, 768]\" = torch.ops.aten.clone.default(linear_35);  linear_35 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:527 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
       "                    add_476: \"f32[1, s41, 768]\" = torch.ops.aten.add.Tensor(clone_13, layer_norm_11);  clone_13 = layer_norm_11 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\normalization.py:229 in forward, code: return F.layer_norm(\n",
       "                    layer_norm_12: \"f32[1, s41, 768]\" = torch.ops.aten.layer_norm.default(add_476, [768], p_bert_encoder_layer_5_output_layernorm_weight, p_bert_encoder_layer_5_output_layernorm_bias, 1e-12);  add_476 = p_bert_encoder_layer_5_output_layernorm_weight = p_bert_encoder_layer_5_output_layernorm_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_36: \"f32[1, s41, 768]\" = torch.ops.aten.linear.default(layer_norm_12, p_bert_encoder_layer_6_attention_self_query_weight, p_bert_encoder_layer_6_attention_self_query_bias);  p_bert_encoder_layer_6_attention_self_query_weight = p_bert_encoder_layer_6_attention_self_query_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:363 in forward, code: self.query(hidden_states).view(bsz, -1, self.num_attention_heads, self.attention_head_size).transpose(1, 2)\n",
       "                    view_24: \"f32[1, s41, 12, 64]\" = torch.ops.aten.view.default(linear_36, [1, -1, 12, 64]);  linear_36 = None\n",
       "                    transpose_24: \"f32[1, 12, s41, 64]\" = torch.ops.aten.transpose.int(view_24, 1, 2);  view_24 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_37: \"f32[1, s41, 768]\" = torch.ops.aten.linear.default(layer_norm_12, p_bert_encoder_layer_6_attention_self_key_weight, p_bert_encoder_layer_6_attention_self_key_bias);  p_bert_encoder_layer_6_attention_self_key_weight = p_bert_encoder_layer_6_attention_self_key_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:388 in forward, code: .view(bsz, -1, self.num_attention_heads, self.attention_head_size)\n",
       "                    view_25: \"f32[1, s41, 12, 64]\" = torch.ops.aten.view.default(linear_37, [1, -1, 12, 64]);  linear_37 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:389 in forward, code: .transpose(1, 2)\n",
       "                    transpose_25: \"f32[1, 12, s41, 64]\" = torch.ops.aten.transpose.int(view_25, 1, 2);  view_25 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_38: \"f32[1, s41, 768]\" = torch.ops.aten.linear.default(layer_norm_12, p_bert_encoder_layer_6_attention_self_value_weight, p_bert_encoder_layer_6_attention_self_value_bias);  p_bert_encoder_layer_6_attention_self_value_weight = p_bert_encoder_layer_6_attention_self_value_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:393 in forward, code: .view(bsz, -1, self.num_attention_heads, self.attention_head_size)\n",
       "                    view_26: \"f32[1, s41, 12, 64]\" = torch.ops.aten.view.default(linear_38, [1, -1, 12, 64]);  linear_38 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:394 in forward, code: .transpose(1, 2)\n",
       "                    transpose_26: \"f32[1, 12, s41, 64]\" = torch.ops.aten.transpose.int(view_26, 1, 2);  view_26 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:413 in forward, code: attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
       "                    scaled_dot_product_attention_6: \"f32[1, 12, s41, 64]\" = torch.ops.aten.scaled_dot_product_attention.default(transpose_24, transpose_25, transpose_26, masked_fill);  transpose_24 = transpose_25 = transpose_26 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:422 in forward, code: attn_output = attn_output.transpose(1, 2)\n",
       "                    transpose_27: \"f32[1, s41, 12, 64]\" = torch.ops.aten.transpose.int(scaled_dot_product_attention_6, 1, 2);  scaled_dot_product_attention_6 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:423 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.all_head_size)\n",
       "                    view_27: \"f32[1, s41, 768]\" = torch.ops.aten.view.default(transpose_27, [1, sym_size_int_79, 768]);  transpose_27 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_39: \"f32[1, s41, 768]\" = torch.ops.aten.linear.default(view_27, p_bert_encoder_layer_6_attention_output_dense_weight, p_bert_encoder_layer_6_attention_output_dense_bias);  view_27 = p_bert_encoder_layer_6_attention_output_dense_weight = p_bert_encoder_layer_6_attention_output_dense_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\dropout.py:73 in forward, code: return F.dropout(input, self.p, self.training, self.inplace)\n",
       "                    clone_14: \"f32[1, s41, 768]\" = torch.ops.aten.clone.default(linear_39);  linear_39 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:438 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
       "                    add_529: \"f32[1, s41, 768]\" = torch.ops.aten.add.Tensor(clone_14, layer_norm_12);  clone_14 = layer_norm_12 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\normalization.py:229 in forward, code: return F.layer_norm(\n",
       "                    layer_norm_13: \"f32[1, s41, 768]\" = torch.ops.aten.layer_norm.default(add_529, [768], p_bert_encoder_layer_6_attention_output_layernorm_weight, p_bert_encoder_layer_6_attention_output_layernorm_bias, 1e-12);  add_529 = p_bert_encoder_layer_6_attention_output_layernorm_weight = p_bert_encoder_layer_6_attention_output_layernorm_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_40: \"f32[1, s41, 3072]\" = torch.ops.aten.linear.default(layer_norm_13, p_bert_encoder_layer_6_intermediate_dense_weight, p_bert_encoder_layer_6_intermediate_dense_bias);  p_bert_encoder_layer_6_intermediate_dense_weight = p_bert_encoder_layer_6_intermediate_dense_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\activations.py:85 in forward, code: return self.act(input)\n",
       "                    gelu_6: \"f32[1, s41, 3072]\" = torch.ops.aten.gelu.default(linear_40);  linear_40 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_41: \"f32[1, s41, 768]\" = torch.ops.aten.linear.default(gelu_6, p_bert_encoder_layer_6_output_dense_weight, p_bert_encoder_layer_6_output_dense_bias);  gelu_6 = p_bert_encoder_layer_6_output_dense_weight = p_bert_encoder_layer_6_output_dense_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\dropout.py:73 in forward, code: return F.dropout(input, self.p, self.training, self.inplace)\n",
       "                    clone_15: \"f32[1, s41, 768]\" = torch.ops.aten.clone.default(linear_41);  linear_41 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:527 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
       "                    add_548: \"f32[1, s41, 768]\" = torch.ops.aten.add.Tensor(clone_15, layer_norm_13);  clone_15 = layer_norm_13 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\normalization.py:229 in forward, code: return F.layer_norm(\n",
       "                    layer_norm_14: \"f32[1, s41, 768]\" = torch.ops.aten.layer_norm.default(add_548, [768], p_bert_encoder_layer_6_output_layernorm_weight, p_bert_encoder_layer_6_output_layernorm_bias, 1e-12);  add_548 = p_bert_encoder_layer_6_output_layernorm_weight = p_bert_encoder_layer_6_output_layernorm_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_42: \"f32[1, s41, 768]\" = torch.ops.aten.linear.default(layer_norm_14, p_bert_encoder_layer_7_attention_self_query_weight, p_bert_encoder_layer_7_attention_self_query_bias);  p_bert_encoder_layer_7_attention_self_query_weight = p_bert_encoder_layer_7_attention_self_query_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:363 in forward, code: self.query(hidden_states).view(bsz, -1, self.num_attention_heads, self.attention_head_size).transpose(1, 2)\n",
       "                    view_28: \"f32[1, s41, 12, 64]\" = torch.ops.aten.view.default(linear_42, [1, -1, 12, 64]);  linear_42 = None\n",
       "                    transpose_28: \"f32[1, 12, s41, 64]\" = torch.ops.aten.transpose.int(view_28, 1, 2);  view_28 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_43: \"f32[1, s41, 768]\" = torch.ops.aten.linear.default(layer_norm_14, p_bert_encoder_layer_7_attention_self_key_weight, p_bert_encoder_layer_7_attention_self_key_bias);  p_bert_encoder_layer_7_attention_self_key_weight = p_bert_encoder_layer_7_attention_self_key_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:388 in forward, code: .view(bsz, -1, self.num_attention_heads, self.attention_head_size)\n",
       "                    view_29: \"f32[1, s41, 12, 64]\" = torch.ops.aten.view.default(linear_43, [1, -1, 12, 64]);  linear_43 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:389 in forward, code: .transpose(1, 2)\n",
       "                    transpose_29: \"f32[1, 12, s41, 64]\" = torch.ops.aten.transpose.int(view_29, 1, 2);  view_29 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_44: \"f32[1, s41, 768]\" = torch.ops.aten.linear.default(layer_norm_14, p_bert_encoder_layer_7_attention_self_value_weight, p_bert_encoder_layer_7_attention_self_value_bias);  p_bert_encoder_layer_7_attention_self_value_weight = p_bert_encoder_layer_7_attention_self_value_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:393 in forward, code: .view(bsz, -1, self.num_attention_heads, self.attention_head_size)\n",
       "                    view_30: \"f32[1, s41, 12, 64]\" = torch.ops.aten.view.default(linear_44, [1, -1, 12, 64]);  linear_44 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:394 in forward, code: .transpose(1, 2)\n",
       "                    transpose_30: \"f32[1, 12, s41, 64]\" = torch.ops.aten.transpose.int(view_30, 1, 2);  view_30 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:413 in forward, code: attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
       "                    scaled_dot_product_attention_7: \"f32[1, 12, s41, 64]\" = torch.ops.aten.scaled_dot_product_attention.default(transpose_28, transpose_29, transpose_30, masked_fill);  transpose_28 = transpose_29 = transpose_30 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:422 in forward, code: attn_output = attn_output.transpose(1, 2)\n",
       "                    transpose_31: \"f32[1, s41, 12, 64]\" = torch.ops.aten.transpose.int(scaled_dot_product_attention_7, 1, 2);  scaled_dot_product_attention_7 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:423 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.all_head_size)\n",
       "                    view_31: \"f32[1, s41, 768]\" = torch.ops.aten.view.default(transpose_31, [1, sym_size_int_79, 768]);  transpose_31 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_45: \"f32[1, s41, 768]\" = torch.ops.aten.linear.default(view_31, p_bert_encoder_layer_7_attention_output_dense_weight, p_bert_encoder_layer_7_attention_output_dense_bias);  view_31 = p_bert_encoder_layer_7_attention_output_dense_weight = p_bert_encoder_layer_7_attention_output_dense_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\dropout.py:73 in forward, code: return F.dropout(input, self.p, self.training, self.inplace)\n",
       "                    clone_16: \"f32[1, s41, 768]\" = torch.ops.aten.clone.default(linear_45);  linear_45 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:438 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
       "                    add_601: \"f32[1, s41, 768]\" = torch.ops.aten.add.Tensor(clone_16, layer_norm_14);  clone_16 = layer_norm_14 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\normalization.py:229 in forward, code: return F.layer_norm(\n",
       "                    layer_norm_15: \"f32[1, s41, 768]\" = torch.ops.aten.layer_norm.default(add_601, [768], p_bert_encoder_layer_7_attention_output_layernorm_weight, p_bert_encoder_layer_7_attention_output_layernorm_bias, 1e-12);  add_601 = p_bert_encoder_layer_7_attention_output_layernorm_weight = p_bert_encoder_layer_7_attention_output_layernorm_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_46: \"f32[1, s41, 3072]\" = torch.ops.aten.linear.default(layer_norm_15, p_bert_encoder_layer_7_intermediate_dense_weight, p_bert_encoder_layer_7_intermediate_dense_bias);  p_bert_encoder_layer_7_intermediate_dense_weight = p_bert_encoder_layer_7_intermediate_dense_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\activations.py:85 in forward, code: return self.act(input)\n",
       "                    gelu_7: \"f32[1, s41, 3072]\" = torch.ops.aten.gelu.default(linear_46);  linear_46 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_47: \"f32[1, s41, 768]\" = torch.ops.aten.linear.default(gelu_7, p_bert_encoder_layer_7_output_dense_weight, p_bert_encoder_layer_7_output_dense_bias);  gelu_7 = p_bert_encoder_layer_7_output_dense_weight = p_bert_encoder_layer_7_output_dense_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\dropout.py:73 in forward, code: return F.dropout(input, self.p, self.training, self.inplace)\n",
       "                    clone_17: \"f32[1, s41, 768]\" = torch.ops.aten.clone.default(linear_47);  linear_47 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:527 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
       "                    add_620: \"f32[1, s41, 768]\" = torch.ops.aten.add.Tensor(clone_17, layer_norm_15);  clone_17 = layer_norm_15 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\normalization.py:229 in forward, code: return F.layer_norm(\n",
       "                    layer_norm_16: \"f32[1, s41, 768]\" = torch.ops.aten.layer_norm.default(add_620, [768], p_bert_encoder_layer_7_output_layernorm_weight, p_bert_encoder_layer_7_output_layernorm_bias, 1e-12);  add_620 = p_bert_encoder_layer_7_output_layernorm_weight = p_bert_encoder_layer_7_output_layernorm_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_48: \"f32[1, s41, 768]\" = torch.ops.aten.linear.default(layer_norm_16, p_bert_encoder_layer_8_attention_self_query_weight, p_bert_encoder_layer_8_attention_self_query_bias);  p_bert_encoder_layer_8_attention_self_query_weight = p_bert_encoder_layer_8_attention_self_query_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:363 in forward, code: self.query(hidden_states).view(bsz, -1, self.num_attention_heads, self.attention_head_size).transpose(1, 2)\n",
       "                    view_32: \"f32[1, s41, 12, 64]\" = torch.ops.aten.view.default(linear_48, [1, -1, 12, 64]);  linear_48 = None\n",
       "                    transpose_32: \"f32[1, 12, s41, 64]\" = torch.ops.aten.transpose.int(view_32, 1, 2);  view_32 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_49: \"f32[1, s41, 768]\" = torch.ops.aten.linear.default(layer_norm_16, p_bert_encoder_layer_8_attention_self_key_weight, p_bert_encoder_layer_8_attention_self_key_bias);  p_bert_encoder_layer_8_attention_self_key_weight = p_bert_encoder_layer_8_attention_self_key_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:388 in forward, code: .view(bsz, -1, self.num_attention_heads, self.attention_head_size)\n",
       "                    view_33: \"f32[1, s41, 12, 64]\" = torch.ops.aten.view.default(linear_49, [1, -1, 12, 64]);  linear_49 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:389 in forward, code: .transpose(1, 2)\n",
       "                    transpose_33: \"f32[1, 12, s41, 64]\" = torch.ops.aten.transpose.int(view_33, 1, 2);  view_33 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_50: \"f32[1, s41, 768]\" = torch.ops.aten.linear.default(layer_norm_16, p_bert_encoder_layer_8_attention_self_value_weight, p_bert_encoder_layer_8_attention_self_value_bias);  p_bert_encoder_layer_8_attention_self_value_weight = p_bert_encoder_layer_8_attention_self_value_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:393 in forward, code: .view(bsz, -1, self.num_attention_heads, self.attention_head_size)\n",
       "                    view_34: \"f32[1, s41, 12, 64]\" = torch.ops.aten.view.default(linear_50, [1, -1, 12, 64]);  linear_50 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:394 in forward, code: .transpose(1, 2)\n",
       "                    transpose_34: \"f32[1, 12, s41, 64]\" = torch.ops.aten.transpose.int(view_34, 1, 2);  view_34 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:413 in forward, code: attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
       "                    scaled_dot_product_attention_8: \"f32[1, 12, s41, 64]\" = torch.ops.aten.scaled_dot_product_attention.default(transpose_32, transpose_33, transpose_34, masked_fill);  transpose_32 = transpose_33 = transpose_34 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:422 in forward, code: attn_output = attn_output.transpose(1, 2)\n",
       "                    transpose_35: \"f32[1, s41, 12, 64]\" = torch.ops.aten.transpose.int(scaled_dot_product_attention_8, 1, 2);  scaled_dot_product_attention_8 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:423 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.all_head_size)\n",
       "                    view_35: \"f32[1, s41, 768]\" = torch.ops.aten.view.default(transpose_35, [1, sym_size_int_79, 768]);  transpose_35 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_51: \"f32[1, s41, 768]\" = torch.ops.aten.linear.default(view_35, p_bert_encoder_layer_8_attention_output_dense_weight, p_bert_encoder_layer_8_attention_output_dense_bias);  view_35 = p_bert_encoder_layer_8_attention_output_dense_weight = p_bert_encoder_layer_8_attention_output_dense_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\dropout.py:73 in forward, code: return F.dropout(input, self.p, self.training, self.inplace)\n",
       "                    clone_18: \"f32[1, s41, 768]\" = torch.ops.aten.clone.default(linear_51);  linear_51 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:438 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
       "                    add_673: \"f32[1, s41, 768]\" = torch.ops.aten.add.Tensor(clone_18, layer_norm_16);  clone_18 = layer_norm_16 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\normalization.py:229 in forward, code: return F.layer_norm(\n",
       "                    layer_norm_17: \"f32[1, s41, 768]\" = torch.ops.aten.layer_norm.default(add_673, [768], p_bert_encoder_layer_8_attention_output_layernorm_weight, p_bert_encoder_layer_8_attention_output_layernorm_bias, 1e-12);  add_673 = p_bert_encoder_layer_8_attention_output_layernorm_weight = p_bert_encoder_layer_8_attention_output_layernorm_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_52: \"f32[1, s41, 3072]\" = torch.ops.aten.linear.default(layer_norm_17, p_bert_encoder_layer_8_intermediate_dense_weight, p_bert_encoder_layer_8_intermediate_dense_bias);  p_bert_encoder_layer_8_intermediate_dense_weight = p_bert_encoder_layer_8_intermediate_dense_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\activations.py:85 in forward, code: return self.act(input)\n",
       "                    gelu_8: \"f32[1, s41, 3072]\" = torch.ops.aten.gelu.default(linear_52);  linear_52 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_53: \"f32[1, s41, 768]\" = torch.ops.aten.linear.default(gelu_8, p_bert_encoder_layer_8_output_dense_weight, p_bert_encoder_layer_8_output_dense_bias);  gelu_8 = p_bert_encoder_layer_8_output_dense_weight = p_bert_encoder_layer_8_output_dense_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\dropout.py:73 in forward, code: return F.dropout(input, self.p, self.training, self.inplace)\n",
       "                    clone_19: \"f32[1, s41, 768]\" = torch.ops.aten.clone.default(linear_53);  linear_53 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:527 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
       "                    add_692: \"f32[1, s41, 768]\" = torch.ops.aten.add.Tensor(clone_19, layer_norm_17);  clone_19 = layer_norm_17 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\normalization.py:229 in forward, code: return F.layer_norm(\n",
       "                    layer_norm_18: \"f32[1, s41, 768]\" = torch.ops.aten.layer_norm.default(add_692, [768], p_bert_encoder_layer_8_output_layernorm_weight, p_bert_encoder_layer_8_output_layernorm_bias, 1e-12);  add_692 = p_bert_encoder_layer_8_output_layernorm_weight = p_bert_encoder_layer_8_output_layernorm_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_54: \"f32[1, s41, 768]\" = torch.ops.aten.linear.default(layer_norm_18, p_bert_encoder_layer_9_attention_self_query_weight, p_bert_encoder_layer_9_attention_self_query_bias);  p_bert_encoder_layer_9_attention_self_query_weight = p_bert_encoder_layer_9_attention_self_query_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:363 in forward, code: self.query(hidden_states).view(bsz, -1, self.num_attention_heads, self.attention_head_size).transpose(1, 2)\n",
       "                    view_36: \"f32[1, s41, 12, 64]\" = torch.ops.aten.view.default(linear_54, [1, -1, 12, 64]);  linear_54 = None\n",
       "                    transpose_36: \"f32[1, 12, s41, 64]\" = torch.ops.aten.transpose.int(view_36, 1, 2);  view_36 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_55: \"f32[1, s41, 768]\" = torch.ops.aten.linear.default(layer_norm_18, p_bert_encoder_layer_9_attention_self_key_weight, p_bert_encoder_layer_9_attention_self_key_bias);  p_bert_encoder_layer_9_attention_self_key_weight = p_bert_encoder_layer_9_attention_self_key_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:388 in forward, code: .view(bsz, -1, self.num_attention_heads, self.attention_head_size)\n",
       "                    view_37: \"f32[1, s41, 12, 64]\" = torch.ops.aten.view.default(linear_55, [1, -1, 12, 64]);  linear_55 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:389 in forward, code: .transpose(1, 2)\n",
       "                    transpose_37: \"f32[1, 12, s41, 64]\" = torch.ops.aten.transpose.int(view_37, 1, 2);  view_37 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_56: \"f32[1, s41, 768]\" = torch.ops.aten.linear.default(layer_norm_18, p_bert_encoder_layer_9_attention_self_value_weight, p_bert_encoder_layer_9_attention_self_value_bias);  p_bert_encoder_layer_9_attention_self_value_weight = p_bert_encoder_layer_9_attention_self_value_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:393 in forward, code: .view(bsz, -1, self.num_attention_heads, self.attention_head_size)\n",
       "                    view_38: \"f32[1, s41, 12, 64]\" = torch.ops.aten.view.default(linear_56, [1, -1, 12, 64]);  linear_56 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:394 in forward, code: .transpose(1, 2)\n",
       "                    transpose_38: \"f32[1, 12, s41, 64]\" = torch.ops.aten.transpose.int(view_38, 1, 2);  view_38 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:413 in forward, code: attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
       "                    scaled_dot_product_attention_9: \"f32[1, 12, s41, 64]\" = torch.ops.aten.scaled_dot_product_attention.default(transpose_36, transpose_37, transpose_38, masked_fill);  transpose_36 = transpose_37 = transpose_38 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:422 in forward, code: attn_output = attn_output.transpose(1, 2)\n",
       "                    transpose_39: \"f32[1, s41, 12, 64]\" = torch.ops.aten.transpose.int(scaled_dot_product_attention_9, 1, 2);  scaled_dot_product_attention_9 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:423 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.all_head_size)\n",
       "                    view_39: \"f32[1, s41, 768]\" = torch.ops.aten.view.default(transpose_39, [1, sym_size_int_79, 768]);  transpose_39 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_57: \"f32[1, s41, 768]\" = torch.ops.aten.linear.default(view_39, p_bert_encoder_layer_9_attention_output_dense_weight, p_bert_encoder_layer_9_attention_output_dense_bias);  view_39 = p_bert_encoder_layer_9_attention_output_dense_weight = p_bert_encoder_layer_9_attention_output_dense_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\dropout.py:73 in forward, code: return F.dropout(input, self.p, self.training, self.inplace)\n",
       "                    clone_20: \"f32[1, s41, 768]\" = torch.ops.aten.clone.default(linear_57);  linear_57 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:438 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
       "                    add_745: \"f32[1, s41, 768]\" = torch.ops.aten.add.Tensor(clone_20, layer_norm_18);  clone_20 = layer_norm_18 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\normalization.py:229 in forward, code: return F.layer_norm(\n",
       "                    layer_norm_19: \"f32[1, s41, 768]\" = torch.ops.aten.layer_norm.default(add_745, [768], p_bert_encoder_layer_9_attention_output_layernorm_weight, p_bert_encoder_layer_9_attention_output_layernorm_bias, 1e-12);  add_745 = p_bert_encoder_layer_9_attention_output_layernorm_weight = p_bert_encoder_layer_9_attention_output_layernorm_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_58: \"f32[1, s41, 3072]\" = torch.ops.aten.linear.default(layer_norm_19, p_bert_encoder_layer_9_intermediate_dense_weight, p_bert_encoder_layer_9_intermediate_dense_bias);  p_bert_encoder_layer_9_intermediate_dense_weight = p_bert_encoder_layer_9_intermediate_dense_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\activations.py:85 in forward, code: return self.act(input)\n",
       "                    gelu_9: \"f32[1, s41, 3072]\" = torch.ops.aten.gelu.default(linear_58);  linear_58 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_59: \"f32[1, s41, 768]\" = torch.ops.aten.linear.default(gelu_9, p_bert_encoder_layer_9_output_dense_weight, p_bert_encoder_layer_9_output_dense_bias);  gelu_9 = p_bert_encoder_layer_9_output_dense_weight = p_bert_encoder_layer_9_output_dense_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\dropout.py:73 in forward, code: return F.dropout(input, self.p, self.training, self.inplace)\n",
       "                    clone_21: \"f32[1, s41, 768]\" = torch.ops.aten.clone.default(linear_59);  linear_59 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:527 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
       "                    add_764: \"f32[1, s41, 768]\" = torch.ops.aten.add.Tensor(clone_21, layer_norm_19);  clone_21 = layer_norm_19 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\normalization.py:229 in forward, code: return F.layer_norm(\n",
       "                    layer_norm_20: \"f32[1, s41, 768]\" = torch.ops.aten.layer_norm.default(add_764, [768], p_bert_encoder_layer_9_output_layernorm_weight, p_bert_encoder_layer_9_output_layernorm_bias, 1e-12);  add_764 = p_bert_encoder_layer_9_output_layernorm_weight = p_bert_encoder_layer_9_output_layernorm_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_60: \"f32[1, s41, 768]\" = torch.ops.aten.linear.default(layer_norm_20, p_bert_encoder_layer_10_attention_self_query_weight, p_bert_encoder_layer_10_attention_self_query_bias);  p_bert_encoder_layer_10_attention_self_query_weight = p_bert_encoder_layer_10_attention_self_query_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:363 in forward, code: self.query(hidden_states).view(bsz, -1, self.num_attention_heads, self.attention_head_size).transpose(1, 2)\n",
       "                    view_40: \"f32[1, s41, 12, 64]\" = torch.ops.aten.view.default(linear_60, [1, -1, 12, 64]);  linear_60 = None\n",
       "                    transpose_40: \"f32[1, 12, s41, 64]\" = torch.ops.aten.transpose.int(view_40, 1, 2);  view_40 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_61: \"f32[1, s41, 768]\" = torch.ops.aten.linear.default(layer_norm_20, p_bert_encoder_layer_10_attention_self_key_weight, p_bert_encoder_layer_10_attention_self_key_bias);  p_bert_encoder_layer_10_attention_self_key_weight = p_bert_encoder_layer_10_attention_self_key_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:388 in forward, code: .view(bsz, -1, self.num_attention_heads, self.attention_head_size)\n",
       "                    view_41: \"f32[1, s41, 12, 64]\" = torch.ops.aten.view.default(linear_61, [1, -1, 12, 64]);  linear_61 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:389 in forward, code: .transpose(1, 2)\n",
       "                    transpose_41: \"f32[1, 12, s41, 64]\" = torch.ops.aten.transpose.int(view_41, 1, 2);  view_41 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_62: \"f32[1, s41, 768]\" = torch.ops.aten.linear.default(layer_norm_20, p_bert_encoder_layer_10_attention_self_value_weight, p_bert_encoder_layer_10_attention_self_value_bias);  p_bert_encoder_layer_10_attention_self_value_weight = p_bert_encoder_layer_10_attention_self_value_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:393 in forward, code: .view(bsz, -1, self.num_attention_heads, self.attention_head_size)\n",
       "                    view_42: \"f32[1, s41, 12, 64]\" = torch.ops.aten.view.default(linear_62, [1, -1, 12, 64]);  linear_62 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:394 in forward, code: .transpose(1, 2)\n",
       "                    transpose_42: \"f32[1, 12, s41, 64]\" = torch.ops.aten.transpose.int(view_42, 1, 2);  view_42 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:413 in forward, code: attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
       "                    scaled_dot_product_attention_10: \"f32[1, 12, s41, 64]\" = torch.ops.aten.scaled_dot_product_attention.default(transpose_40, transpose_41, transpose_42, masked_fill);  transpose_40 = transpose_41 = transpose_42 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:422 in forward, code: attn_output = attn_output.transpose(1, 2)\n",
       "                    transpose_43: \"f32[1, s41, 12, 64]\" = torch.ops.aten.transpose.int(scaled_dot_product_attention_10, 1, 2);  scaled_dot_product_attention_10 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:423 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.all_head_size)\n",
       "                    view_43: \"f32[1, s41, 768]\" = torch.ops.aten.view.default(transpose_43, [1, sym_size_int_79, 768]);  transpose_43 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_63: \"f32[1, s41, 768]\" = torch.ops.aten.linear.default(view_43, p_bert_encoder_layer_10_attention_output_dense_weight, p_bert_encoder_layer_10_attention_output_dense_bias);  view_43 = p_bert_encoder_layer_10_attention_output_dense_weight = p_bert_encoder_layer_10_attention_output_dense_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\dropout.py:73 in forward, code: return F.dropout(input, self.p, self.training, self.inplace)\n",
       "                    clone_22: \"f32[1, s41, 768]\" = torch.ops.aten.clone.default(linear_63);  linear_63 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:438 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
       "                    add_817: \"f32[1, s41, 768]\" = torch.ops.aten.add.Tensor(clone_22, layer_norm_20);  clone_22 = layer_norm_20 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\normalization.py:229 in forward, code: return F.layer_norm(\n",
       "                    layer_norm_21: \"f32[1, s41, 768]\" = torch.ops.aten.layer_norm.default(add_817, [768], p_bert_encoder_layer_10_attention_output_layernorm_weight, p_bert_encoder_layer_10_attention_output_layernorm_bias, 1e-12);  add_817 = p_bert_encoder_layer_10_attention_output_layernorm_weight = p_bert_encoder_layer_10_attention_output_layernorm_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_64: \"f32[1, s41, 3072]\" = torch.ops.aten.linear.default(layer_norm_21, p_bert_encoder_layer_10_intermediate_dense_weight, p_bert_encoder_layer_10_intermediate_dense_bias);  p_bert_encoder_layer_10_intermediate_dense_weight = p_bert_encoder_layer_10_intermediate_dense_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\activations.py:85 in forward, code: return self.act(input)\n",
       "                    gelu_10: \"f32[1, s41, 3072]\" = torch.ops.aten.gelu.default(linear_64);  linear_64 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_65: \"f32[1, s41, 768]\" = torch.ops.aten.linear.default(gelu_10, p_bert_encoder_layer_10_output_dense_weight, p_bert_encoder_layer_10_output_dense_bias);  gelu_10 = p_bert_encoder_layer_10_output_dense_weight = p_bert_encoder_layer_10_output_dense_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\dropout.py:73 in forward, code: return F.dropout(input, self.p, self.training, self.inplace)\n",
       "                    clone_23: \"f32[1, s41, 768]\" = torch.ops.aten.clone.default(linear_65);  linear_65 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:527 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
       "                    add_836: \"f32[1, s41, 768]\" = torch.ops.aten.add.Tensor(clone_23, layer_norm_21);  clone_23 = layer_norm_21 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\normalization.py:229 in forward, code: return F.layer_norm(\n",
       "                    layer_norm_22: \"f32[1, s41, 768]\" = torch.ops.aten.layer_norm.default(add_836, [768], p_bert_encoder_layer_10_output_layernorm_weight, p_bert_encoder_layer_10_output_layernorm_bias, 1e-12);  add_836 = p_bert_encoder_layer_10_output_layernorm_weight = p_bert_encoder_layer_10_output_layernorm_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_66: \"f32[1, s41, 768]\" = torch.ops.aten.linear.default(layer_norm_22, p_bert_encoder_layer_11_attention_self_query_weight, p_bert_encoder_layer_11_attention_self_query_bias);  p_bert_encoder_layer_11_attention_self_query_weight = p_bert_encoder_layer_11_attention_self_query_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:363 in forward, code: self.query(hidden_states).view(bsz, -1, self.num_attention_heads, self.attention_head_size).transpose(1, 2)\n",
       "                    view_44: \"f32[1, s41, 12, 64]\" = torch.ops.aten.view.default(linear_66, [1, -1, 12, 64]);  linear_66 = None\n",
       "                    transpose_44: \"f32[1, 12, s41, 64]\" = torch.ops.aten.transpose.int(view_44, 1, 2);  view_44 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_67: \"f32[1, s41, 768]\" = torch.ops.aten.linear.default(layer_norm_22, p_bert_encoder_layer_11_attention_self_key_weight, p_bert_encoder_layer_11_attention_self_key_bias);  p_bert_encoder_layer_11_attention_self_key_weight = p_bert_encoder_layer_11_attention_self_key_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:388 in forward, code: .view(bsz, -1, self.num_attention_heads, self.attention_head_size)\n",
       "                    view_45: \"f32[1, s41, 12, 64]\" = torch.ops.aten.view.default(linear_67, [1, -1, 12, 64]);  linear_67 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:389 in forward, code: .transpose(1, 2)\n",
       "                    transpose_45: \"f32[1, 12, s41, 64]\" = torch.ops.aten.transpose.int(view_45, 1, 2);  view_45 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_68: \"f32[1, s41, 768]\" = torch.ops.aten.linear.default(layer_norm_22, p_bert_encoder_layer_11_attention_self_value_weight, p_bert_encoder_layer_11_attention_self_value_bias);  p_bert_encoder_layer_11_attention_self_value_weight = p_bert_encoder_layer_11_attention_self_value_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:393 in forward, code: .view(bsz, -1, self.num_attention_heads, self.attention_head_size)\n",
       "                    view_46: \"f32[1, s41, 12, 64]\" = torch.ops.aten.view.default(linear_68, [1, -1, 12, 64]);  linear_68 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:394 in forward, code: .transpose(1, 2)\n",
       "                    transpose_46: \"f32[1, 12, s41, 64]\" = torch.ops.aten.transpose.int(view_46, 1, 2);  view_46 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:413 in forward, code: attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
       "                    scaled_dot_product_attention_11: \"f32[1, 12, s41, 64]\" = torch.ops.aten.scaled_dot_product_attention.default(transpose_44, transpose_45, transpose_46, masked_fill);  transpose_44 = transpose_45 = transpose_46 = masked_fill = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:422 in forward, code: attn_output = attn_output.transpose(1, 2)\n",
       "                    transpose_47: \"f32[1, s41, 12, 64]\" = torch.ops.aten.transpose.int(scaled_dot_product_attention_11, 1, 2);  scaled_dot_product_attention_11 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:423 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.all_head_size)\n",
       "                    view_47: \"f32[1, s41, 768]\" = torch.ops.aten.view.default(transpose_47, [1, sym_size_int_79, 768]);  transpose_47 = sym_size_int_79 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_69: \"f32[1, s41, 768]\" = torch.ops.aten.linear.default(view_47, p_bert_encoder_layer_11_attention_output_dense_weight, p_bert_encoder_layer_11_attention_output_dense_bias);  view_47 = p_bert_encoder_layer_11_attention_output_dense_weight = p_bert_encoder_layer_11_attention_output_dense_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\dropout.py:73 in forward, code: return F.dropout(input, self.p, self.training, self.inplace)\n",
       "                    clone_24: \"f32[1, s41, 768]\" = torch.ops.aten.clone.default(linear_69);  linear_69 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:438 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
       "                    add_889: \"f32[1, s41, 768]\" = torch.ops.aten.add.Tensor(clone_24, layer_norm_22);  clone_24 = layer_norm_22 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\normalization.py:229 in forward, code: return F.layer_norm(\n",
       "                    layer_norm_23: \"f32[1, s41, 768]\" = torch.ops.aten.layer_norm.default(add_889, [768], p_bert_encoder_layer_11_attention_output_layernorm_weight, p_bert_encoder_layer_11_attention_output_layernorm_bias, 1e-12);  add_889 = p_bert_encoder_layer_11_attention_output_layernorm_weight = p_bert_encoder_layer_11_attention_output_layernorm_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_70: \"f32[1, s41, 3072]\" = torch.ops.aten.linear.default(layer_norm_23, p_bert_encoder_layer_11_intermediate_dense_weight, p_bert_encoder_layer_11_intermediate_dense_bias);  p_bert_encoder_layer_11_intermediate_dense_weight = p_bert_encoder_layer_11_intermediate_dense_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\activations.py:85 in forward, code: return self.act(input)\n",
       "                    gelu_11: \"f32[1, s41, 3072]\" = torch.ops.aten.gelu.default(linear_70);  linear_70 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_71: \"f32[1, s41, 768]\" = torch.ops.aten.linear.default(gelu_11, p_bert_encoder_layer_11_output_dense_weight, p_bert_encoder_layer_11_output_dense_bias);  gelu_11 = p_bert_encoder_layer_11_output_dense_weight = p_bert_encoder_layer_11_output_dense_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\dropout.py:73 in forward, code: return F.dropout(input, self.p, self.training, self.inplace)\n",
       "                    clone_25: \"f32[1, s41, 768]\" = torch.ops.aten.clone.default(linear_71);  linear_71 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:527 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
       "                    add_908: \"f32[1, s41, 768]\" = torch.ops.aten.add.Tensor(clone_25, layer_norm_23);  clone_25 = layer_norm_23 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\normalization.py:229 in forward, code: return F.layer_norm(\n",
       "                    layer_norm_24: \"f32[1, s41, 768]\" = torch.ops.aten.layer_norm.default(add_908, [768], p_bert_encoder_layer_11_output_layernorm_weight, p_bert_encoder_layer_11_output_layernorm_bias, 1e-12);  add_908 = p_bert_encoder_layer_11_output_layernorm_weight = p_bert_encoder_layer_11_output_layernorm_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:700 in forward, code: first_token_tensor = hidden_states[:, 0]\n",
       "                    select: \"f32[1, 768]\" = torch.ops.aten.select.int(layer_norm_24, 1, 0);  layer_norm_24 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_72: \"f32[1, 768]\" = torch.ops.aten.linear.default(select, p_bert_pooler_dense_weight, p_bert_pooler_dense_bias);  select = p_bert_pooler_dense_weight = p_bert_pooler_dense_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:430 in forward, code: return torch.tanh(input)\n",
       "                    tanh: \"f32[1, 768]\" = torch.ops.aten.tanh.default(linear_72);  linear_72 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\dropout.py:73 in forward, code: return F.dropout(input, self.p, self.training, self.inplace)\n",
       "                    clone_26: \"f32[1, 768]\" = torch.ops.aten.clone.default(tanh);  tanh = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_73: \"f32[1, 2]\" = torch.ops.aten.linear.default(clone_26, p_classifier_weight, p_classifier_bias);  clone_26 = p_classifier_weight = p_classifier_bias = None\n",
       "                    return (linear_73,)\n",
       "            \n",
       "        Graph signature: \n",
       "            # inputs\n",
       "            p_bert_embeddings_word_embeddings_weight: PARAMETER target='bert.embeddings.word_embeddings.weight'\n",
       "            p_bert_embeddings_position_embeddings_weight: PARAMETER target='bert.embeddings.position_embeddings.weight'\n",
       "            p_bert_embeddings_token_type_embeddings_weight: PARAMETER target='bert.embeddings.token_type_embeddings.weight'\n",
       "            p_bert_embeddings_layernorm_weight: PARAMETER target='bert.embeddings.LayerNorm.weight'\n",
       "            p_bert_embeddings_layernorm_bias: PARAMETER target='bert.embeddings.LayerNorm.bias'\n",
       "            p_bert_encoder_layer_0_attention_self_query_weight: PARAMETER target='bert.encoder.layer.0.attention.self.query.weight'\n",
       "            p_bert_encoder_layer_0_attention_self_query_bias: PARAMETER target='bert.encoder.layer.0.attention.self.query.bias'\n",
       "            p_bert_encoder_layer_0_attention_self_key_weight: PARAMETER target='bert.encoder.layer.0.attention.self.key.weight'\n",
       "            p_bert_encoder_layer_0_attention_self_key_bias: PARAMETER target='bert.encoder.layer.0.attention.self.key.bias'\n",
       "            p_bert_encoder_layer_0_attention_self_value_weight: PARAMETER target='bert.encoder.layer.0.attention.self.value.weight'\n",
       "            p_bert_encoder_layer_0_attention_self_value_bias: PARAMETER target='bert.encoder.layer.0.attention.self.value.bias'\n",
       "            p_bert_encoder_layer_0_attention_output_dense_weight: PARAMETER target='bert.encoder.layer.0.attention.output.dense.weight'\n",
       "            p_bert_encoder_layer_0_attention_output_dense_bias: PARAMETER target='bert.encoder.layer.0.attention.output.dense.bias'\n",
       "            p_bert_encoder_layer_0_attention_output_layernorm_weight: PARAMETER target='bert.encoder.layer.0.attention.output.LayerNorm.weight'\n",
       "            p_bert_encoder_layer_0_attention_output_layernorm_bias: PARAMETER target='bert.encoder.layer.0.attention.output.LayerNorm.bias'\n",
       "            p_bert_encoder_layer_0_intermediate_dense_weight: PARAMETER target='bert.encoder.layer.0.intermediate.dense.weight'\n",
       "            p_bert_encoder_layer_0_intermediate_dense_bias: PARAMETER target='bert.encoder.layer.0.intermediate.dense.bias'\n",
       "            p_bert_encoder_layer_0_output_dense_weight: PARAMETER target='bert.encoder.layer.0.output.dense.weight'\n",
       "            p_bert_encoder_layer_0_output_dense_bias: PARAMETER target='bert.encoder.layer.0.output.dense.bias'\n",
       "            p_bert_encoder_layer_0_output_layernorm_weight: PARAMETER target='bert.encoder.layer.0.output.LayerNorm.weight'\n",
       "            p_bert_encoder_layer_0_output_layernorm_bias: PARAMETER target='bert.encoder.layer.0.output.LayerNorm.bias'\n",
       "            p_bert_encoder_layer_1_attention_self_query_weight: PARAMETER target='bert.encoder.layer.1.attention.self.query.weight'\n",
       "            p_bert_encoder_layer_1_attention_self_query_bias: PARAMETER target='bert.encoder.layer.1.attention.self.query.bias'\n",
       "            p_bert_encoder_layer_1_attention_self_key_weight: PARAMETER target='bert.encoder.layer.1.attention.self.key.weight'\n",
       "            p_bert_encoder_layer_1_attention_self_key_bias: PARAMETER target='bert.encoder.layer.1.attention.self.key.bias'\n",
       "            p_bert_encoder_layer_1_attention_self_value_weight: PARAMETER target='bert.encoder.layer.1.attention.self.value.weight'\n",
       "            p_bert_encoder_layer_1_attention_self_value_bias: PARAMETER target='bert.encoder.layer.1.attention.self.value.bias'\n",
       "            p_bert_encoder_layer_1_attention_output_dense_weight: PARAMETER target='bert.encoder.layer.1.attention.output.dense.weight'\n",
       "            p_bert_encoder_layer_1_attention_output_dense_bias: PARAMETER target='bert.encoder.layer.1.attention.output.dense.bias'\n",
       "            p_bert_encoder_layer_1_attention_output_layernorm_weight: PARAMETER target='bert.encoder.layer.1.attention.output.LayerNorm.weight'\n",
       "            p_bert_encoder_layer_1_attention_output_layernorm_bias: PARAMETER target='bert.encoder.layer.1.attention.output.LayerNorm.bias'\n",
       "            p_bert_encoder_layer_1_intermediate_dense_weight: PARAMETER target='bert.encoder.layer.1.intermediate.dense.weight'\n",
       "            p_bert_encoder_layer_1_intermediate_dense_bias: PARAMETER target='bert.encoder.layer.1.intermediate.dense.bias'\n",
       "            p_bert_encoder_layer_1_output_dense_weight: PARAMETER target='bert.encoder.layer.1.output.dense.weight'\n",
       "            p_bert_encoder_layer_1_output_dense_bias: PARAMETER target='bert.encoder.layer.1.output.dense.bias'\n",
       "            p_bert_encoder_layer_1_output_layernorm_weight: PARAMETER target='bert.encoder.layer.1.output.LayerNorm.weight'\n",
       "            p_bert_encoder_layer_1_output_layernorm_bias: PARAMETER target='bert.encoder.layer.1.output.LayerNorm.bias'\n",
       "            p_bert_encoder_layer_2_attention_self_query_weight: PARAMETER target='bert.encoder.layer.2.attention.self.query.weight'\n",
       "            p_bert_encoder_layer_2_attention_self_query_bias: PARAMETER target='bert.encoder.layer.2.attention.self.query.bias'\n",
       "            p_bert_encoder_layer_2_attention_self_key_weight: PARAMETER target='bert.encoder.layer.2.attention.self.key.weight'\n",
       "            p_bert_encoder_layer_2_attention_self_key_bias: PARAMETER target='bert.encoder.layer.2.attention.self.key.bias'\n",
       "            p_bert_encoder_layer_2_attention_self_value_weight: PARAMETER target='bert.encoder.layer.2.attention.self.value.weight'\n",
       "            p_bert_encoder_layer_2_attention_self_value_bias: PARAMETER target='bert.encoder.layer.2.attention.self.value.bias'\n",
       "            p_bert_encoder_layer_2_attention_output_dense_weight: PARAMETER target='bert.encoder.layer.2.attention.output.dense.weight'\n",
       "            p_bert_encoder_layer_2_attention_output_dense_bias: PARAMETER target='bert.encoder.layer.2.attention.output.dense.bias'\n",
       "            p_bert_encoder_layer_2_attention_output_layernorm_weight: PARAMETER target='bert.encoder.layer.2.attention.output.LayerNorm.weight'\n",
       "            p_bert_encoder_layer_2_attention_output_layernorm_bias: PARAMETER target='bert.encoder.layer.2.attention.output.LayerNorm.bias'\n",
       "            p_bert_encoder_layer_2_intermediate_dense_weight: PARAMETER target='bert.encoder.layer.2.intermediate.dense.weight'\n",
       "            p_bert_encoder_layer_2_intermediate_dense_bias: PARAMETER target='bert.encoder.layer.2.intermediate.dense.bias'\n",
       "            p_bert_encoder_layer_2_output_dense_weight: PARAMETER target='bert.encoder.layer.2.output.dense.weight'\n",
       "            p_bert_encoder_layer_2_output_dense_bias: PARAMETER target='bert.encoder.layer.2.output.dense.bias'\n",
       "            p_bert_encoder_layer_2_output_layernorm_weight: PARAMETER target='bert.encoder.layer.2.output.LayerNorm.weight'\n",
       "            p_bert_encoder_layer_2_output_layernorm_bias: PARAMETER target='bert.encoder.layer.2.output.LayerNorm.bias'\n",
       "            p_bert_encoder_layer_3_attention_self_query_weight: PARAMETER target='bert.encoder.layer.3.attention.self.query.weight'\n",
       "            p_bert_encoder_layer_3_attention_self_query_bias: PARAMETER target='bert.encoder.layer.3.attention.self.query.bias'\n",
       "            p_bert_encoder_layer_3_attention_self_key_weight: PARAMETER target='bert.encoder.layer.3.attention.self.key.weight'\n",
       "            p_bert_encoder_layer_3_attention_self_key_bias: PARAMETER target='bert.encoder.layer.3.attention.self.key.bias'\n",
       "            p_bert_encoder_layer_3_attention_self_value_weight: PARAMETER target='bert.encoder.layer.3.attention.self.value.weight'\n",
       "            p_bert_encoder_layer_3_attention_self_value_bias: PARAMETER target='bert.encoder.layer.3.attention.self.value.bias'\n",
       "            p_bert_encoder_layer_3_attention_output_dense_weight: PARAMETER target='bert.encoder.layer.3.attention.output.dense.weight'\n",
       "            p_bert_encoder_layer_3_attention_output_dense_bias: PARAMETER target='bert.encoder.layer.3.attention.output.dense.bias'\n",
       "            p_bert_encoder_layer_3_attention_output_layernorm_weight: PARAMETER target='bert.encoder.layer.3.attention.output.LayerNorm.weight'\n",
       "            p_bert_encoder_layer_3_attention_output_layernorm_bias: PARAMETER target='bert.encoder.layer.3.attention.output.LayerNorm.bias'\n",
       "            p_bert_encoder_layer_3_intermediate_dense_weight: PARAMETER target='bert.encoder.layer.3.intermediate.dense.weight'\n",
       "            p_bert_encoder_layer_3_intermediate_dense_bias: PARAMETER target='bert.encoder.layer.3.intermediate.dense.bias'\n",
       "            p_bert_encoder_layer_3_output_dense_weight: PARAMETER target='bert.encoder.layer.3.output.dense.weight'\n",
       "            p_bert_encoder_layer_3_output_dense_bias: PARAMETER target='bert.encoder.layer.3.output.dense.bias'\n",
       "            p_bert_encoder_layer_3_output_layernorm_weight: PARAMETER target='bert.encoder.layer.3.output.LayerNorm.weight'\n",
       "            p_bert_encoder_layer_3_output_layernorm_bias: PARAMETER target='bert.encoder.layer.3.output.LayerNorm.bias'\n",
       "            p_bert_encoder_layer_4_attention_self_query_weight: PARAMETER target='bert.encoder.layer.4.attention.self.query.weight'\n",
       "            p_bert_encoder_layer_4_attention_self_query_bias: PARAMETER target='bert.encoder.layer.4.attention.self.query.bias'\n",
       "            p_bert_encoder_layer_4_attention_self_key_weight: PARAMETER target='bert.encoder.layer.4.attention.self.key.weight'\n",
       "            p_bert_encoder_layer_4_attention_self_key_bias: PARAMETER target='bert.encoder.layer.4.attention.self.key.bias'\n",
       "            p_bert_encoder_layer_4_attention_self_value_weight: PARAMETER target='bert.encoder.layer.4.attention.self.value.weight'\n",
       "            p_bert_encoder_layer_4_attention_self_value_bias: PARAMETER target='bert.encoder.layer.4.attention.self.value.bias'\n",
       "            p_bert_encoder_layer_4_attention_output_dense_weight: PARAMETER target='bert.encoder.layer.4.attention.output.dense.weight'\n",
       "            p_bert_encoder_layer_4_attention_output_dense_bias: PARAMETER target='bert.encoder.layer.4.attention.output.dense.bias'\n",
       "            p_bert_encoder_layer_4_attention_output_layernorm_weight: PARAMETER target='bert.encoder.layer.4.attention.output.LayerNorm.weight'\n",
       "            p_bert_encoder_layer_4_attention_output_layernorm_bias: PARAMETER target='bert.encoder.layer.4.attention.output.LayerNorm.bias'\n",
       "            p_bert_encoder_layer_4_intermediate_dense_weight: PARAMETER target='bert.encoder.layer.4.intermediate.dense.weight'\n",
       "            p_bert_encoder_layer_4_intermediate_dense_bias: PARAMETER target='bert.encoder.layer.4.intermediate.dense.bias'\n",
       "            p_bert_encoder_layer_4_output_dense_weight: PARAMETER target='bert.encoder.layer.4.output.dense.weight'\n",
       "            p_bert_encoder_layer_4_output_dense_bias: PARAMETER target='bert.encoder.layer.4.output.dense.bias'\n",
       "            p_bert_encoder_layer_4_output_layernorm_weight: PARAMETER target='bert.encoder.layer.4.output.LayerNorm.weight'\n",
       "            p_bert_encoder_layer_4_output_layernorm_bias: PARAMETER target='bert.encoder.layer.4.output.LayerNorm.bias'\n",
       "            p_bert_encoder_layer_5_attention_self_query_weight: PARAMETER target='bert.encoder.layer.5.attention.self.query.weight'\n",
       "            p_bert_encoder_layer_5_attention_self_query_bias: PARAMETER target='bert.encoder.layer.5.attention.self.query.bias'\n",
       "            p_bert_encoder_layer_5_attention_self_key_weight: PARAMETER target='bert.encoder.layer.5.attention.self.key.weight'\n",
       "            p_bert_encoder_layer_5_attention_self_key_bias: PARAMETER target='bert.encoder.layer.5.attention.self.key.bias'\n",
       "            p_bert_encoder_layer_5_attention_self_value_weight: PARAMETER target='bert.encoder.layer.5.attention.self.value.weight'\n",
       "            p_bert_encoder_layer_5_attention_self_value_bias: PARAMETER target='bert.encoder.layer.5.attention.self.value.bias'\n",
       "            p_bert_encoder_layer_5_attention_output_dense_weight: PARAMETER target='bert.encoder.layer.5.attention.output.dense.weight'\n",
       "            p_bert_encoder_layer_5_attention_output_dense_bias: PARAMETER target='bert.encoder.layer.5.attention.output.dense.bias'\n",
       "            p_bert_encoder_layer_5_attention_output_layernorm_weight: PARAMETER target='bert.encoder.layer.5.attention.output.LayerNorm.weight'\n",
       "            p_bert_encoder_layer_5_attention_output_layernorm_bias: PARAMETER target='bert.encoder.layer.5.attention.output.LayerNorm.bias'\n",
       "            p_bert_encoder_layer_5_intermediate_dense_weight: PARAMETER target='bert.encoder.layer.5.intermediate.dense.weight'\n",
       "            p_bert_encoder_layer_5_intermediate_dense_bias: PARAMETER target='bert.encoder.layer.5.intermediate.dense.bias'\n",
       "            p_bert_encoder_layer_5_output_dense_weight: PARAMETER target='bert.encoder.layer.5.output.dense.weight'\n",
       "            p_bert_encoder_layer_5_output_dense_bias: PARAMETER target='bert.encoder.layer.5.output.dense.bias'\n",
       "            p_bert_encoder_layer_5_output_layernorm_weight: PARAMETER target='bert.encoder.layer.5.output.LayerNorm.weight'\n",
       "            p_bert_encoder_layer_5_output_layernorm_bias: PARAMETER target='bert.encoder.layer.5.output.LayerNorm.bias'\n",
       "            p_bert_encoder_layer_6_attention_self_query_weight: PARAMETER target='bert.encoder.layer.6.attention.self.query.weight'\n",
       "            p_bert_encoder_layer_6_attention_self_query_bias: PARAMETER target='bert.encoder.layer.6.attention.self.query.bias'\n",
       "            p_bert_encoder_layer_6_attention_self_key_weight: PARAMETER target='bert.encoder.layer.6.attention.self.key.weight'\n",
       "            p_bert_encoder_layer_6_attention_self_key_bias: PARAMETER target='bert.encoder.layer.6.attention.self.key.bias'\n",
       "            p_bert_encoder_layer_6_attention_self_value_weight: PARAMETER target='bert.encoder.layer.6.attention.self.value.weight'\n",
       "            p_bert_encoder_layer_6_attention_self_value_bias: PARAMETER target='bert.encoder.layer.6.attention.self.value.bias'\n",
       "            p_bert_encoder_layer_6_attention_output_dense_weight: PARAMETER target='bert.encoder.layer.6.attention.output.dense.weight'\n",
       "            p_bert_encoder_layer_6_attention_output_dense_bias: PARAMETER target='bert.encoder.layer.6.attention.output.dense.bias'\n",
       "            p_bert_encoder_layer_6_attention_output_layernorm_weight: PARAMETER target='bert.encoder.layer.6.attention.output.LayerNorm.weight'\n",
       "            p_bert_encoder_layer_6_attention_output_layernorm_bias: PARAMETER target='bert.encoder.layer.6.attention.output.LayerNorm.bias'\n",
       "            p_bert_encoder_layer_6_intermediate_dense_weight: PARAMETER target='bert.encoder.layer.6.intermediate.dense.weight'\n",
       "            p_bert_encoder_layer_6_intermediate_dense_bias: PARAMETER target='bert.encoder.layer.6.intermediate.dense.bias'\n",
       "            p_bert_encoder_layer_6_output_dense_weight: PARAMETER target='bert.encoder.layer.6.output.dense.weight'\n",
       "            p_bert_encoder_layer_6_output_dense_bias: PARAMETER target='bert.encoder.layer.6.output.dense.bias'\n",
       "            p_bert_encoder_layer_6_output_layernorm_weight: PARAMETER target='bert.encoder.layer.6.output.LayerNorm.weight'\n",
       "            p_bert_encoder_layer_6_output_layernorm_bias: PARAMETER target='bert.encoder.layer.6.output.LayerNorm.bias'\n",
       "            p_bert_encoder_layer_7_attention_self_query_weight: PARAMETER target='bert.encoder.layer.7.attention.self.query.weight'\n",
       "            p_bert_encoder_layer_7_attention_self_query_bias: PARAMETER target='bert.encoder.layer.7.attention.self.query.bias'\n",
       "            p_bert_encoder_layer_7_attention_self_key_weight: PARAMETER target='bert.encoder.layer.7.attention.self.key.weight'\n",
       "            p_bert_encoder_layer_7_attention_self_key_bias: PARAMETER target='bert.encoder.layer.7.attention.self.key.bias'\n",
       "            p_bert_encoder_layer_7_attention_self_value_weight: PARAMETER target='bert.encoder.layer.7.attention.self.value.weight'\n",
       "            p_bert_encoder_layer_7_attention_self_value_bias: PARAMETER target='bert.encoder.layer.7.attention.self.value.bias'\n",
       "            p_bert_encoder_layer_7_attention_output_dense_weight: PARAMETER target='bert.encoder.layer.7.attention.output.dense.weight'\n",
       "            p_bert_encoder_layer_7_attention_output_dense_bias: PARAMETER target='bert.encoder.layer.7.attention.output.dense.bias'\n",
       "            p_bert_encoder_layer_7_attention_output_layernorm_weight: PARAMETER target='bert.encoder.layer.7.attention.output.LayerNorm.weight'\n",
       "            p_bert_encoder_layer_7_attention_output_layernorm_bias: PARAMETER target='bert.encoder.layer.7.attention.output.LayerNorm.bias'\n",
       "            p_bert_encoder_layer_7_intermediate_dense_weight: PARAMETER target='bert.encoder.layer.7.intermediate.dense.weight'\n",
       "            p_bert_encoder_layer_7_intermediate_dense_bias: PARAMETER target='bert.encoder.layer.7.intermediate.dense.bias'\n",
       "            p_bert_encoder_layer_7_output_dense_weight: PARAMETER target='bert.encoder.layer.7.output.dense.weight'\n",
       "            p_bert_encoder_layer_7_output_dense_bias: PARAMETER target='bert.encoder.layer.7.output.dense.bias'\n",
       "            p_bert_encoder_layer_7_output_layernorm_weight: PARAMETER target='bert.encoder.layer.7.output.LayerNorm.weight'\n",
       "            p_bert_encoder_layer_7_output_layernorm_bias: PARAMETER target='bert.encoder.layer.7.output.LayerNorm.bias'\n",
       "            p_bert_encoder_layer_8_attention_self_query_weight: PARAMETER target='bert.encoder.layer.8.attention.self.query.weight'\n",
       "            p_bert_encoder_layer_8_attention_self_query_bias: PARAMETER target='bert.encoder.layer.8.attention.self.query.bias'\n",
       "            p_bert_encoder_layer_8_attention_self_key_weight: PARAMETER target='bert.encoder.layer.8.attention.self.key.weight'\n",
       "            p_bert_encoder_layer_8_attention_self_key_bias: PARAMETER target='bert.encoder.layer.8.attention.self.key.bias'\n",
       "            p_bert_encoder_layer_8_attention_self_value_weight: PARAMETER target='bert.encoder.layer.8.attention.self.value.weight'\n",
       "            p_bert_encoder_layer_8_attention_self_value_bias: PARAMETER target='bert.encoder.layer.8.attention.self.value.bias'\n",
       "            p_bert_encoder_layer_8_attention_output_dense_weight: PARAMETER target='bert.encoder.layer.8.attention.output.dense.weight'\n",
       "            p_bert_encoder_layer_8_attention_output_dense_bias: PARAMETER target='bert.encoder.layer.8.attention.output.dense.bias'\n",
       "            p_bert_encoder_layer_8_attention_output_layernorm_weight: PARAMETER target='bert.encoder.layer.8.attention.output.LayerNorm.weight'\n",
       "            p_bert_encoder_layer_8_attention_output_layernorm_bias: PARAMETER target='bert.encoder.layer.8.attention.output.LayerNorm.bias'\n",
       "            p_bert_encoder_layer_8_intermediate_dense_weight: PARAMETER target='bert.encoder.layer.8.intermediate.dense.weight'\n",
       "            p_bert_encoder_layer_8_intermediate_dense_bias: PARAMETER target='bert.encoder.layer.8.intermediate.dense.bias'\n",
       "            p_bert_encoder_layer_8_output_dense_weight: PARAMETER target='bert.encoder.layer.8.output.dense.weight'\n",
       "            p_bert_encoder_layer_8_output_dense_bias: PARAMETER target='bert.encoder.layer.8.output.dense.bias'\n",
       "            p_bert_encoder_layer_8_output_layernorm_weight: PARAMETER target='bert.encoder.layer.8.output.LayerNorm.weight'\n",
       "            p_bert_encoder_layer_8_output_layernorm_bias: PARAMETER target='bert.encoder.layer.8.output.LayerNorm.bias'\n",
       "            p_bert_encoder_layer_9_attention_self_query_weight: PARAMETER target='bert.encoder.layer.9.attention.self.query.weight'\n",
       "            p_bert_encoder_layer_9_attention_self_query_bias: PARAMETER target='bert.encoder.layer.9.attention.self.query.bias'\n",
       "            p_bert_encoder_layer_9_attention_self_key_weight: PARAMETER target='bert.encoder.layer.9.attention.self.key.weight'\n",
       "            p_bert_encoder_layer_9_attention_self_key_bias: PARAMETER target='bert.encoder.layer.9.attention.self.key.bias'\n",
       "            p_bert_encoder_layer_9_attention_self_value_weight: PARAMETER target='bert.encoder.layer.9.attention.self.value.weight'\n",
       "            p_bert_encoder_layer_9_attention_self_value_bias: PARAMETER target='bert.encoder.layer.9.attention.self.value.bias'\n",
       "            p_bert_encoder_layer_9_attention_output_dense_weight: PARAMETER target='bert.encoder.layer.9.attention.output.dense.weight'\n",
       "            p_bert_encoder_layer_9_attention_output_dense_bias: PARAMETER target='bert.encoder.layer.9.attention.output.dense.bias'\n",
       "            p_bert_encoder_layer_9_attention_output_layernorm_weight: PARAMETER target='bert.encoder.layer.9.attention.output.LayerNorm.weight'\n",
       "            p_bert_encoder_layer_9_attention_output_layernorm_bias: PARAMETER target='bert.encoder.layer.9.attention.output.LayerNorm.bias'\n",
       "            p_bert_encoder_layer_9_intermediate_dense_weight: PARAMETER target='bert.encoder.layer.9.intermediate.dense.weight'\n",
       "            p_bert_encoder_layer_9_intermediate_dense_bias: PARAMETER target='bert.encoder.layer.9.intermediate.dense.bias'\n",
       "            p_bert_encoder_layer_9_output_dense_weight: PARAMETER target='bert.encoder.layer.9.output.dense.weight'\n",
       "            p_bert_encoder_layer_9_output_dense_bias: PARAMETER target='bert.encoder.layer.9.output.dense.bias'\n",
       "            p_bert_encoder_layer_9_output_layernorm_weight: PARAMETER target='bert.encoder.layer.9.output.LayerNorm.weight'\n",
       "            p_bert_encoder_layer_9_output_layernorm_bias: PARAMETER target='bert.encoder.layer.9.output.LayerNorm.bias'\n",
       "            p_bert_encoder_layer_10_attention_self_query_weight: PARAMETER target='bert.encoder.layer.10.attention.self.query.weight'\n",
       "            p_bert_encoder_layer_10_attention_self_query_bias: PARAMETER target='bert.encoder.layer.10.attention.self.query.bias'\n",
       "            p_bert_encoder_layer_10_attention_self_key_weight: PARAMETER target='bert.encoder.layer.10.attention.self.key.weight'\n",
       "            p_bert_encoder_layer_10_attention_self_key_bias: PARAMETER target='bert.encoder.layer.10.attention.self.key.bias'\n",
       "            p_bert_encoder_layer_10_attention_self_value_weight: PARAMETER target='bert.encoder.layer.10.attention.self.value.weight'\n",
       "            p_bert_encoder_layer_10_attention_self_value_bias: PARAMETER target='bert.encoder.layer.10.attention.self.value.bias'\n",
       "            p_bert_encoder_layer_10_attention_output_dense_weight: PARAMETER target='bert.encoder.layer.10.attention.output.dense.weight'\n",
       "            p_bert_encoder_layer_10_attention_output_dense_bias: PARAMETER target='bert.encoder.layer.10.attention.output.dense.bias'\n",
       "            p_bert_encoder_layer_10_attention_output_layernorm_weight: PARAMETER target='bert.encoder.layer.10.attention.output.LayerNorm.weight'\n",
       "            p_bert_encoder_layer_10_attention_output_layernorm_bias: PARAMETER target='bert.encoder.layer.10.attention.output.LayerNorm.bias'\n",
       "            p_bert_encoder_layer_10_intermediate_dense_weight: PARAMETER target='bert.encoder.layer.10.intermediate.dense.weight'\n",
       "            p_bert_encoder_layer_10_intermediate_dense_bias: PARAMETER target='bert.encoder.layer.10.intermediate.dense.bias'\n",
       "            p_bert_encoder_layer_10_output_dense_weight: PARAMETER target='bert.encoder.layer.10.output.dense.weight'\n",
       "            p_bert_encoder_layer_10_output_dense_bias: PARAMETER target='bert.encoder.layer.10.output.dense.bias'\n",
       "            p_bert_encoder_layer_10_output_layernorm_weight: PARAMETER target='bert.encoder.layer.10.output.LayerNorm.weight'\n",
       "            p_bert_encoder_layer_10_output_layernorm_bias: PARAMETER target='bert.encoder.layer.10.output.LayerNorm.bias'\n",
       "            p_bert_encoder_layer_11_attention_self_query_weight: PARAMETER target='bert.encoder.layer.11.attention.self.query.weight'\n",
       "            p_bert_encoder_layer_11_attention_self_query_bias: PARAMETER target='bert.encoder.layer.11.attention.self.query.bias'\n",
       "            p_bert_encoder_layer_11_attention_self_key_weight: PARAMETER target='bert.encoder.layer.11.attention.self.key.weight'\n",
       "            p_bert_encoder_layer_11_attention_self_key_bias: PARAMETER target='bert.encoder.layer.11.attention.self.key.bias'\n",
       "            p_bert_encoder_layer_11_attention_self_value_weight: PARAMETER target='bert.encoder.layer.11.attention.self.value.weight'\n",
       "            p_bert_encoder_layer_11_attention_self_value_bias: PARAMETER target='bert.encoder.layer.11.attention.self.value.bias'\n",
       "            p_bert_encoder_layer_11_attention_output_dense_weight: PARAMETER target='bert.encoder.layer.11.attention.output.dense.weight'\n",
       "            p_bert_encoder_layer_11_attention_output_dense_bias: PARAMETER target='bert.encoder.layer.11.attention.output.dense.bias'\n",
       "            p_bert_encoder_layer_11_attention_output_layernorm_weight: PARAMETER target='bert.encoder.layer.11.attention.output.LayerNorm.weight'\n",
       "            p_bert_encoder_layer_11_attention_output_layernorm_bias: PARAMETER target='bert.encoder.layer.11.attention.output.LayerNorm.bias'\n",
       "            p_bert_encoder_layer_11_intermediate_dense_weight: PARAMETER target='bert.encoder.layer.11.intermediate.dense.weight'\n",
       "            p_bert_encoder_layer_11_intermediate_dense_bias: PARAMETER target='bert.encoder.layer.11.intermediate.dense.bias'\n",
       "            p_bert_encoder_layer_11_output_dense_weight: PARAMETER target='bert.encoder.layer.11.output.dense.weight'\n",
       "            p_bert_encoder_layer_11_output_dense_bias: PARAMETER target='bert.encoder.layer.11.output.dense.bias'\n",
       "            p_bert_encoder_layer_11_output_layernorm_weight: PARAMETER target='bert.encoder.layer.11.output.LayerNorm.weight'\n",
       "            p_bert_encoder_layer_11_output_layernorm_bias: PARAMETER target='bert.encoder.layer.11.output.LayerNorm.bias'\n",
       "            p_bert_pooler_dense_weight: PARAMETER target='bert.pooler.dense.weight'\n",
       "            p_bert_pooler_dense_bias: PARAMETER target='bert.pooler.dense.bias'\n",
       "            p_classifier_weight: PARAMETER target='classifier.weight'\n",
       "            p_classifier_bias: PARAMETER target='classifier.bias'\n",
       "            c_bert_lifted_tensor_0: CONSTANT_TENSOR target='bert.lifted_tensor_0'\n",
       "            b_bert_embeddings_position_ids: BUFFER target='bert.embeddings.position_ids' persistent=False\n",
       "            b_bert_embeddings_token_type_ids: BUFFER target='bert.embeddings.token_type_ids' persistent=False\n",
       "            input_ids: USER_INPUT\n",
       "            attention_mask: USER_INPUT\n",
       "            token_type_ids: USER_INPUT\n",
       "    \n",
       "            # outputs\n",
       "            linear_73: USER_OUTPUT\n",
       "    \n",
       "        Range constraints: {s41: VR[0, 512]}\n",
       "\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_input = tokenizer(\"This movie is good.\", return_tensors=\"pt\")\n",
    "\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    (dummy_input[\"input_ids\"], dummy_input[\"attention_mask\"], dummy_input[\"token_type_ids\"]), # example inputs\n",
    "    \"../deploy/movie-review-sentiment-analysis.onnx\",\n",
    "    input_names=[\"input_ids\", \"attention_mask\", \"token_type_ids\"],\n",
    "    output_names=[\"logits\"],\n",
    "    opset_version=17,\n",
    "    dynamic_axes={\n",
    "        \"input_ids\": {1: \"sequence\"},\n",
    "        \"attention_mask\": {1: \"sequence\"},\n",
    "        \"token_type_ids\": {1: \"sequence\"},\n",
    "        \"logits\": {0: \"batch\"}\n",
    "    }\n",
    "    # Set dynamic inputs, to prevent onnx from freeze input as dummy\n",
    "    ,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990cd0fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "move-review-sentiment-analysis-model",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
