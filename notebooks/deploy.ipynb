{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15501a13",
   "metadata": {},
   "source": [
    "Convert model to onnx format for deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7356b987",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c13ed02",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-uncased\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"./output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c278330",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the model to evaluation mode\n",
    "# so that some layer is disable in inference mode, rather than training mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15b98bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1123 19:44:42.215000 19088 Lib\\site-packages\\torch\\onnx\\_internal\\exporter\\_compat.py:114] Setting ONNX exporter to use operator set version 18 because the requested opset_version 14 is a lower version than we have implementations for. Automatic version conversion will be performed, which may not be successful at converting to the requested version. If version conversion is unsuccessful, the opset version of the exported model will be kept at 18. Please consider setting opset_version >=18 to leverage latest ONNX features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.onnx] Obtain model graph for `BertForSequenceClassification([...]` with `torch.export.export(..., strict=False)`...\n",
      "[torch.onnx] Obtain model graph for `BertForSequenceClassification([...]` with `torch.export.export(..., strict=False)`... ✅\n",
      "[torch.onnx] Run decomposition...\n",
      "[torch.onnx] Run decomposition... ✅\n",
      "[torch.onnx] Translate the graph into ONNX...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model version conversion is not supported by the onnxscript version converter and fallback is enabled. The model will be converted using the onnx C API (target version: 14).\n",
      "Failed to convert the model to the target version 14 using the ONNX C API. The model was not modified\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\onnxscript\\version_converter\\__init__.py\", line 127, in call\n",
      "    converted_proto = _c_api_utils.call_onnx_api(\n",
      "        func=_partial_convert_version, model=model\n",
      "    )\n",
      "  File \"d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\onnxscript\\version_converter\\_c_api_utils.py\", line 65, in call_onnx_api\n",
      "    result = func(proto)\n",
      "  File \"d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\onnxscript\\version_converter\\__init__.py\", line 122, in _partial_convert_version\n",
      "    return onnx.version_converter.convert_version(\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        proto, target_version=self.target_version\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\onnx\\version_converter.py\", line 39, in convert_version\n",
      "    converted_model_str = C.convert_version(model_str, target_version)\n",
      "RuntimeError: D:\\a\\onnx\\onnx\\onnx/version_converter/adapters/no_previous_version.h:26: adapt: Assertion `false` failed: No Previous Version of LayerNormalization exists\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.onnx] Translate the graph into ONNX... ✅\n",
      "Applied 1 of general pattern rewrite rules.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ONNXProgram(\n",
       "    model=\n",
       "        <\n",
       "            ir_version=10,\n",
       "            opset_imports={'': 18},\n",
       "            producer_name='pytorch',\n",
       "            producer_version='2.9.0+cu130',\n",
       "            domain=None,\n",
       "            model_version=None,\n",
       "        >\n",
       "        graph(\n",
       "            name=main_graph,\n",
       "            inputs=(\n",
       "                %\"input_ids\"<INT64,[1,7]>,\n",
       "                %\"attention_mask\"<INT64,[1,7]>\n",
       "            ),\n",
       "            outputs=(\n",
       "                %\"logits\"<FLOAT,[1,2]>\n",
       "            ),\n",
       "            initializers=(\n",
       "                %\"bert.embeddings.LayerNorm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.embeddings.LayerNorm.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.0.attention.self.query.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.0.attention.self.key.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.0.attention.self.value.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.0.attention.output.dense.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.0.attention.output.LayerNorm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.0.attention.output.LayerNorm.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.0.output.dense.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.0.output.LayerNorm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.0.output.LayerNorm.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.1.attention.self.query.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.1.attention.self.key.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.1.attention.self.value.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.1.attention.output.dense.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.1.attention.output.LayerNorm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.1.attention.output.LayerNorm.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.1.output.dense.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.1.output.LayerNorm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.1.output.LayerNorm.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.2.attention.self.query.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.2.attention.self.key.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.2.attention.self.value.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.2.attention.output.dense.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.2.attention.output.LayerNorm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.2.attention.output.LayerNorm.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.2.output.dense.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.2.output.LayerNorm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.2.output.LayerNorm.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.3.attention.self.query.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.3.attention.self.key.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.3.attention.self.value.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.3.attention.output.dense.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.3.attention.output.LayerNorm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.3.attention.output.LayerNorm.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.3.output.dense.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.3.output.LayerNorm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.3.output.LayerNorm.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.4.attention.self.query.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.4.attention.self.key.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.4.attention.self.value.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.4.attention.output.dense.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.4.attention.output.LayerNorm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.4.attention.output.LayerNorm.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.4.output.dense.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.4.output.LayerNorm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.4.output.LayerNorm.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.5.attention.self.query.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.5.attention.self.key.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.5.attention.self.value.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.5.attention.output.dense.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.5.attention.output.LayerNorm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.5.attention.output.LayerNorm.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.5.output.dense.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.5.output.LayerNorm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.5.output.LayerNorm.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.6.attention.self.query.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.6.attention.self.key.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.6.attention.self.value.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.6.attention.output.dense.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.6.attention.output.LayerNorm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.6.attention.output.LayerNorm.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.6.output.dense.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.6.output.LayerNorm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.6.output.LayerNorm.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.7.attention.self.query.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.7.attention.self.key.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.7.attention.self.value.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.7.attention.output.dense.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.7.attention.output.LayerNorm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.7.attention.output.LayerNorm.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.7.output.dense.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.7.output.LayerNorm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.7.output.LayerNorm.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.8.attention.self.query.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.8.attention.self.key.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.8.attention.self.value.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.8.attention.output.dense.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.8.attention.output.LayerNorm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.8.attention.output.LayerNorm.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.8.output.dense.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.8.output.LayerNorm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.8.output.LayerNorm.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.9.attention.self.query.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.9.attention.self.key.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.9.attention.self.value.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.9.attention.output.dense.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.9.attention.output.LayerNorm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.9.attention.output.LayerNorm.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.9.output.dense.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.9.output.LayerNorm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.9.output.LayerNorm.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.10.attention.self.query.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.10.attention.self.key.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.10.attention.self.value.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.10.attention.output.dense.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.10.attention.output.LayerNorm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.10.attention.output.LayerNorm.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.10.output.dense.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.10.output.LayerNorm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.10.output.LayerNorm.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.11.attention.self.query.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.11.attention.self.key.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.11.attention.self.value.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.11.attention.output.dense.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.11.attention.output.LayerNorm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.11.attention.output.LayerNorm.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.11.output.dense.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.11.output.LayerNorm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.11.output.LayerNorm.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"bert.pooler.dense.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"classifier.bias\"<FLOAT,[2]>{TorchTensor<FLOAT,[2]>(Parameter containing: tensor([ 0.0010, -0.0010], requires_grad=True), name='classifier.bias')},\n",
       "                %\"bert.embeddings.word_embeddings.weight\"<FLOAT,[30522,768]>{TorchTensor(...)},\n",
       "                %\"bert.embeddings.position_embeddings.weight\"<FLOAT,[512,768]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.0.intermediate.dense.bias\"<FLOAT,[3072]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.1.intermediate.dense.bias\"<FLOAT,[3072]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.2.intermediate.dense.bias\"<FLOAT,[3072]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.3.intermediate.dense.bias\"<FLOAT,[3072]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.4.intermediate.dense.bias\"<FLOAT,[3072]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.5.intermediate.dense.bias\"<FLOAT,[3072]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.6.intermediate.dense.bias\"<FLOAT,[3072]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.7.intermediate.dense.bias\"<FLOAT,[3072]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.8.intermediate.dense.bias\"<FLOAT,[3072]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.9.intermediate.dense.bias\"<FLOAT,[3072]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.10.intermediate.dense.bias\"<FLOAT,[3072]>{TorchTensor(...)},\n",
       "                %\"bert.encoder.layer.11.intermediate.dense.bias\"<FLOAT,[3072]>{TorchTensor(...)},\n",
       "                %\"bert.pooler.dense.weight\"<FLOAT,[768,768]>{TorchTensor(...)},\n",
       "                %\"classifier.weight\"<FLOAT,[2,768]>{TorchTensor(...)},\n",
       "                %\"slice_2\"<INT64,[1,7]>{Tensor<INT64,[1,7]>(array([[0, 1, 2, 3, 4, 5, 6]]), name='slice_2')},\n",
       "                %\"embedding_1\"<FLOAT,[1,7,768]>{Tensor(...)},\n",
       "                %\"val_36\"<INT64,[4]>{Tensor<INT64,[4]>(array([1, 1, 7, 7]), name='val_36')},\n",
       "                %\"clone_1\"<FLOAT,[]>{Tensor<FLOAT,[]>(array(1., dtype=float32), name='clone_1')},\n",
       "                %\"val_38\"<FLOAT,[]>{Tensor<FLOAT,[]>(array(-3.4028235e+38, dtype=float32), name='val_38')},\n",
       "                %\"val_39\"<FLOAT,[768,768]>{Tensor(...)},\n",
       "                %\"val_46\"<INT64,[4]>{Tensor<INT64,[4]>(array([ 1, -1, 12, 64]), name='val_46')},\n",
       "                %\"val_47\"<FLOAT,[768,768]>{Tensor(...)},\n",
       "                %\"val_55\"<FLOAT,[768,768]>{Tensor(...)},\n",
       "                %\"val_81\"<INT64,[3]>{Tensor<INT64,[3]>(array([-1,  7, 64]), name='val_81')},\n",
       "                %\"val_84\"<INT64,[4]>{Tensor<INT64,[4]>(array([ 1, 12, 64,  7]), name='val_84')},\n",
       "                %\"val_86\"<FLOAT,[1]>{Tensor<FLOAT,[1]>(array([0.35355338], dtype=float32), name='val_86')},\n",
       "                %\"val_97\"<INT64,[3]>{Tensor<INT64,[3]>(array([  1,   7, 768]), name='val_97')},\n",
       "                %\"val_98\"<FLOAT,[768,768]>{Tensor(...)},\n",
       "                %\"val_102\"<FLOAT,[768,3072]>{Tensor(...)},\n",
       "                %\"val_111\"<FLOAT,[3072,768]>{Tensor(...)},\n",
       "                %\"val_115\"<FLOAT,[768,768]>{Tensor(...)},\n",
       "                %\"val_123\"<FLOAT,[768,768]>{Tensor(...)},\n",
       "                %\"val_131\"<FLOAT,[768,768]>{Tensor(...)},\n",
       "                %\"val_172\"<FLOAT,[768,768]>{Tensor(...)},\n",
       "                %\"val_176\"<FLOAT,[768,3072]>{Tensor(...)},\n",
       "                %\"val_185\"<FLOAT,[3072,768]>{Tensor(...)},\n",
       "                %\"val_189\"<FLOAT,[768,768]>{Tensor(...)},\n",
       "                %\"val_197\"<FLOAT,[768,768]>{Tensor(...)},\n",
       "                %\"val_205\"<FLOAT,[768,768]>{Tensor(...)},\n",
       "                %\"val_246\"<FLOAT,[768,768]>{Tensor(...)},\n",
       "                %\"val_250\"<FLOAT,[768,3072]>{Tensor(...)},\n",
       "                %\"val_259\"<FLOAT,[3072,768]>{Tensor(...)},\n",
       "                %\"val_263\"<FLOAT,[768,768]>{Tensor(...)},\n",
       "                %\"val_271\"<FLOAT,[768,768]>{Tensor(...)},\n",
       "                %\"val_279\"<FLOAT,[768,768]>{Tensor(...)},\n",
       "                %\"val_320\"<FLOAT,[768,768]>{Tensor(...)},\n",
       "                %\"val_324\"<FLOAT,[768,3072]>{Tensor(...)},\n",
       "                %\"val_333\"<FLOAT,[3072,768]>{Tensor(...)},\n",
       "                %\"val_337\"<FLOAT,[768,768]>{Tensor(...)},\n",
       "                %\"val_345\"<FLOAT,[768,768]>{Tensor(...)},\n",
       "                %\"val_353\"<FLOAT,[768,768]>{Tensor(...)},\n",
       "                %\"val_394\"<FLOAT,[768,768]>{Tensor(...)},\n",
       "                %\"val_398\"<FLOAT,[768,3072]>{Tensor(...)},\n",
       "                %\"val_407\"<FLOAT,[3072,768]>{Tensor(...)},\n",
       "                %\"val_411\"<FLOAT,[768,768]>{Tensor(...)},\n",
       "                %\"val_419\"<FLOAT,[768,768]>{Tensor(...)},\n",
       "                %\"val_427\"<FLOAT,[768,768]>{Tensor(...)},\n",
       "                %\"val_468\"<FLOAT,[768,768]>{Tensor(...)},\n",
       "                %\"val_472\"<FLOAT,[768,3072]>{Tensor(...)},\n",
       "                %\"val_481\"<FLOAT,[3072,768]>{Tensor(...)},\n",
       "                %\"val_485\"<FLOAT,[768,768]>{Tensor(...)},\n",
       "                %\"val_493\"<FLOAT,[768,768]>{Tensor(...)},\n",
       "                %\"val_501\"<FLOAT,[768,768]>{Tensor(...)},\n",
       "                %\"val_542\"<FLOAT,[768,768]>{Tensor(...)},\n",
       "                %\"val_546\"<FLOAT,[768,3072]>{Tensor(...)},\n",
       "                %\"val_555\"<FLOAT,[3072,768]>{Tensor(...)},\n",
       "                %\"val_559\"<FLOAT,[768,768]>{Tensor(...)},\n",
       "                %\"val_567\"<FLOAT,[768,768]>{Tensor(...)},\n",
       "                %\"val_575\"<FLOAT,[768,768]>{Tensor(...)},\n",
       "                %\"val_616\"<FLOAT,[768,768]>{Tensor(...)},\n",
       "                %\"val_620\"<FLOAT,[768,3072]>{Tensor(...)},\n",
       "                %\"val_629\"<FLOAT,[3072,768]>{Tensor(...)},\n",
       "                %\"val_633\"<FLOAT,[768,768]>{Tensor(...)},\n",
       "                %\"val_641\"<FLOAT,[768,768]>{Tensor(...)},\n",
       "                %\"val_649\"<FLOAT,[768,768]>{Tensor(...)},\n",
       "                %\"val_690\"<FLOAT,[768,768]>{Tensor(...)},\n",
       "                %\"val_694\"<FLOAT,[768,3072]>{Tensor(...)},\n",
       "                %\"val_703\"<FLOAT,[3072,768]>{Tensor(...)},\n",
       "                %\"val_707\"<FLOAT,[768,768]>{Tensor(...)},\n",
       "                %\"val_715\"<FLOAT,[768,768]>{Tensor(...)},\n",
       "                %\"val_723\"<FLOAT,[768,768]>{Tensor(...)},\n",
       "                %\"val_764\"<FLOAT,[768,768]>{Tensor(...)},\n",
       "                %\"val_768\"<FLOAT,[768,3072]>{Tensor(...)},\n",
       "                %\"val_777\"<FLOAT,[3072,768]>{Tensor(...)},\n",
       "                %\"val_781\"<FLOAT,[768,768]>{Tensor(...)},\n",
       "                %\"val_789\"<FLOAT,[768,768]>{Tensor(...)},\n",
       "                %\"val_797\"<FLOAT,[768,768]>{Tensor(...)},\n",
       "                %\"val_838\"<FLOAT,[768,768]>{Tensor(...)},\n",
       "                %\"val_842\"<FLOAT,[768,3072]>{Tensor(...)},\n",
       "                %\"val_851\"<FLOAT,[3072,768]>{Tensor(...)},\n",
       "                %\"val_855\"<FLOAT,[768,768]>{Tensor(...)},\n",
       "                %\"val_863\"<FLOAT,[768,768]>{Tensor(...)},\n",
       "                %\"val_871\"<FLOAT,[768,768]>{Tensor(...)},\n",
       "                %\"val_912\"<FLOAT,[768,768]>{Tensor(...)},\n",
       "                %\"val_916\"<FLOAT,[768,3072]>{Tensor(...)},\n",
       "                %\"val_925\"<FLOAT,[3072,768]>{Tensor(...)},\n",
       "                %\"val_0\"<INT64,[]>{Tensor<INT64,[]>(array(0), name='val_0')},\n",
       "                %\"val_929\"<INT64,[2]>{Tensor<INT64,[2]>(array([1, 2]), name='val_929')},\n",
       "                %\"val_104\"<FLOAT,[]>{Tensor<FLOAT,[]>(array(1.4142135, dtype=float32), name='val_104')},\n",
       "                %\"val_109\"<FLOAT,[]>{Tensor<FLOAT,[]>(array(0.5, dtype=float32), name='val_109')}\n",
       "            ),\n",
       "        ) {\n",
       "              0 |  # node_embedding\n",
       "                   %\"embedding\"<FLOAT,[1,7,768]> ⬅️ ::Gather(%\"bert.embeddings.word_embeddings.weight\"{...}, %\"input_ids\") {axis=0}\n",
       "              1 |  # node_add\n",
       "                   %\"add\"<FLOAT,[1,7,768]> ⬅️ ::Add(%\"embedding\", %\"embedding_1\"{...})\n",
       "              2 |  # node_embedding_2\n",
       "                   %\"embedding_2\"<FLOAT,[1,7,768]> ⬅️ ::Gather(%\"bert.embeddings.position_embeddings.weight\"{...}, %\"slice_2\"{[[0, 1, 2, 3, 4, 5, 6]]}) {axis=0}\n",
       "              3 |  # node_add_1\n",
       "                   %\"add_1\"<FLOAT,[1,7,768]> ⬅️ ::Add(%\"add\", %\"embedding_2\")\n",
       "              4 |  # node_layer_norm\n",
       "                   %\"layer_norm\"<FLOAT,[1,7,768]>, %\"\"<?,?>, %\"\"<?,?> ⬅️ ::LayerNormalization(%\"add_1\", %\"bert.embeddings.LayerNorm.weight\"{...}, %\"bert.embeddings.LayerNorm.bias\"{...}) {axis=-1, epsilon=1e-12, stash_type=1}\n",
       "              5 |  # node_Unsqueeze_960\n",
       "                   %\"unsqueeze_1\"<INT64,[1,1,1,7]> ⬅️ ::Unsqueeze(%\"attention_mask\", %\"val_929\"{[1, 2]})\n",
       "              6 |  # node_expand_1\n",
       "                   %\"expand_1\"<INT64,[1,1,7,7]> ⬅️ ::Expand(%\"unsqueeze_1\", %\"val_36\"{[1, 1, 7, 7]})\n",
       "              7 |  # node__to_copy\n",
       "                   %\"_to_copy\"<FLOAT,[1,1,7,7]> ⬅️ ::Cast(%\"expand_1\") {to=1}\n",
       "              8 |  # node_sub\n",
       "                   %\"sub\"<FLOAT,[1,1,7,7]> ⬅️ ::Sub(%\"clone_1\"{1.0}, %\"_to_copy\")\n",
       "              9 |  # node__to_copy_1\n",
       "                   %\"_to_copy_1\"<BOOL,[1,1,7,7]> ⬅️ ::Cast(%\"sub\") {to=9}\n",
       "             10 |  # node_masked_fill\n",
       "                   %\"masked_fill\"<FLOAT,[1,1,7,7]> ⬅️ ::Where(%\"_to_copy_1\", %\"val_38\"{-3.4028234663852886e+38}, %\"sub\")\n",
       "             11 |  # node_MatMul_38\n",
       "                   %\"val_40\"<FLOAT,[1,7,768]> ⬅️ ::MatMul(%\"layer_norm\", %\"val_39\"{...})\n",
       "             12 |  # node_linear\n",
       "                   %\"linear\"<FLOAT,[1,7,768]> ⬅️ ::Add(%\"val_40\", %\"bert.encoder.layer.0.attention.self.query.bias\"{...})\n",
       "             13 |  # node_view\n",
       "                   %\"view\"<FLOAT,[1,7,12,64]> ⬅️ ::Reshape(%\"linear\", %\"val_46\"{[1, -1, 12, 64]}) {allowzero=1}\n",
       "             14 |  # node_transpose\n",
       "                   %\"transpose\"<FLOAT,[1,12,7,64]> ⬅️ ::Transpose(%\"view\") {perm=(0, 2, 1, 3)}\n",
       "             15 |  # node_MatMul_46\n",
       "                   %\"val_48\"<FLOAT,[1,7,768]> ⬅️ ::MatMul(%\"layer_norm\", %\"val_47\"{...})\n",
       "             16 |  # node_linear_1\n",
       "                   %\"linear_1\"<FLOAT,[1,7,768]> ⬅️ ::Add(%\"val_48\", %\"bert.encoder.layer.0.attention.self.key.bias\"{...})\n",
       "             17 |  # node_view_1\n",
       "                   %\"view_1\"<FLOAT,[1,7,12,64]> ⬅️ ::Reshape(%\"linear_1\", %\"val_46\"{[1, -1, 12, 64]}) {allowzero=1}\n",
       "             18 |  # node_transpose_1\n",
       "                   %\"transpose_1\"<FLOAT,[1,12,7,64]> ⬅️ ::Transpose(%\"view_1\") {perm=(0, 2, 1, 3)}\n",
       "             19 |  # node_MatMul_54\n",
       "                   %\"val_56\"<FLOAT,[1,7,768]> ⬅️ ::MatMul(%\"layer_norm\", %\"val_55\"{...})\n",
       "             20 |  # node_linear_2\n",
       "                   %\"linear_2\"<FLOAT,[1,7,768]> ⬅️ ::Add(%\"val_56\", %\"bert.encoder.layer.0.attention.self.value.bias\"{...})\n",
       "             21 |  # node_view_2\n",
       "                   %\"view_2\"<FLOAT,[1,7,12,64]> ⬅️ ::Reshape(%\"linear_2\", %\"val_46\"{[1, -1, 12, 64]}) {allowzero=1}\n",
       "             22 |  # node_transpose_2\n",
       "                   %\"transpose_2\"<FLOAT,[1,12,7,64]> ⬅️ ::Transpose(%\"view_2\") {perm=(0, 2, 1, 3)}\n",
       "             23 |  # node_Reshape_80\n",
       "                   %\"val_82\"<FLOAT,[12,7,64]> ⬅️ ::Reshape(%\"transpose_1\", %\"val_81\"{[-1, 7, 64]}) {allowzero=0}\n",
       "             24 |  # node_Transpose_81\n",
       "                   %\"val_83\"<FLOAT,[12,64,7]> ⬅️ ::Transpose(%\"val_82\") {perm=(0, 2, 1)}\n",
       "             25 |  # node_Reshape_83\n",
       "                   %\"val_85\"<FLOAT,[1,12,64,7]> ⬅️ ::Reshape(%\"val_83\", %\"val_84\"{[1, 12, 64, 7]}) {allowzero=0}\n",
       "             26 |  # node_Mul_85\n",
       "                   %\"val_87\"<FLOAT,[1,12,7,64]> ⬅️ ::Mul(%\"transpose\", %\"val_86\"{[0.3535533845424652]})\n",
       "             27 |  # node_Mul_87\n",
       "                   %\"val_89\"<FLOAT,[1,12,64,7]> ⬅️ ::Mul(%\"val_85\", %\"val_86\"{[0.3535533845424652]})\n",
       "             28 |  # node_MatMul_88\n",
       "                   %\"val_90\"<FLOAT,[1,12,7,7]> ⬅️ ::MatMul(%\"val_87\", %\"val_89\")\n",
       "             29 |  # node_Add_89\n",
       "                   %\"val_91\"<FLOAT,[1,12,7,7]> ⬅️ ::Add(%\"val_90\", %\"masked_fill\")\n",
       "             30 |  # node_Softmax_90\n",
       "                   %\"val_92\"<FLOAT,[1,12,7,7]> ⬅️ ::Softmax(%\"val_91\") {axis=-1}\n",
       "             31 |  # node_scaled_dot_product_attention\n",
       "                   %\"scaled_dot_product_attention\"<FLOAT,[1,12,7,64]> ⬅️ ::MatMul(%\"val_92\", %\"transpose_2\")\n",
       "             32 |  # node_transpose_3\n",
       "                   %\"transpose_3\"<FLOAT,[1,7,12,64]> ⬅️ ::Transpose(%\"scaled_dot_product_attention\") {perm=(0, 2, 1, 3)}\n",
       "             33 |  # node_view_3\n",
       "                   %\"view_3\"<FLOAT,[1,7,768]> ⬅️ ::Reshape(%\"transpose_3\", %\"val_97\"{[1, 7, 768]}) {allowzero=1}\n",
       "             34 |  # node_MatMul_97\n",
       "                   %\"val_99\"<FLOAT,[1,7,768]> ⬅️ ::MatMul(%\"view_3\", %\"val_98\"{...})\n",
       "             35 |  # node_linear_3\n",
       "                   %\"linear_3\"<FLOAT,[1,7,768]> ⬅️ ::Add(%\"val_99\", %\"bert.encoder.layer.0.attention.output.dense.bias\"{...})\n",
       "             36 |  # node_add_2\n",
       "                   %\"add_2\"<FLOAT,[1,7,768]> ⬅️ ::Add(%\"linear_3\", %\"layer_norm\")\n",
       "             37 |  # node_layer_norm_1\n",
       "                   %\"layer_norm_1\"<FLOAT,[1,7,768]>, %\"\"<?,?>, %\"\"<?,?> ⬅️ ::LayerNormalization(%\"add_2\", %\"bert.encoder.layer.0.attention.output.LayerNorm.weight\"{...}, %\"bert.encoder.layer.0.attention.output.LayerNorm.bias\"{...}) {axis=-1, epsilon=1e-12, stash_type=1}\n",
       "             38 |  # node_MatMul_99\n",
       "                   %\"val_103\"<FLOAT,[1,7,3072]> ⬅️ ::MatMul(%\"layer_norm_1\", %\"val_102\"{...})\n",
       "             39 |  # node_linear_4\n",
       "                   %\"linear_4\"<FLOAT,[1,7,3072]> ⬅️ ::Add(%\"val_103\", %\"bert.encoder.layer.0.intermediate.dense.bias\"{...})\n",
       "             40 |  # node_Div_101\n",
       "                   %\"val_105\"<FLOAT,[1,7,3072]> ⬅️ ::Div(%\"linear_4\", %\"val_104\"{1.4142135381698608})\n",
       "             41 |  # node_Erf_102\n",
       "                   %\"val_106\"<FLOAT,[1,7,3072]> ⬅️ ::Erf(%\"val_105\")\n",
       "             42 |  # node_Add_104\n",
       "                   %\"val_108\"<FLOAT,[1,7,3072]> ⬅️ ::Add(%\"val_106\", %\"clone_1\"{1.0})\n",
       "             43 |  # node_Mul_106\n",
       "                   %\"val_110\"<FLOAT,[1,7,3072]> ⬅️ ::Mul(%\"val_109\"{0.5}, %\"val_108\")\n",
       "             44 |  # node_gelu\n",
       "                   %\"gelu\"<FLOAT,[1,7,3072]> ⬅️ ::Mul(%\"linear_4\", %\"val_110\")\n",
       "             45 |  # node_MatMul_108\n",
       "                   %\"val_112\"<FLOAT,[1,7,768]> ⬅️ ::MatMul(%\"gelu\", %\"val_111\"{...})\n",
       "             46 |  # node_linear_5\n",
       "                   %\"linear_5\"<FLOAT,[1,7,768]> ⬅️ ::Add(%\"val_112\", %\"bert.encoder.layer.0.output.dense.bias\"{...})\n",
       "             47 |  # node_add_3\n",
       "                   %\"add_3\"<FLOAT,[1,7,768]> ⬅️ ::Add(%\"linear_5\", %\"layer_norm_1\")\n",
       "             48 |  # node_layer_norm_2\n",
       "                   %\"layer_norm_2\"<FLOAT,[1,7,768]>, %\"\"<?,?>, %\"\"<?,?> ⬅️ ::LayerNormalization(%\"add_3\", %\"bert.encoder.layer.0.output.LayerNorm.weight\"{...}, %\"bert.encoder.layer.0.output.LayerNorm.bias\"{...}) {axis=-1, epsilon=1e-12, stash_type=1}\n",
       "             49 |  # node_MatMul_110\n",
       "                   %\"val_116\"<FLOAT,[1,7,768]> ⬅️ ::MatMul(%\"layer_norm_2\", %\"val_115\"{...})\n",
       "             50 |  # node_linear_6\n",
       "                   %\"linear_6\"<FLOAT,[1,7,768]> ⬅️ ::Add(%\"val_116\", %\"bert.encoder.layer.1.attention.self.query.bias\"{...})\n",
       "             51 |  # node_view_4\n",
       "                   %\"view_4\"<FLOAT,[1,7,12,64]> ⬅️ ::Reshape(%\"linear_6\", %\"val_46\"{[1, -1, 12, 64]}) {allowzero=1}\n",
       "             52 |  # node_transpose_4\n",
       "                   %\"transpose_4\"<FLOAT,[1,12,7,64]> ⬅️ ::Transpose(%\"view_4\") {perm=(0, 2, 1, 3)}\n",
       "             53 |  # node_MatMul_118\n",
       "                   %\"val_124\"<FLOAT,[1,7,768]> ⬅️ ::MatMul(%\"layer_norm_2\", %\"val_123\"{...})\n",
       "             54 |  # node_linear_7\n",
       "                   %\"linear_7\"<FLOAT,[1,7,768]> ⬅️ ::Add(%\"val_124\", %\"bert.encoder.layer.1.attention.self.key.bias\"{...})\n",
       "             55 |  # node_view_5\n",
       "                   %\"view_5\"<FLOAT,[1,7,12,64]> ⬅️ ::Reshape(%\"linear_7\", %\"val_46\"{[1, -1, 12, 64]}) {allowzero=1}\n",
       "             56 |  # node_transpose_5\n",
       "                   %\"transpose_5\"<FLOAT,[1,12,7,64]> ⬅️ ::Transpose(%\"view_5\") {perm=(0, 2, 1, 3)}\n",
       "             57 |  # node_MatMul_126\n",
       "                   %\"val_132\"<FLOAT,[1,7,768]> ⬅️ ::MatMul(%\"layer_norm_2\", %\"val_131\"{...})\n",
       "             58 |  # node_linear_8\n",
       "                   %\"linear_8\"<FLOAT,[1,7,768]> ⬅️ ::Add(%\"val_132\", %\"bert.encoder.layer.1.attention.self.value.bias\"{...})\n",
       "             59 |  # node_view_6\n",
       "                   %\"view_6\"<FLOAT,[1,7,12,64]> ⬅️ ::Reshape(%\"linear_8\", %\"val_46\"{[1, -1, 12, 64]}) {allowzero=1}\n",
       "             60 |  # node_transpose_6\n",
       "                   %\"transpose_6\"<FLOAT,[1,12,7,64]> ⬅️ ::Transpose(%\"view_6\") {perm=(0, 2, 1, 3)}\n",
       "             61 |  # node_Reshape_150\n",
       "                   %\"val_156\"<FLOAT,[12,7,64]> ⬅️ ::Reshape(%\"transpose_5\", %\"val_81\"{[-1, 7, 64]}) {allowzero=0}\n",
       "             62 |  # node_Transpose_151\n",
       "                   %\"val_157\"<FLOAT,[12,64,7]> ⬅️ ::Transpose(%\"val_156\") {perm=(0, 2, 1)}\n",
       "             63 |  # node_Reshape_153\n",
       "                   %\"val_159\"<FLOAT,[1,12,64,7]> ⬅️ ::Reshape(%\"val_157\", %\"val_84\"{[1, 12, 64, 7]}) {allowzero=0}\n",
       "             64 |  # node_Mul_155\n",
       "                   %\"val_161\"<FLOAT,[1,12,7,64]> ⬅️ ::Mul(%\"transpose_4\", %\"val_86\"{[0.3535533845424652]})\n",
       "             65 |  # node_Mul_157\n",
       "                   %\"val_163\"<FLOAT,[1,12,64,7]> ⬅️ ::Mul(%\"val_159\", %\"val_86\"{[0.3535533845424652]})\n",
       "             66 |  # node_MatMul_158\n",
       "                   %\"val_164\"<FLOAT,[1,12,7,7]> ⬅️ ::MatMul(%\"val_161\", %\"val_163\")\n",
       "             67 |  # node_Add_159\n",
       "                   %\"val_165\"<FLOAT,[1,12,7,7]> ⬅️ ::Add(%\"val_164\", %\"masked_fill\")\n",
       "             68 |  # node_Softmax_160\n",
       "                   %\"val_166\"<FLOAT,[1,12,7,7]> ⬅️ ::Softmax(%\"val_165\") {axis=-1}\n",
       "             69 |  # node_scaled_dot_product_attention_1\n",
       "                   %\"scaled_dot_product_attention_1\"<FLOAT,[1,12,7,64]> ⬅️ ::MatMul(%\"val_166\", %\"transpose_6\")\n",
       "             70 |  # node_transpose_7\n",
       "                   %\"transpose_7\"<FLOAT,[1,7,12,64]> ⬅️ ::Transpose(%\"scaled_dot_product_attention_1\") {perm=(0, 2, 1, 3)}\n",
       "             71 |  # node_view_7\n",
       "                   %\"view_7\"<FLOAT,[1,7,768]> ⬅️ ::Reshape(%\"transpose_7\", %\"val_97\"{[1, 7, 768]}) {allowzero=1}\n",
       "             72 |  # node_MatMul_167\n",
       "                   %\"val_173\"<FLOAT,[1,7,768]> ⬅️ ::MatMul(%\"view_7\", %\"val_172\"{...})\n",
       "             73 |  # node_linear_9\n",
       "                   %\"linear_9\"<FLOAT,[1,7,768]> ⬅️ ::Add(%\"val_173\", %\"bert.encoder.layer.1.attention.output.dense.bias\"{...})\n",
       "             74 |  # node_add_4\n",
       "                   %\"add_4\"<FLOAT,[1,7,768]> ⬅️ ::Add(%\"linear_9\", %\"layer_norm_2\")\n",
       "             75 |  # node_layer_norm_3\n",
       "                   %\"layer_norm_3\"<FLOAT,[1,7,768]>, %\"\"<?,?>, %\"\"<?,?> ⬅️ ::LayerNormalization(%\"add_4\", %\"bert.encoder.layer.1.attention.output.LayerNorm.weight\"{...}, %\"bert.encoder.layer.1.attention.output.LayerNorm.bias\"{...}) {axis=-1, epsilon=1e-12, stash_type=1}\n",
       "             76 |  # node_MatMul_169\n",
       "                   %\"val_177\"<FLOAT,[1,7,3072]> ⬅️ ::MatMul(%\"layer_norm_3\", %\"val_176\"{...})\n",
       "             77 |  # node_linear_10\n",
       "                   %\"linear_10\"<FLOAT,[1,7,3072]> ⬅️ ::Add(%\"val_177\", %\"bert.encoder.layer.1.intermediate.dense.bias\"{...})\n",
       "             78 |  # node_Div_171\n",
       "                   %\"val_179\"<FLOAT,[1,7,3072]> ⬅️ ::Div(%\"linear_10\", %\"val_104\"{1.4142135381698608})\n",
       "             79 |  # node_Erf_172\n",
       "                   %\"val_180\"<FLOAT,[1,7,3072]> ⬅️ ::Erf(%\"val_179\")\n",
       "             80 |  # node_Add_174\n",
       "                   %\"val_182\"<FLOAT,[1,7,3072]> ⬅️ ::Add(%\"val_180\", %\"clone_1\"{1.0})\n",
       "             81 |  # node_Mul_176\n",
       "                   %\"val_184\"<FLOAT,[1,7,3072]> ⬅️ ::Mul(%\"val_109\"{0.5}, %\"val_182\")\n",
       "             82 |  # node_gelu_1\n",
       "                   %\"gelu_1\"<FLOAT,[1,7,3072]> ⬅️ ::Mul(%\"linear_10\", %\"val_184\")\n",
       "             83 |  # node_MatMul_178\n",
       "                   %\"val_186\"<FLOAT,[1,7,768]> ⬅️ ::MatMul(%\"gelu_1\", %\"val_185\"{...})\n",
       "             84 |  # node_linear_11\n",
       "                   %\"linear_11\"<FLOAT,[1,7,768]> ⬅️ ::Add(%\"val_186\", %\"bert.encoder.layer.1.output.dense.bias\"{...})\n",
       "             85 |  # node_add_5\n",
       "                   %\"add_5\"<FLOAT,[1,7,768]> ⬅️ ::Add(%\"linear_11\", %\"layer_norm_3\")\n",
       "             86 |  # node_layer_norm_4\n",
       "                   %\"layer_norm_4\"<FLOAT,[1,7,768]>, %\"\"<?,?>, %\"\"<?,?> ⬅️ ::LayerNormalization(%\"add_5\", %\"bert.encoder.layer.1.output.LayerNorm.weight\"{...}, %\"bert.encoder.layer.1.output.LayerNorm.bias\"{...}) {axis=-1, epsilon=1e-12, stash_type=1}\n",
       "             87 |  # node_MatMul_180\n",
       "                   %\"val_190\"<FLOAT,[1,7,768]> ⬅️ ::MatMul(%\"layer_norm_4\", %\"val_189\"{...})\n",
       "             88 |  # node_linear_12\n",
       "                   %\"linear_12\"<FLOAT,[1,7,768]> ⬅️ ::Add(%\"val_190\", %\"bert.encoder.layer.2.attention.self.query.bias\"{...})\n",
       "             89 |  # node_view_8\n",
       "                   %\"view_8\"<FLOAT,[1,7,12,64]> ⬅️ ::Reshape(%\"linear_12\", %\"val_46\"{[1, -1, 12, 64]}) {allowzero=1}\n",
       "             90 |  # node_transpose_8\n",
       "                   %\"transpose_8\"<FLOAT,[1,12,7,64]> ⬅️ ::Transpose(%\"view_8\") {perm=(0, 2, 1, 3)}\n",
       "             91 |  # node_MatMul_188\n",
       "                   %\"val_198\"<FLOAT,[1,7,768]> ⬅️ ::MatMul(%\"layer_norm_4\", %\"val_197\"{...})\n",
       "             92 |  # node_linear_13\n",
       "                   %\"linear_13\"<FLOAT,[1,7,768]> ⬅️ ::Add(%\"val_198\", %\"bert.encoder.layer.2.attention.self.key.bias\"{...})\n",
       "             93 |  # node_view_9\n",
       "                   %\"view_9\"<FLOAT,[1,7,12,64]> ⬅️ ::Reshape(%\"linear_13\", %\"val_46\"{[1, -1, 12, 64]}) {allowzero=1}\n",
       "             94 |  # node_transpose_9\n",
       "                   %\"transpose_9\"<FLOAT,[1,12,7,64]> ⬅️ ::Transpose(%\"view_9\") {perm=(0, 2, 1, 3)}\n",
       "             95 |  # node_MatMul_196\n",
       "                   %\"val_206\"<FLOAT,[1,7,768]> ⬅️ ::MatMul(%\"layer_norm_4\", %\"val_205\"{...})\n",
       "             96 |  # node_linear_14\n",
       "                   %\"linear_14\"<FLOAT,[1,7,768]> ⬅️ ::Add(%\"val_206\", %\"bert.encoder.layer.2.attention.self.value.bias\"{...})\n",
       "             97 |  # node_view_10\n",
       "                   %\"view_10\"<FLOAT,[1,7,12,64]> ⬅️ ::Reshape(%\"linear_14\", %\"val_46\"{[1, -1, 12, 64]}) {allowzero=1}\n",
       "             98 |  # node_transpose_10\n",
       "                   %\"transpose_10\"<FLOAT,[1,12,7,64]> ⬅️ ::Transpose(%\"view_10\") {perm=(0, 2, 1, 3)}\n",
       "             99 |  # node_Reshape_220\n",
       "                   %\"val_230\"<FLOAT,[12,7,64]> ⬅️ ::Reshape(%\"transpose_9\", %\"val_81\"{[-1, 7, 64]}) {allowzero=0}\n",
       "            100 |  # node_Transpose_221\n",
       "                   %\"val_231\"<FLOAT,[12,64,7]> ⬅️ ::Transpose(%\"val_230\") {perm=(0, 2, 1)}\n",
       "            101 |  # node_Reshape_223\n",
       "                   %\"val_233\"<FLOAT,[1,12,64,7]> ⬅️ ::Reshape(%\"val_231\", %\"val_84\"{[1, 12, 64, 7]}) {allowzero=0}\n",
       "            102 |  # node_Mul_225\n",
       "                   %\"val_235\"<FLOAT,[1,12,7,64]> ⬅️ ::Mul(%\"transpose_8\", %\"val_86\"{[0.3535533845424652]})\n",
       "            103 |  # node_Mul_227\n",
       "                   %\"val_237\"<FLOAT,[1,12,64,7]> ⬅️ ::Mul(%\"val_233\", %\"val_86\"{[0.3535533845424652]})\n",
       "            104 |  # node_MatMul_228\n",
       "                   %\"val_238\"<FLOAT,[1,12,7,7]> ⬅️ ::MatMul(%\"val_235\", %\"val_237\")\n",
       "            105 |  # node_Add_229\n",
       "                   %\"val_239\"<FLOAT,[1,12,7,7]> ⬅️ ::Add(%\"val_238\", %\"masked_fill\")\n",
       "            106 |  # node_Softmax_230\n",
       "                   %\"val_240\"<FLOAT,[1,12,7,7]> ⬅️ ::Softmax(%\"val_239\") {axis=-1}\n",
       "            107 |  # node_scaled_dot_product_attention_2\n",
       "                   %\"scaled_dot_product_attention_2\"<FLOAT,[1,12,7,64]> ⬅️ ::MatMul(%\"val_240\", %\"transpose_10\")\n",
       "            108 |  # node_transpose_11\n",
       "                   %\"transpose_11\"<FLOAT,[1,7,12,64]> ⬅️ ::Transpose(%\"scaled_dot_product_attention_2\") {perm=(0, 2, 1, 3)}\n",
       "            109 |  # node_view_11\n",
       "                   %\"view_11\"<FLOAT,[1,7,768]> ⬅️ ::Reshape(%\"transpose_11\", %\"val_97\"{[1, 7, 768]}) {allowzero=1}\n",
       "            110 |  # node_MatMul_237\n",
       "                   %\"val_247\"<FLOAT,[1,7,768]> ⬅️ ::MatMul(%\"view_11\", %\"val_246\"{...})\n",
       "            111 |  # node_linear_15\n",
       "                   %\"linear_15\"<FLOAT,[1,7,768]> ⬅️ ::Add(%\"val_247\", %\"bert.encoder.layer.2.attention.output.dense.bias\"{...})\n",
       "            112 |  # node_add_6\n",
       "                   %\"add_6\"<FLOAT,[1,7,768]> ⬅️ ::Add(%\"linear_15\", %\"layer_norm_4\")\n",
       "            113 |  # node_layer_norm_5\n",
       "                   %\"layer_norm_5\"<FLOAT,[1,7,768]>, %\"\"<?,?>, %\"\"<?,?> ⬅️ ::LayerNormalization(%\"add_6\", %\"bert.encoder.layer.2.attention.output.LayerNorm.weight\"{...}, %\"bert.encoder.layer.2.attention.output.LayerNorm.bias\"{...}) {axis=-1, epsilon=1e-12, stash_type=1}\n",
       "            114 |  # node_MatMul_239\n",
       "                   %\"val_251\"<FLOAT,[1,7,3072]> ⬅️ ::MatMul(%\"layer_norm_5\", %\"val_250\"{...})\n",
       "            115 |  # node_linear_16\n",
       "                   %\"linear_16\"<FLOAT,[1,7,3072]> ⬅️ ::Add(%\"val_251\", %\"bert.encoder.layer.2.intermediate.dense.bias\"{...})\n",
       "            116 |  # node_Div_241\n",
       "                   %\"val_253\"<FLOAT,[1,7,3072]> ⬅️ ::Div(%\"linear_16\", %\"val_104\"{1.4142135381698608})\n",
       "            117 |  # node_Erf_242\n",
       "                   %\"val_254\"<FLOAT,[1,7,3072]> ⬅️ ::Erf(%\"val_253\")\n",
       "            118 |  # node_Add_244\n",
       "                   %\"val_256\"<FLOAT,[1,7,3072]> ⬅️ ::Add(%\"val_254\", %\"clone_1\"{1.0})\n",
       "            119 |  # node_Mul_246\n",
       "                   %\"val_258\"<FLOAT,[1,7,3072]> ⬅️ ::Mul(%\"val_109\"{0.5}, %\"val_256\")\n",
       "            120 |  # node_gelu_2\n",
       "                   %\"gelu_2\"<FLOAT,[1,7,3072]> ⬅️ ::Mul(%\"linear_16\", %\"val_258\")\n",
       "            121 |  # node_MatMul_248\n",
       "                   %\"val_260\"<FLOAT,[1,7,768]> ⬅️ ::MatMul(%\"gelu_2\", %\"val_259\"{...})\n",
       "            122 |  # node_linear_17\n",
       "                   %\"linear_17\"<FLOAT,[1,7,768]> ⬅️ ::Add(%\"val_260\", %\"bert.encoder.layer.2.output.dense.bias\"{...})\n",
       "            123 |  # node_add_7\n",
       "                   %\"add_7\"<FLOAT,[1,7,768]> ⬅️ ::Add(%\"linear_17\", %\"layer_norm_5\")\n",
       "            124 |  # node_layer_norm_6\n",
       "                   %\"layer_norm_6\"<FLOAT,[1,7,768]>, %\"\"<?,?>, %\"\"<?,?> ⬅️ ::LayerNormalization(%\"add_7\", %\"bert.encoder.layer.2.output.LayerNorm.weight\"{...}, %\"bert.encoder.layer.2.output.LayerNorm.bias\"{...}) {axis=-1, epsilon=1e-12, stash_type=1}\n",
       "            125 |  # node_MatMul_250\n",
       "                   %\"val_264\"<FLOAT,[1,7,768]> ⬅️ ::MatMul(%\"layer_norm_6\", %\"val_263\"{...})\n",
       "            126 |  # node_linear_18\n",
       "                   %\"linear_18\"<FLOAT,[1,7,768]> ⬅️ ::Add(%\"val_264\", %\"bert.encoder.layer.3.attention.self.query.bias\"{...})\n",
       "            127 |  # node_view_12\n",
       "                   %\"view_12\"<FLOAT,[1,7,12,64]> ⬅️ ::Reshape(%\"linear_18\", %\"val_46\"{[1, -1, 12, 64]}) {allowzero=1}\n",
       "            128 |  # node_transpose_12\n",
       "                   %\"transpose_12\"<FLOAT,[1,12,7,64]> ⬅️ ::Transpose(%\"view_12\") {perm=(0, 2, 1, 3)}\n",
       "            129 |  # node_MatMul_258\n",
       "                   %\"val_272\"<FLOAT,[1,7,768]> ⬅️ ::MatMul(%\"layer_norm_6\", %\"val_271\"{...})\n",
       "            130 |  # node_linear_19\n",
       "                   %\"linear_19\"<FLOAT,[1,7,768]> ⬅️ ::Add(%\"val_272\", %\"bert.encoder.layer.3.attention.self.key.bias\"{...})\n",
       "            131 |  # node_view_13\n",
       "                   %\"view_13\"<FLOAT,[1,7,12,64]> ⬅️ ::Reshape(%\"linear_19\", %\"val_46\"{[1, -1, 12, 64]}) {allowzero=1}\n",
       "            132 |  # node_transpose_13\n",
       "                   %\"transpose_13\"<FLOAT,[1,12,7,64]> ⬅️ ::Transpose(%\"view_13\") {perm=(0, 2, 1, 3)}\n",
       "            133 |  # node_MatMul_266\n",
       "                   %\"val_280\"<FLOAT,[1,7,768]> ⬅️ ::MatMul(%\"layer_norm_6\", %\"val_279\"{...})\n",
       "            134 |  # node_linear_20\n",
       "                   %\"linear_20\"<FLOAT,[1,7,768]> ⬅️ ::Add(%\"val_280\", %\"bert.encoder.layer.3.attention.self.value.bias\"{...})\n",
       "            135 |  # node_view_14\n",
       "                   %\"view_14\"<FLOAT,[1,7,12,64]> ⬅️ ::Reshape(%\"linear_20\", %\"val_46\"{[1, -1, 12, 64]}) {allowzero=1}\n",
       "            136 |  # node_transpose_14\n",
       "                   %\"transpose_14\"<FLOAT,[1,12,7,64]> ⬅️ ::Transpose(%\"view_14\") {perm=(0, 2, 1, 3)}\n",
       "            137 |  # node_Reshape_290\n",
       "                   %\"val_304\"<FLOAT,[12,7,64]> ⬅️ ::Reshape(%\"transpose_13\", %\"val_81\"{[-1, 7, 64]}) {allowzero=0}\n",
       "            138 |  # node_Transpose_291\n",
       "                   %\"val_305\"<FLOAT,[12,64,7]> ⬅️ ::Transpose(%\"val_304\") {perm=(0, 2, 1)}\n",
       "            139 |  # node_Reshape_293\n",
       "                   %\"val_307\"<FLOAT,[1,12,64,7]> ⬅️ ::Reshape(%\"val_305\", %\"val_84\"{[1, 12, 64, 7]}) {allowzero=0}\n",
       "            140 |  # node_Mul_295\n",
       "                   %\"val_309\"<FLOAT,[1,12,7,64]> ⬅️ ::Mul(%\"transpose_12\", %\"val_86\"{[0.3535533845424652]})\n",
       "            141 |  # node_Mul_297\n",
       "                   %\"val_311\"<FLOAT,[1,12,64,7]> ⬅️ ::Mul(%\"val_307\", %\"val_86\"{[0.3535533845424652]})\n",
       "            142 |  # node_MatMul_298\n",
       "                   %\"val_312\"<FLOAT,[1,12,7,7]> ⬅️ ::MatMul(%\"val_309\", %\"val_311\")\n",
       "            143 |  # node_Add_299\n",
       "                   %\"val_313\"<FLOAT,[1,12,7,7]> ⬅️ ::Add(%\"val_312\", %\"masked_fill\")\n",
       "            144 |  # node_Softmax_300\n",
       "                   %\"val_314\"<FLOAT,[1,12,7,7]> ⬅️ ::Softmax(%\"val_313\") {axis=-1}\n",
       "            145 |  # node_scaled_dot_product_attention_3\n",
       "                   %\"scaled_dot_product_attention_3\"<FLOAT,[1,12,7,64]> ⬅️ ::MatMul(%\"val_314\", %\"transpose_14\")\n",
       "            146 |  # node_transpose_15\n",
       "                   %\"transpose_15\"<FLOAT,[1,7,12,64]> ⬅️ ::Transpose(%\"scaled_dot_product_attention_3\") {perm=(0, 2, 1, 3)}\n",
       "            147 |  # node_view_15\n",
       "                   %\"view_15\"<FLOAT,[1,7,768]> ⬅️ ::Reshape(%\"transpose_15\", %\"val_97\"{[1, 7, 768]}) {allowzero=1}\n",
       "            148 |  # node_MatMul_307\n",
       "                   %\"val_321\"<FLOAT,[1,7,768]> ⬅️ ::MatMul(%\"view_15\", %\"val_320\"{...})\n",
       "            149 |  # node_linear_21\n",
       "                   %\"linear_21\"<FLOAT,[1,7,768]> ⬅️ ::Add(%\"val_321\", %\"bert.encoder.layer.3.attention.output.dense.bias\"{...})\n",
       "            150 |  # node_add_8\n",
       "                   %\"add_8\"<FLOAT,[1,7,768]> ⬅️ ::Add(%\"linear_21\", %\"layer_norm_6\")\n",
       "            151 |  # node_layer_norm_7\n",
       "                   %\"layer_norm_7\"<FLOAT,[1,7,768]>, %\"\"<?,?>, %\"\"<?,?> ⬅️ ::LayerNormalization(%\"add_8\", %\"bert.encoder.layer.3.attention.output.LayerNorm.weight\"{...}, %\"bert.encoder.layer.3.attention.output.LayerNorm.bias\"{...}) {axis=-1, epsilon=1e-12, stash_type=1}\n",
       "            152 |  # node_MatMul_309\n",
       "                   %\"val_325\"<FLOAT,[1,7,3072]> ⬅️ ::MatMul(%\"layer_norm_7\", %\"val_324\"{...})\n",
       "            153 |  # node_linear_22\n",
       "                   %\"linear_22\"<FLOAT,[1,7,3072]> ⬅️ ::Add(%\"val_325\", %\"bert.encoder.layer.3.intermediate.dense.bias\"{...})\n",
       "            154 |  # node_Div_311\n",
       "                   %\"val_327\"<FLOAT,[1,7,3072]> ⬅️ ::Div(%\"linear_22\", %\"val_104\"{1.4142135381698608})\n",
       "            155 |  # node_Erf_312\n",
       "                   %\"val_328\"<FLOAT,[1,7,3072]> ⬅️ ::Erf(%\"val_327\")\n",
       "            156 |  # node_Add_314\n",
       "                   %\"val_330\"<FLOAT,[1,7,3072]> ⬅️ ::Add(%\"val_328\", %\"clone_1\"{1.0})\n",
       "            157 |  # node_Mul_316\n",
       "                   %\"val_332\"<FLOAT,[1,7,3072]> ⬅️ ::Mul(%\"val_109\"{0.5}, %\"val_330\")\n",
       "            158 |  # node_gelu_3\n",
       "                   %\"gelu_3\"<FLOAT,[1,7,3072]> ⬅️ ::Mul(%\"linear_22\", %\"val_332\")\n",
       "            159 |  # node_MatMul_318\n",
       "                   %\"val_334\"<FLOAT,[1,7,768]> ⬅️ ::MatMul(%\"gelu_3\", %\"val_333\"{...})\n",
       "            160 |  # node_linear_23\n",
       "                   %\"linear_23\"<FLOAT,[1,7,768]> ⬅️ ::Add(%\"val_334\", %\"bert.encoder.layer.3.output.dense.bias\"{...})\n",
       "            161 |  # node_add_9\n",
       "                   %\"add_9\"<FLOAT,[1,7,768]> ⬅️ ::Add(%\"linear_23\", %\"layer_norm_7\")\n",
       "            162 |  # node_layer_norm_8\n",
       "                   %\"layer_norm_8\"<FLOAT,[1,7,768]>, %\"\"<?,?>, %\"\"<?,?> ⬅️ ::LayerNormalization(%\"add_9\", %\"bert.encoder.layer.3.output.LayerNorm.weight\"{...}, %\"bert.encoder.layer.3.output.LayerNorm.bias\"{...}) {axis=-1, epsilon=1e-12, stash_type=1}\n",
       "            163 |  # node_MatMul_320\n",
       "                   %\"val_338\"<FLOAT,[1,7,768]> ⬅️ ::MatMul(%\"layer_norm_8\", %\"val_337\"{...})\n",
       "            164 |  # node_linear_24\n",
       "                   %\"linear_24\"<FLOAT,[1,7,768]> ⬅️ ::Add(%\"val_338\", %\"bert.encoder.layer.4.attention.self.query.bias\"{...})\n",
       "            165 |  # node_view_16\n",
       "                   %\"view_16\"<FLOAT,[1,7,12,64]> ⬅️ ::Reshape(%\"linear_24\", %\"val_46\"{[1, -1, 12, 64]}) {allowzero=1}\n",
       "            166 |  # node_transpose_16\n",
       "                   %\"transpose_16\"<FLOAT,[1,12,7,64]> ⬅️ ::Transpose(%\"view_16\") {perm=(0, 2, 1, 3)}\n",
       "            167 |  # node_MatMul_328\n",
       "                   %\"val_346\"<FLOAT,[1,7,768]> ⬅️ ::MatMul(%\"layer_norm_8\", %\"val_345\"{...})\n",
       "            168 |  # node_linear_25\n",
       "                   %\"linear_25\"<FLOAT,[1,7,768]> ⬅️ ::Add(%\"val_346\", %\"bert.encoder.layer.4.attention.self.key.bias\"{...})\n",
       "            169 |  # node_view_17\n",
       "                   %\"view_17\"<FLOAT,[1,7,12,64]> ⬅️ ::Reshape(%\"linear_25\", %\"val_46\"{[1, -1, 12, 64]}) {allowzero=1}\n",
       "            170 |  # node_transpose_17\n",
       "                   %\"transpose_17\"<FLOAT,[1,12,7,64]> ⬅️ ::Transpose(%\"view_17\") {perm=(0, 2, 1, 3)}\n",
       "            171 |  # node_MatMul_336\n",
       "                   %\"val_354\"<FLOAT,[1,7,768]> ⬅️ ::MatMul(%\"layer_norm_8\", %\"val_353\"{...})\n",
       "            172 |  # node_linear_26\n",
       "                   %\"linear_26\"<FLOAT,[1,7,768]> ⬅️ ::Add(%\"val_354\", %\"bert.encoder.layer.4.attention.self.value.bias\"{...})\n",
       "            173 |  # node_view_18\n",
       "                   %\"view_18\"<FLOAT,[1,7,12,64]> ⬅️ ::Reshape(%\"linear_26\", %\"val_46\"{[1, -1, 12, 64]}) {allowzero=1}\n",
       "            174 |  # node_transpose_18\n",
       "                   %\"transpose_18\"<FLOAT,[1,12,7,64]> ⬅️ ::Transpose(%\"view_18\") {perm=(0, 2, 1, 3)}\n",
       "            175 |  # node_Reshape_360\n",
       "                   %\"val_378\"<FLOAT,[12,7,64]> ⬅️ ::Reshape(%\"transpose_17\", %\"val_81\"{[-1, 7, 64]}) {allowzero=0}\n",
       "            176 |  # node_Transpose_361\n",
       "                   %\"val_379\"<FLOAT,[12,64,7]> ⬅️ ::Transpose(%\"val_378\") {perm=(0, 2, 1)}\n",
       "            177 |  # node_Reshape_363\n",
       "                   %\"val_381\"<FLOAT,[1,12,64,7]> ⬅️ ::Reshape(%\"val_379\", %\"val_84\"{[1, 12, 64, 7]}) {allowzero=0}\n",
       "            178 |  # node_Mul_365\n",
       "                   %\"val_383\"<FLOAT,[1,12,7,64]> ⬅️ ::Mul(%\"transpose_16\", %\"val_86\"{[0.3535533845424652]})\n",
       "            179 |  # node_Mul_367\n",
       "                   %\"val_385\"<FLOAT,[1,12,64,7]> ⬅️ ::Mul(%\"val_381\", %\"val_86\"{[0.3535533845424652]})\n",
       "            180 |  # node_MatMul_368\n",
       "                   %\"val_386\"<FLOAT,[1,12,7,7]> ⬅️ ::MatMul(%\"val_383\", %\"val_385\")\n",
       "            181 |  # node_Add_369\n",
       "                   %\"val_387\"<FLOAT,[1,12,7,7]> ⬅️ ::Add(%\"val_386\", %\"masked_fill\")\n",
       "            182 |  # node_Softmax_370\n",
       "                   %\"val_388\"<FLOAT,[1,12,7,7]> ⬅️ ::Softmax(%\"val_387\") {axis=-1}\n",
       "            183 |  # node_scaled_dot_product_attention_4\n",
       "                   %\"scaled_dot_product_attention_4\"<FLOAT,[1,12,7,64]> ⬅️ ::MatMul(%\"val_388\", %\"transpose_18\")\n",
       "            184 |  # node_transpose_19\n",
       "                   %\"transpose_19\"<FLOAT,[1,7,12,64]> ⬅️ ::Transpose(%\"scaled_dot_product_attention_4\") {perm=(0, 2, 1, 3)}\n",
       "            185 |  # node_view_19\n",
       "                   %\"view_19\"<FLOAT,[1,7,768]> ⬅️ ::Reshape(%\"transpose_19\", %\"val_97\"{[1, 7, 768]}) {allowzero=1}\n",
       "            186 |  # node_MatMul_377\n",
       "                   %\"val_395\"<FLOAT,[1,7,768]> ⬅️ ::MatMul(%\"view_19\", %\"val_394\"{...})\n",
       "            187 |  # node_linear_27\n",
       "                   %\"linear_27\"<FLOAT,[1,7,768]> ⬅️ ::Add(%\"val_395\", %\"bert.encoder.layer.4.attention.output.dense.bias\"{...})\n",
       "            188 |  # node_add_10\n",
       "                   %\"add_10\"<FLOAT,[1,7,768]> ⬅️ ::Add(%\"linear_27\", %\"layer_norm_8\")\n",
       "            189 |  # node_layer_norm_9\n",
       "                   %\"layer_norm_9\"<FLOAT,[1,7,768]>, %\"\"<?,?>, %\"\"<?,?> ⬅️ ::LayerNormalization(%\"add_10\", %\"bert.encoder.layer.4.attention.output.LayerNorm.weight\"{...}, %\"bert.encoder.layer.4.attention.output.LayerNorm.bias\"{...}) {axis=-1, epsilon=1e-12, stash_type=1}\n",
       "            190 |  # node_MatMul_379\n",
       "                   %\"val_399\"<FLOAT,[1,7,3072]> ⬅️ ::MatMul(%\"layer_norm_9\", %\"val_398\"{...})\n",
       "            191 |  # node_linear_28\n",
       "                   %\"linear_28\"<FLOAT,[1,7,3072]> ⬅️ ::Add(%\"val_399\", %\"bert.encoder.layer.4.intermediate.dense.bias\"{...})\n",
       "            192 |  # node_Div_381\n",
       "                   %\"val_401\"<FLOAT,[1,7,3072]> ⬅️ ::Div(%\"linear_28\", %\"val_104\"{1.4142135381698608})\n",
       "            193 |  # node_Erf_382\n",
       "                   %\"val_402\"<FLOAT,[1,7,3072]> ⬅️ ::Erf(%\"val_401\")\n",
       "            194 |  # node_Add_384\n",
       "                   %\"val_404\"<FLOAT,[1,7,3072]> ⬅️ ::Add(%\"val_402\", %\"clone_1\"{1.0})\n",
       "            195 |  # node_Mul_386\n",
       "                   %\"val_406\"<FLOAT,[1,7,3072]> ⬅️ ::Mul(%\"val_109\"{0.5}, %\"val_404\")\n",
       "            196 |  # node_gelu_4\n",
       "                   %\"gelu_4\"<FLOAT,[1,7,3072]> ⬅️ ::Mul(%\"linear_28\", %\"val_406\")\n",
       "            197 |  # node_MatMul_388\n",
       "                   %\"val_408\"<FLOAT,[1,7,768]> ⬅️ ::MatMul(%\"gelu_4\", %\"val_407\"{...})\n",
       "            198 |  # node_linear_29\n",
       "                   %\"linear_29\"<FLOAT,[1,7,768]> ⬅️ ::Add(%\"val_408\", %\"bert.encoder.layer.4.output.dense.bias\"{...})\n",
       "            199 |  # node_add_11\n",
       "                   %\"add_11\"<FLOAT,[1,7,768]> ⬅️ ::Add(%\"linear_29\", %\"layer_norm_9\")\n",
       "            200 |  # node_layer_norm_10\n",
       "                   %\"layer_norm_10\"<FLOAT,[1,7,768]>, %\"\"<?,?>, %\"\"<?,?> ⬅️ ::LayerNormalization(%\"add_11\", %\"bert.encoder.layer.4.output.LayerNorm.weight\"{...}, %\"bert.encoder.layer.4.output.LayerNorm.bias\"{...}) {axis=-1, epsilon=1e-12, stash_type=1}\n",
       "            201 |  # node_MatMul_390\n",
       "                   %\"val_412\"<FLOAT,[1,7,768]> ⬅️ ::MatMul(%\"layer_norm_10\", %\"val_411\"{...})\n",
       "            202 |  # node_linear_30\n",
       "                   %\"linear_30\"<FLOAT,[1,7,768]> ⬅️ ::Add(%\"val_412\", %\"bert.encoder.layer.5.attention.self.query.bias\"{...})\n",
       "            203 |  # node_view_20\n",
       "                   %\"view_20\"<FLOAT,[1,7,12,64]> ⬅️ ::Reshape(%\"linear_30\", %\"val_46\"{[1, -1, 12, 64]}) {allowzero=1}\n",
       "            204 |  # node_transpose_20\n",
       "                   %\"transpose_20\"<FLOAT,[1,12,7,64]> ⬅️ ::Transpose(%\"view_20\") {perm=(0, 2, 1, 3)}\n",
       "            205 |  # node_MatMul_398\n",
       "                   %\"val_420\"<FLOAT,[1,7,768]> ⬅️ ::MatMul(%\"layer_norm_10\", %\"val_419\"{...})\n",
       "            206 |  # node_linear_31\n",
       "                   %\"linear_31\"<FLOAT,[1,7,768]> ⬅️ ::Add(%\"val_420\", %\"bert.encoder.layer.5.attention.self.key.bias\"{...})\n",
       "            207 |  # node_view_21\n",
       "                   %\"view_21\"<FLOAT,[1,7,12,64]> ⬅️ ::Reshape(%\"linear_31\", %\"val_46\"{[1, -1, 12, 64]}) {allowzero=1}\n",
       "            208 |  # node_transpose_21\n",
       "                   %\"transpose_21\"<FLOAT,[1,12,7,64]> ⬅️ ::Transpose(%\"view_21\") {perm=(0, 2, 1, 3)}\n",
       "            209 |  # node_MatMul_406\n",
       "                   %\"val_428\"<FLOAT,[1,7,768]> ⬅️ ::MatMul(%\"layer_norm_10\", %\"val_427\"{...})\n",
       "            210 |  # node_linear_32\n",
       "                   %\"linear_32\"<FLOAT,[1,7,768]> ⬅️ ::Add(%\"val_428\", %\"bert.encoder.layer.5.attention.self.value.bias\"{...})\n",
       "            211 |  # node_view_22\n",
       "                   %\"view_22\"<FLOAT,[1,7,12,64]> ⬅️ ::Reshape(%\"linear_32\", %\"val_46\"{[1, -1, 12, 64]}) {allowzero=1}\n",
       "            212 |  # node_transpose_22\n",
       "                   %\"transpose_22\"<FLOAT,[1,12,7,64]> ⬅️ ::Transpose(%\"view_22\") {perm=(0, 2, 1, 3)}\n",
       "            213 |  # node_Reshape_430\n",
       "                   %\"val_452\"<FLOAT,[12,7,64]> ⬅️ ::Reshape(%\"transpose_21\", %\"val_81\"{[-1, 7, 64]}) {allowzero=0}\n",
       "            214 |  # node_Transpose_431\n",
       "                   %\"val_453\"<FLOAT,[12,64,7]> ⬅️ ::Transpose(%\"val_452\") {perm=(0, 2, 1)}\n",
       "            215 |  # node_Reshape_433\n",
       "                   %\"val_455\"<FLOAT,[1,12,64,7]> ⬅️ ::Reshape(%\"val_453\", %\"val_84\"{[1, 12, 64, 7]}) {allowzero=0}\n",
       "            216 |  # node_Mul_435\n",
       "                   %\"val_457\"<FLOAT,[1,12,7,64]> ⬅️ ::Mul(%\"transpose_20\", %\"val_86\"{[0.3535533845424652]})\n",
       "            217 |  # node_Mul_437\n",
       "                   %\"val_459\"<FLOAT,[1,12,64,7]> ⬅️ ::Mul(%\"val_455\", %\"val_86\"{[0.3535533845424652]})\n",
       "            218 |  # node_MatMul_438\n",
       "                   %\"val_460\"<FLOAT,[1,12,7,7]> ⬅️ ::MatMul(%\"val_457\", %\"val_459\")\n",
       "            219 |  # node_Add_439\n",
       "                   %\"val_461\"<FLOAT,[1,12,7,7]> ⬅️ ::Add(%\"val_460\", %\"masked_fill\")\n",
       "            220 |  # node_Softmax_440\n",
       "                   %\"val_462\"<FLOAT,[1,12,7,7]> ⬅️ ::Softmax(%\"val_461\") {axis=-1}\n",
       "            221 |  # node_scaled_dot_product_attention_5\n",
       "                   %\"scaled_dot_product_attention_5\"<FLOAT,[1,12,7,64]> ⬅️ ::MatMul(%\"val_462\", %\"transpose_22\")\n",
       "            222 |  # node_transpose_23\n",
       "                   %\"transpose_23\"<FLOAT,[1,7,12,64]> ⬅️ ::Transpose(%\"scaled_dot_product_attention_5\") {perm=(0, 2, 1, 3)}\n",
       "            223 |  # node_view_23\n",
       "                   %\"view_23\"<FLOAT,[1,7,768]> ⬅️ ::Reshape(%\"transpose_23\", %\"val_97\"{[1, 7, 768]}) {allowzero=1}\n",
       "            224 |  # node_MatMul_447\n",
       "                   %\"val_469\"<FLOAT,[1,7,768]> ⬅️ ::MatMul(%\"view_23\", %\"val_468\"{...})\n",
       "            225 |  # node_linear_33\n",
       "                   %\"linear_33\"<FLOAT,[1,7,768]> ⬅️ ::Add(%\"val_469\", %\"bert.encoder.layer.5.attention.output.dense.bias\"{...})\n",
       "            226 |  # node_add_12\n",
       "                   %\"add_12\"<FLOAT,[1,7,768]> ⬅️ ::Add(%\"linear_33\", %\"layer_norm_10\")\n",
       "            227 |  # node_layer_norm_11\n",
       "                   %\"layer_norm_11\"<FLOAT,[1,7,768]>, %\"\"<?,?>, %\"\"<?,?> ⬅️ ::LayerNormalization(%\"add_12\", %\"bert.encoder.layer.5.attention.output.LayerNorm.weight\"{...}, %\"bert.encoder.layer.5.attention.output.LayerNorm.bias\"{...}) {axis=-1, epsilon=1e-12, stash_type=1}\n",
       "            228 |  # node_MatMul_449\n",
       "                   %\"val_473\"<FLOAT,[1,7,3072]> ⬅️ ::MatMul(%\"layer_norm_11\", %\"val_472\"{...})\n",
       "            229 |  # node_linear_34\n",
       "                   %\"linear_34\"<FLOAT,[1,7,3072]> ⬅️ ::Add(%\"val_473\", %\"bert.encoder.layer.5.intermediate.dense.bias\"{...})\n",
       "            230 |  # node_Div_451\n",
       "                   %\"val_475\"<FLOAT,[1,7,3072]> ⬅️ ::Div(%\"linear_34\", %\"val_104\"{1.4142135381698608})\n",
       "            231 |  # node_Erf_452\n",
       "                   %\"val_476\"<FLOAT,[1,7,3072]> ⬅️ ::Erf(%\"val_475\")\n",
       "            232 |  # node_Add_454\n",
       "                   %\"val_478\"<FLOAT,[1,7,3072]> ⬅️ ::Add(%\"val_476\", %\"clone_1\"{1.0})\n",
       "            233 |  # node_Mul_456\n",
       "                   %\"val_480\"<FLOAT,[1,7,3072]> ⬅️ ::Mul(%\"val_109\"{0.5}, %\"val_478\")\n",
       "            234 |  # node_gelu_5\n",
       "                   %\"gelu_5\"<FLOAT,[1,7,3072]> ⬅️ ::Mul(%\"linear_34\", %\"val_480\")\n",
       "            235 |  # node_MatMul_458\n",
       "                   %\"val_482\"<FLOAT,[1,7,768]> ⬅️ ::MatMul(%\"gelu_5\", %\"val_481\"{...})\n",
       "            236 |  # node_linear_35\n",
       "                   %\"linear_35\"<FLOAT,[1,7,768]> ⬅️ ::Add(%\"val_482\", %\"bert.encoder.layer.5.output.dense.bias\"{...})\n",
       "            237 |  # node_add_13\n",
       "                   %\"add_13\"<FLOAT,[1,7,768]> ⬅️ ::Add(%\"linear_35\", %\"layer_norm_11\")\n",
       "            238 |  # node_layer_norm_12\n",
       "                   %\"layer_norm_12\"<FLOAT,[1,7,768]>, %\"\"<?,?>, %\"\"<?,?> ⬅️ ::LayerNormalization(%\"add_13\", %\"bert.encoder.layer.5.output.LayerNorm.weight\"{...}, %\"bert.encoder.layer.5.output.LayerNorm.bias\"{...}) {axis=-1, epsilon=1e-12, stash_type=1}\n",
       "            239 |  # node_MatMul_460\n",
       "                   %\"val_486\"<FLOAT,[1,7,768]> ⬅️ ::MatMul(%\"layer_norm_12\", %\"val_485\"{...})\n",
       "            240 |  # node_linear_36\n",
       "                   %\"linear_36\"<FLOAT,[1,7,768]> ⬅️ ::Add(%\"val_486\", %\"bert.encoder.layer.6.attention.self.query.bias\"{...})\n",
       "            241 |  # node_view_24\n",
       "                   %\"view_24\"<FLOAT,[1,7,12,64]> ⬅️ ::Reshape(%\"linear_36\", %\"val_46\"{[1, -1, 12, 64]}) {allowzero=1}\n",
       "            242 |  # node_transpose_24\n",
       "                   %\"transpose_24\"<FLOAT,[1,12,7,64]> ⬅️ ::Transpose(%\"view_24\") {perm=(0, 2, 1, 3)}\n",
       "            243 |  # node_MatMul_468\n",
       "                   %\"val_494\"<FLOAT,[1,7,768]> ⬅️ ::MatMul(%\"layer_norm_12\", %\"val_493\"{...})\n",
       "            244 |  # node_linear_37\n",
       "                   %\"linear_37\"<FLOAT,[1,7,768]> ⬅️ ::Add(%\"val_494\", %\"bert.encoder.layer.6.attention.self.key.bias\"{...})\n",
       "            245 |  # node_view_25\n",
       "                   %\"view_25\"<FLOAT,[1,7,12,64]> ⬅️ ::Reshape(%\"linear_37\", %\"val_46\"{[1, -1, 12, 64]}) {allowzero=1}\n",
       "            246 |  # node_transpose_25\n",
       "                   %\"transpose_25\"<FLOAT,[1,12,7,64]> ⬅️ ::Transpose(%\"view_25\") {perm=(0, 2, 1, 3)}\n",
       "            247 |  # node_MatMul_476\n",
       "                   %\"val_502\"<FLOAT,[1,7,768]> ⬅️ ::MatMul(%\"layer_norm_12\", %\"val_501\"{...})\n",
       "            248 |  # node_linear_38\n",
       "                   %\"linear_38\"<FLOAT,[1,7,768]> ⬅️ ::Add(%\"val_502\", %\"bert.encoder.layer.6.attention.self.value.bias\"{...})\n",
       "            249 |  # node_view_26\n",
       "                   %\"view_26\"<FLOAT,[1,7,12,64]> ⬅️ ::Reshape(%\"linear_38\", %\"val_46\"{[1, -1, 12, 64]}) {allowzero=1}\n",
       "            250 |  # node_transpose_26\n",
       "                   %\"transpose_26\"<FLOAT,[1,12,7,64]> ⬅️ ::Transpose(%\"view_26\") {perm=(0, 2, 1, 3)}\n",
       "            251 |  # node_Reshape_500\n",
       "                   %\"val_526\"<FLOAT,[12,7,64]> ⬅️ ::Reshape(%\"transpose_25\", %\"val_81\"{[-1, 7, 64]}) {allowzero=0}\n",
       "            252 |  # node_Transpose_501\n",
       "                   %\"val_527\"<FLOAT,[12,64,7]> ⬅️ ::Transpose(%\"val_526\") {perm=(0, 2, 1)}\n",
       "            253 |  # node_Reshape_503\n",
       "                   %\"val_529\"<FLOAT,[1,12,64,7]> ⬅️ ::Reshape(%\"val_527\", %\"val_84\"{[1, 12, 64, 7]}) {allowzero=0}\n",
       "            254 |  # node_Mul_505\n",
       "                   %\"val_531\"<FLOAT,[1,12,7,64]> ⬅️ ::Mul(%\"transpose_24\", %\"val_86\"{[0.3535533845424652]})\n",
       "            255 |  # node_Mul_507\n",
       "                   %\"val_533\"<FLOAT,[1,12,64,7]> ⬅️ ::Mul(%\"val_529\", %\"val_86\"{[0.3535533845424652]})\n",
       "            256 |  # node_MatMul_508\n",
       "                   %\"val_534\"<FLOAT,[1,12,7,7]> ⬅️ ::MatMul(%\"val_531\", %\"val_533\")\n",
       "            257 |  # node_Add_509\n",
       "                   %\"val_535\"<FLOAT,[1,12,7,7]> ⬅️ ::Add(%\"val_534\", %\"masked_fill\")\n",
       "            258 |  # node_Softmax_510\n",
       "                   %\"val_536\"<FLOAT,[1,12,7,7]> ⬅️ ::Softmax(%\"val_535\") {axis=-1}\n",
       "            259 |  # node_scaled_dot_product_attention_6\n",
       "                   %\"scaled_dot_product_attention_6\"<FLOAT,[1,12,7,64]> ⬅️ ::MatMul(%\"val_536\", %\"transpose_26\")\n",
       "            260 |  # node_transpose_27\n",
       "                   %\"transpose_27\"<FLOAT,[1,7,12,64]> ⬅️ ::Transpose(%\"scaled_dot_product_attention_6\") {perm=(0, 2, 1, 3)}\n",
       "            261 |  # node_view_27\n",
       "                   %\"view_27\"<FLOAT,[1,7,768]> ⬅️ ::Reshape(%\"transpose_27\", %\"val_97\"{[1, 7, 768]}) {allowzero=1}\n",
       "            262 |  # node_MatMul_517\n",
       "                   %\"val_543\"<FLOAT,[1,7,768]> ⬅️ ::MatMul(%\"view_27\", %\"val_542\"{...})\n",
       "            263 |  # node_linear_39\n",
       "                   %\"linear_39\"<FLOAT,[1,7,768]> ⬅️ ::Add(%\"val_543\", %\"bert.encoder.layer.6.attention.output.dense.bias\"{...})\n",
       "            264 |  # node_add_14\n",
       "                   %\"add_14\"<FLOAT,[1,7,768]> ⬅️ ::Add(%\"linear_39\", %\"layer_norm_12\")\n",
       "            265 |  # node_layer_norm_13\n",
       "                   %\"layer_norm_13\"<FLOAT,[1,7,768]>, %\"\"<?,?>, %\"\"<?,?> ⬅️ ::LayerNormalization(%\"add_14\", %\"bert.encoder.layer.6.attention.output.LayerNorm.weight\"{...}, %\"bert.encoder.layer.6.attention.output.LayerNorm.bias\"{...}) {axis=-1, epsilon=1e-12, stash_type=1}\n",
       "            266 |  # node_MatMul_519\n",
       "                   %\"val_547\"<FLOAT,[1,7,3072]> ⬅️ ::MatMul(%\"layer_norm_13\", %\"val_546\"{...})\n",
       "            267 |  # node_linear_40\n",
       "                   %\"linear_40\"<FLOAT,[1,7,3072]> ⬅️ ::Add(%\"val_547\", %\"bert.encoder.layer.6.intermediate.dense.bias\"{...})\n",
       "            268 |  # node_Div_521\n",
       "                   %\"val_549\"<FLOAT,[1,7,3072]> ⬅️ ::Div(%\"linear_40\", %\"val_104\"{1.4142135381698608})\n",
       "            269 |  # node_Erf_522\n",
       "                   %\"val_550\"<FLOAT,[1,7,3072]> ⬅️ ::Erf(%\"val_549\")\n",
       "            270 |  # node_Add_524\n",
       "                   %\"val_552\"<FLOAT,[1,7,3072]> ⬅️ ::Add(%\"val_550\", %\"clone_1\"{1.0})\n",
       "            271 |  # node_Mul_526\n",
       "                   %\"val_554\"<FLOAT,[1,7,3072]> ⬅️ ::Mul(%\"val_109\"{0.5}, %\"val_552\")\n",
       "            272 |  # node_gelu_6\n",
       "                   %\"gelu_6\"<FLOAT,[1,7,3072]> ⬅️ ::Mul(%\"linear_40\", %\"val_554\")\n",
       "            273 |  # node_MatMul_528\n",
       "                   %\"val_556\"<FLOAT,[1,7,768]> ⬅️ ::MatMul(%\"gelu_6\", %\"val_555\"{...})\n",
       "            274 |  # node_linear_41\n",
       "                   %\"linear_41\"<FLOAT,[1,7,768]> ⬅️ ::Add(%\"val_556\", %\"bert.encoder.layer.6.output.dense.bias\"{...})\n",
       "            275 |  # node_add_15\n",
       "                   %\"add_15\"<FLOAT,[1,7,768]> ⬅️ ::Add(%\"linear_41\", %\"layer_norm_13\")\n",
       "            276 |  # node_layer_norm_14\n",
       "                   %\"layer_norm_14\"<FLOAT,[1,7,768]>, %\"\"<?,?>, %\"\"<?,?> ⬅️ ::LayerNormalization(%\"add_15\", %\"bert.encoder.layer.6.output.LayerNorm.weight\"{...}, %\"bert.encoder.layer.6.output.LayerNorm.bias\"{...}) {axis=-1, epsilon=1e-12, stash_type=1}\n",
       "            277 |  # node_MatMul_530\n",
       "                   %\"val_560\"<FLOAT,[1,7,768]> ⬅️ ::MatMul(%\"layer_norm_14\", %\"val_559\"{...})\n",
       "            278 |  # node_linear_42\n",
       "                   %\"linear_42\"<FLOAT,[1,7,768]> ⬅️ ::Add(%\"val_560\", %\"bert.encoder.layer.7.attention.self.query.bias\"{...})\n",
       "            279 |  # node_view_28\n",
       "                   %\"view_28\"<FLOAT,[1,7,12,64]> ⬅️ ::Reshape(%\"linear_42\", %\"val_46\"{[1, -1, 12, 64]}) {allowzero=1}\n",
       "            280 |  # node_transpose_28\n",
       "                   %\"transpose_28\"<FLOAT,[1,12,7,64]> ⬅️ ::Transpose(%\"view_28\") {perm=(0, 2, 1, 3)}\n",
       "            281 |  # node_MatMul_538\n",
       "                   %\"val_568\"<FLOAT,[1,7,768]> ⬅️ ::MatMul(%\"layer_norm_14\", %\"val_567\"{...})\n",
       "            282 |  # node_linear_43\n",
       "                   %\"linear_43\"<FLOAT,[1,7,768]> ⬅️ ::Add(%\"val_568\", %\"bert.encoder.layer.7.attention.self.key.bias\"{...})\n",
       "            283 |  # node_view_29\n",
       "                   %\"view_29\"<FLOAT,[1,7,12,64]> ⬅️ ::Reshape(%\"linear_43\", %\"val_46\"{[1, -1, 12, 64]}) {allowzero=1}\n",
       "            284 |  # node_transpose_29\n",
       "                   %\"transpose_29\"<FLOAT,[1,12,7,64]> ⬅️ ::Transpose(%\"view_29\") {perm=(0, 2, 1, 3)}\n",
       "            285 |  # node_MatMul_546\n",
       "                   %\"val_576\"<FLOAT,[1,7,768]> ⬅️ ::MatMul(%\"layer_norm_14\", %\"val_575\"{...})\n",
       "            286 |  # node_linear_44\n",
       "                   %\"linear_44\"<FLOAT,[1,7,768]> ⬅️ ::Add(%\"val_576\", %\"bert.encoder.layer.7.attention.self.value.bias\"{...})\n",
       "            287 |  # node_view_30\n",
       "                   %\"view_30\"<FLOAT,[1,7,12,64]> ⬅️ ::Reshape(%\"linear_44\", %\"val_46\"{[1, -1, 12, 64]}) {allowzero=1}\n",
       "            288 |  # node_transpose_30\n",
       "                   %\"transpose_30\"<FLOAT,[1,12,7,64]> ⬅️ ::Transpose(%\"view_30\") {perm=(0, 2, 1, 3)}\n",
       "            289 |  # node_Reshape_570\n",
       "                   %\"val_600\"<FLOAT,[12,7,64]> ⬅️ ::Reshape(%\"transpose_29\", %\"val_81\"{[-1, 7, 64]}) {allowzero=0}\n",
       "            290 |  # node_Transpose_571\n",
       "                   %\"val_601\"<FLOAT,[12,64,7]> ⬅️ ::Transpose(%\"val_600\") {perm=(0, 2, 1)}\n",
       "            291 |  # node_Reshape_573\n",
       "                   %\"val_603\"<FLOAT,[1,12,64,7]> ⬅️ ::Reshape(%\"val_601\", %\"val_84\"{[1, 12, 64, 7]}) {allowzero=0}\n",
       "            292 |  # node_Mul_575\n",
       "                   %\"val_605\"<FLOAT,[1,12,7,64]> ⬅️ ::Mul(%\"transpose_28\", %\"val_86\"{[0.3535533845424652]})\n",
       "            293 |  # node_Mul_577\n",
       "                   %\"val_607\"<FLOAT,[1,12,64,7]> ⬅️ ::Mul(%\"val_603\", %\"val_86\"{[0.3535533845424652]})\n",
       "            294 |  # node_MatMul_578\n",
       "                   %\"val_608\"<FLOAT,[1,12,7,7]> ⬅️ ::MatMul(%\"val_605\", %\"val_607\")\n",
       "            295 |  # node_Add_579\n",
       "                   %\"val_609\"<FLOAT,[1,12,7,7]> ⬅️ ::Add(%\"val_608\", %\"masked_fill\")\n",
       "            296 |  # node_Softmax_580\n",
       "                   %\"val_610\"<FLOAT,[1,12,7,7]> ⬅️ ::Softmax(%\"val_609\") {axis=-1}\n",
       "            297 |  # node_scaled_dot_product_attention_7\n",
       "                   %\"scaled_dot_product_attention_7\"<FLOAT,[1,12,7,64]> ⬅️ ::MatMul(%\"val_610\", %\"transpose_30\")\n",
       "            298 |  # node_transpose_31\n",
       "                   %\"transpose_31\"<FLOAT,[1,7,12,64]> ⬅️ ::Transpose(%\"scaled_dot_product_attention_7\") {perm=(0, 2, 1, 3)}\n",
       "            299 |  # node_view_31\n",
       "                   %\"view_31\"<FLOAT,[1,7,768]> ⬅️ ::Reshape(%\"transpose_31\", %\"val_97\"{[1, 7, 768]}) {allowzero=1}\n",
       "            300 |  # node_MatMul_587\n",
       "                   %\"val_617\"<FLOAT,[1,7,768]> ⬅️ ::MatMul(%\"view_31\", %\"val_616\"{...})\n",
       "            301 |  # node_linear_45\n",
       "                   %\"linear_45\"<FLOAT,[1,7,768]> ⬅️ ::Add(%\"val_617\", %\"bert.encoder.layer.7.attention.output.dense.bias\"{...})\n",
       "            302 |  # node_add_16\n",
       "                   %\"add_16\"<FLOAT,[1,7,768]> ⬅️ ::Add(%\"linear_45\", %\"layer_norm_14\")\n",
       "            303 |  # node_layer_norm_15\n",
       "                   %\"layer_norm_15\"<FLOAT,[1,7,768]>, %\"\"<?,?>, %\"\"<?,?> ⬅️ ::LayerNormalization(%\"add_16\", %\"bert.encoder.layer.7.attention.output.LayerNorm.weight\"{...}, %\"bert.encoder.layer.7.attention.output.LayerNorm.bias\"{...}) {axis=-1, epsilon=1e-12, stash_type=1}\n",
       "            304 |  # node_MatMul_589\n",
       "                   %\"val_621\"<FLOAT,[1,7,3072]> ⬅️ ::MatMul(%\"layer_norm_15\", %\"val_620\"{...})\n",
       "            305 |  # node_linear_46\n",
       "                   %\"linear_46\"<FLOAT,[1,7,3072]> ⬅️ ::Add(%\"val_621\", %\"bert.encoder.layer.7.intermediate.dense.bias\"{...})\n",
       "            306 |  # node_Div_591\n",
       "                   %\"val_623\"<FLOAT,[1,7,3072]> ⬅️ ::Div(%\"linear_46\", %\"val_104\"{1.4142135381698608})\n",
       "            307 |  # node_Erf_592\n",
       "                   %\"val_624\"<FLOAT,[1,7,3072]> ⬅️ ::Erf(%\"val_623\")\n",
       "            308 |  # node_Add_594\n",
       "                   %\"val_626\"<FLOAT,[1,7,3072]> ⬅️ ::Add(%\"val_624\", %\"clone_1\"{1.0})\n",
       "            309 |  # node_Mul_596\n",
       "                   %\"val_628\"<FLOAT,[1,7,3072]> ⬅️ ::Mul(%\"val_109\"{0.5}, %\"val_626\")\n",
       "            310 |  # node_gelu_7\n",
       "                   %\"gelu_7\"<FLOAT,[1,7,3072]> ⬅️ ::Mul(%\"linear_46\", %\"val_628\")\n",
       "            311 |  # node_MatMul_598\n",
       "                   %\"val_630\"<FLOAT,[1,7,768]> ⬅️ ::MatMul(%\"gelu_7\", %\"val_629\"{...})\n",
       "            312 |  # node_linear_47\n",
       "                   %\"linear_47\"<FLOAT,[1,7,768]> ⬅️ ::Add(%\"val_630\", %\"bert.encoder.layer.7.output.dense.bias\"{...})\n",
       "            313 |  # node_add_17\n",
       "                   %\"add_17\"<FLOAT,[1,7,768]> ⬅️ ::Add(%\"linear_47\", %\"layer_norm_15\")\n",
       "            314 |  # node_layer_norm_16\n",
       "                   %\"layer_norm_16\"<FLOAT,[1,7,768]>, %\"\"<?,?>, %\"\"<?,?> ⬅️ ::LayerNormalization(%\"add_17\", %\"bert.encoder.layer.7.output.LayerNorm.weight\"{...}, %\"bert.encoder.layer.7.output.LayerNorm.bias\"{...}) {axis=-1, epsilon=1e-12, stash_type=1}\n",
       "            315 |  # node_MatMul_600\n",
       "                   %\"val_634\"<FLOAT,[1,7,768]> ⬅️ ::MatMul(%\"layer_norm_16\", %\"val_633\"{...})\n",
       "            316 |  # node_linear_48\n",
       "                   %\"linear_48\"<FLOAT,[1,7,768]> ⬅️ ::Add(%\"val_634\", %\"bert.encoder.layer.8.attention.self.query.bias\"{...})\n",
       "            317 |  # node_view_32\n",
       "                   %\"view_32\"<FLOAT,[1,7,12,64]> ⬅️ ::Reshape(%\"linear_48\", %\"val_46\"{[1, -1, 12, 64]}) {allowzero=1}\n",
       "            318 |  # node_transpose_32\n",
       "                   %\"transpose_32\"<FLOAT,[1,12,7,64]> ⬅️ ::Transpose(%\"view_32\") {perm=(0, 2, 1, 3)}\n",
       "            319 |  # node_MatMul_608\n",
       "                   %\"val_642\"<FLOAT,[1,7,768]> ⬅️ ::MatMul(%\"layer_norm_16\", %\"val_641\"{...})\n",
       "            320 |  # node_linear_49\n",
       "                   %\"linear_49\"<FLOAT,[1,7,768]> ⬅️ ::Add(%\"val_642\", %\"bert.encoder.layer.8.attention.self.key.bias\"{...})\n",
       "            321 |  # node_view_33\n",
       "                   %\"view_33\"<FLOAT,[1,7,12,64]> ⬅️ ::Reshape(%\"linear_49\", %\"val_46\"{[1, -1, 12, 64]}) {allowzero=1}\n",
       "            322 |  # node_transpose_33\n",
       "                   %\"transpose_33\"<FLOAT,[1,12,7,64]> ⬅️ ::Transpose(%\"view_33\") {perm=(0, 2, 1, 3)}\n",
       "            323 |  # node_MatMul_616\n",
       "                   %\"val_650\"<FLOAT,[1,7,768]> ⬅️ ::MatMul(%\"layer_norm_16\", %\"val_649\"{...})\n",
       "            324 |  # node_linear_50\n",
       "                   %\"linear_50\"<FLOAT,[1,7,768]> ⬅️ ::Add(%\"val_650\", %\"bert.encoder.layer.8.attention.self.value.bias\"{...})\n",
       "            325 |  # node_view_34\n",
       "                   %\"view_34\"<FLOAT,[1,7,12,64]> ⬅️ ::Reshape(%\"linear_50\", %\"val_46\"{[1, -1, 12, 64]}) {allowzero=1}\n",
       "            326 |  # node_transpose_34\n",
       "                   %\"transpose_34\"<FLOAT,[1,12,7,64]> ⬅️ ::Transpose(%\"view_34\") {perm=(0, 2, 1, 3)}\n",
       "            327 |  # node_Reshape_640\n",
       "                   %\"val_674\"<FLOAT,[12,7,64]> ⬅️ ::Reshape(%\"transpose_33\", %\"val_81\"{[-1, 7, 64]}) {allowzero=0}\n",
       "            328 |  # node_Transpose_641\n",
       "                   %\"val_675\"<FLOAT,[12,64,7]> ⬅️ ::Transpose(%\"val_674\") {perm=(0, 2, 1)}\n",
       "            329 |  # node_Reshape_643\n",
       "                   %\"val_677\"<FLOAT,[1,12,64,7]> ⬅️ ::Reshape(%\"val_675\", %\"val_84\"{[1, 12, 64, 7]}) {allowzero=0}\n",
       "            330 |  # node_Mul_645\n",
       "                   %\"val_679\"<FLOAT,[1,12,7,64]> ⬅️ ::Mul(%\"transpose_32\", %\"val_86\"{[0.3535533845424652]})\n",
       "            331 |  # node_Mul_647\n",
       "                   %\"val_681\"<FLOAT,[1,12,64,7]> ⬅️ ::Mul(%\"val_677\", %\"val_86\"{[0.3535533845424652]})\n",
       "            332 |  # node_MatMul_648\n",
       "                   %\"val_682\"<FLOAT,[1,12,7,7]> ⬅️ ::MatMul(%\"val_679\", %\"val_681\")\n",
       "            333 |  # node_Add_649\n",
       "                   %\"val_683\"<FLOAT,[1,12,7,7]> ⬅️ ::Add(%\"val_682\", %\"masked_fill\")\n",
       "            334 |  # node_Softmax_650\n",
       "                   %\"val_684\"<FLOAT,[1,12,7,7]> ⬅️ ::Softmax(%\"val_683\") {axis=-1}\n",
       "            335 |  # node_scaled_dot_product_attention_8\n",
       "                   %\"scaled_dot_product_attention_8\"<FLOAT,[1,12,7,64]> ⬅️ ::MatMul(%\"val_684\", %\"transpose_34\")\n",
       "            336 |  # node_transpose_35\n",
       "                   %\"transpose_35\"<FLOAT,[1,7,12,64]> ⬅️ ::Transpose(%\"scaled_dot_product_attention_8\") {perm=(0, 2, 1, 3)}\n",
       "            337 |  # node_view_35\n",
       "                   %\"view_35\"<FLOAT,[1,7,768]> ⬅️ ::Reshape(%\"transpose_35\", %\"val_97\"{[1, 7, 768]}) {allowzero=1}\n",
       "            338 |  # node_MatMul_657\n",
       "                   %\"val_691\"<FLOAT,[1,7,768]> ⬅️ ::MatMul(%\"view_35\", %\"val_690\"{...})\n",
       "            339 |  # node_linear_51\n",
       "                   %\"linear_51\"<FLOAT,[1,7,768]> ⬅️ ::Add(%\"val_691\", %\"bert.encoder.layer.8.attention.output.dense.bias\"{...})\n",
       "            340 |  # node_add_18\n",
       "                   %\"add_18\"<FLOAT,[1,7,768]> ⬅️ ::Add(%\"linear_51\", %\"layer_norm_16\")\n",
       "            341 |  # node_layer_norm_17\n",
       "                   %\"layer_norm_17\"<FLOAT,[1,7,768]>, %\"\"<?,?>, %\"\"<?,?> ⬅️ ::LayerNormalization(%\"add_18\", %\"bert.encoder.layer.8.attention.output.LayerNorm.weight\"{...}, %\"bert.encoder.layer.8.attention.output.LayerNorm.bias\"{...}) {axis=-1, epsilon=1e-12, stash_type=1}\n",
       "            342 |  # node_MatMul_659\n",
       "                   %\"val_695\"<FLOAT,[1,7,3072]> ⬅️ ::MatMul(%\"layer_norm_17\", %\"val_694\"{...})\n",
       "            343 |  # node_linear_52\n",
       "                   %\"linear_52\"<FLOAT,[1,7,3072]> ⬅️ ::Add(%\"val_695\", %\"bert.encoder.layer.8.intermediate.dense.bias\"{...})\n",
       "            344 |  # node_Div_661\n",
       "                   %\"val_697\"<FLOAT,[1,7,3072]> ⬅️ ::Div(%\"linear_52\", %\"val_104\"{1.4142135381698608})\n",
       "            345 |  # node_Erf_662\n",
       "                   %\"val_698\"<FLOAT,[1,7,3072]> ⬅️ ::Erf(%\"val_697\")\n",
       "            346 |  # node_Add_664\n",
       "                   %\"val_700\"<FLOAT,[1,7,3072]> ⬅️ ::Add(%\"val_698\", %\"clone_1\"{1.0})\n",
       "            347 |  # node_Mul_666\n",
       "                   %\"val_702\"<FLOAT,[1,7,3072]> ⬅️ ::Mul(%\"val_109\"{0.5}, %\"val_700\")\n",
       "            348 |  # node_gelu_8\n",
       "                   %\"gelu_8\"<FLOAT,[1,7,3072]> ⬅️ ::Mul(%\"linear_52\", %\"val_702\")\n",
       "            349 |  # node_MatMul_668\n",
       "                   %\"val_704\"<FLOAT,[1,7,768]> ⬅️ ::MatMul(%\"gelu_8\", %\"val_703\"{...})\n",
       "            350 |  # node_linear_53\n",
       "                   %\"linear_53\"<FLOAT,[1,7,768]> ⬅️ ::Add(%\"val_704\", %\"bert.encoder.layer.8.output.dense.bias\"{...})\n",
       "            351 |  # node_add_19\n",
       "                   %\"add_19\"<FLOAT,[1,7,768]> ⬅️ ::Add(%\"linear_53\", %\"layer_norm_17\")\n",
       "            352 |  # node_layer_norm_18\n",
       "                   %\"layer_norm_18\"<FLOAT,[1,7,768]>, %\"\"<?,?>, %\"\"<?,?> ⬅️ ::LayerNormalization(%\"add_19\", %\"bert.encoder.layer.8.output.LayerNorm.weight\"{...}, %\"bert.encoder.layer.8.output.LayerNorm.bias\"{...}) {axis=-1, epsilon=1e-12, stash_type=1}\n",
       "            353 |  # node_MatMul_670\n",
       "                   %\"val_708\"<FLOAT,[1,7,768]> ⬅️ ::MatMul(%\"layer_norm_18\", %\"val_707\"{...})\n",
       "            354 |  # node_linear_54\n",
       "                   %\"linear_54\"<FLOAT,[1,7,768]> ⬅️ ::Add(%\"val_708\", %\"bert.encoder.layer.9.attention.self.query.bias\"{...})\n",
       "            355 |  # node_view_36\n",
       "                   %\"view_36\"<FLOAT,[1,7,12,64]> ⬅️ ::Reshape(%\"linear_54\", %\"val_46\"{[1, -1, 12, 64]}) {allowzero=1}\n",
       "            356 |  # node_transpose_36\n",
       "                   %\"transpose_36\"<FLOAT,[1,12,7,64]> ⬅️ ::Transpose(%\"view_36\") {perm=(0, 2, 1, 3)}\n",
       "            357 |  # node_MatMul_678\n",
       "                   %\"val_716\"<FLOAT,[1,7,768]> ⬅️ ::MatMul(%\"layer_norm_18\", %\"val_715\"{...})\n",
       "            358 |  # node_linear_55\n",
       "                   %\"linear_55\"<FLOAT,[1,7,768]> ⬅️ ::Add(%\"val_716\", %\"bert.encoder.layer.9.attention.self.key.bias\"{...})\n",
       "            359 |  # node_view_37\n",
       "                   %\"view_37\"<FLOAT,[1,7,12,64]> ⬅️ ::Reshape(%\"linear_55\", %\"val_46\"{[1, -1, 12, 64]}) {allowzero=1}\n",
       "            360 |  # node_transpose_37\n",
       "                   %\"transpose_37\"<FLOAT,[1,12,7,64]> ⬅️ ::Transpose(%\"view_37\") {perm=(0, 2, 1, 3)}\n",
       "            361 |  # node_MatMul_686\n",
       "                   %\"val_724\"<FLOAT,[1,7,768]> ⬅️ ::MatMul(%\"layer_norm_18\", %\"val_723\"{...})\n",
       "            362 |  # node_linear_56\n",
       "                   %\"linear_56\"<FLOAT,[1,7,768]> ⬅️ ::Add(%\"val_724\", %\"bert.encoder.layer.9.attention.self.value.bias\"{...})\n",
       "            363 |  # node_view_38\n",
       "                   %\"view_38\"<FLOAT,[1,7,12,64]> ⬅️ ::Reshape(%\"linear_56\", %\"val_46\"{[1, -1, 12, 64]}) {allowzero=1}\n",
       "            364 |  # node_transpose_38\n",
       "                   %\"transpose_38\"<FLOAT,[1,12,7,64]> ⬅️ ::Transpose(%\"view_38\") {perm=(0, 2, 1, 3)}\n",
       "            365 |  # node_Reshape_710\n",
       "                   %\"val_748\"<FLOAT,[12,7,64]> ⬅️ ::Reshape(%\"transpose_37\", %\"val_81\"{[-1, 7, 64]}) {allowzero=0}\n",
       "            366 |  # node_Transpose_711\n",
       "                   %\"val_749\"<FLOAT,[12,64,7]> ⬅️ ::Transpose(%\"val_748\") {perm=(0, 2, 1)}\n",
       "            367 |  # node_Reshape_713\n",
       "                   %\"val_751\"<FLOAT,[1,12,64,7]> ⬅️ ::Reshape(%\"val_749\", %\"val_84\"{[1, 12, 64, 7]}) {allowzero=0}\n",
       "            368 |  # node_Mul_715\n",
       "                   %\"val_753\"<FLOAT,[1,12,7,64]> ⬅️ ::Mul(%\"transpose_36\", %\"val_86\"{[0.3535533845424652]})\n",
       "            369 |  # node_Mul_717\n",
       "                   %\"val_755\"<FLOAT,[1,12,64,7]> ⬅️ ::Mul(%\"val_751\", %\"val_86\"{[0.3535533845424652]})\n",
       "            370 |  # node_MatMul_718\n",
       "                   %\"val_756\"<FLOAT,[1,12,7,7]> ⬅️ ::MatMul(%\"val_753\", %\"val_755\")\n",
       "            371 |  # node_Add_719\n",
       "                   %\"val_757\"<FLOAT,[1,12,7,7]> ⬅️ ::Add(%\"val_756\", %\"masked_fill\")\n",
       "            372 |  # node_Softmax_720\n",
       "                   %\"val_758\"<FLOAT,[1,12,7,7]> ⬅️ ::Softmax(%\"val_757\") {axis=-1}\n",
       "            373 |  # node_scaled_dot_product_attention_9\n",
       "                   %\"scaled_dot_product_attention_9\"<FLOAT,[1,12,7,64]> ⬅️ ::MatMul(%\"val_758\", %\"transpose_38\")\n",
       "            374 |  # node_transpose_39\n",
       "                   %\"transpose_39\"<FLOAT,[1,7,12,64]> ⬅️ ::Transpose(%\"scaled_dot_product_attention_9\") {perm=(0, 2, 1, 3)}\n",
       "            375 |  # node_view_39\n",
       "                   %\"view_39\"<FLOAT,[1,7,768]> ⬅️ ::Reshape(%\"transpose_39\", %\"val_97\"{[1, 7, 768]}) {allowzero=1}\n",
       "            376 |  # node_MatMul_727\n",
       "                   %\"val_765\"<FLOAT,[1,7,768]> ⬅️ ::MatMul(%\"view_39\", %\"val_764\"{...})\n",
       "            377 |  # node_linear_57\n",
       "                   %\"linear_57\"<FLOAT,[1,7,768]> ⬅️ ::Add(%\"val_765\", %\"bert.encoder.layer.9.attention.output.dense.bias\"{...})\n",
       "            378 |  # node_add_20\n",
       "                   %\"add_20\"<FLOAT,[1,7,768]> ⬅️ ::Add(%\"linear_57\", %\"layer_norm_18\")\n",
       "            379 |  # node_layer_norm_19\n",
       "                   %\"layer_norm_19\"<FLOAT,[1,7,768]>, %\"\"<?,?>, %\"\"<?,?> ⬅️ ::LayerNormalization(%\"add_20\", %\"bert.encoder.layer.9.attention.output.LayerNorm.weight\"{...}, %\"bert.encoder.layer.9.attention.output.LayerNorm.bias\"{...}) {axis=-1, epsilon=1e-12, stash_type=1}\n",
       "            380 |  # node_MatMul_729\n",
       "                   %\"val_769\"<FLOAT,[1,7,3072]> ⬅️ ::MatMul(%\"layer_norm_19\", %\"val_768\"{...})\n",
       "            381 |  # node_linear_58\n",
       "                   %\"linear_58\"<FLOAT,[1,7,3072]> ⬅️ ::Add(%\"val_769\", %\"bert.encoder.layer.9.intermediate.dense.bias\"{...})\n",
       "            382 |  # node_Div_731\n",
       "                   %\"val_771\"<FLOAT,[1,7,3072]> ⬅️ ::Div(%\"linear_58\", %\"val_104\"{1.4142135381698608})\n",
       "            383 |  # node_Erf_732\n",
       "                   %\"val_772\"<FLOAT,[1,7,3072]> ⬅️ ::Erf(%\"val_771\")\n",
       "            384 |  # node_Add_734\n",
       "                   %\"val_774\"<FLOAT,[1,7,3072]> ⬅️ ::Add(%\"val_772\", %\"clone_1\"{1.0})\n",
       "            385 |  # node_Mul_736\n",
       "                   %\"val_776\"<FLOAT,[1,7,3072]> ⬅️ ::Mul(%\"val_109\"{0.5}, %\"val_774\")\n",
       "            386 |  # node_gelu_9\n",
       "                   %\"gelu_9\"<FLOAT,[1,7,3072]> ⬅️ ::Mul(%\"linear_58\", %\"val_776\")\n",
       "            387 |  # node_MatMul_738\n",
       "                   %\"val_778\"<FLOAT,[1,7,768]> ⬅️ ::MatMul(%\"gelu_9\", %\"val_777\"{...})\n",
       "            388 |  # node_linear_59\n",
       "                   %\"linear_59\"<FLOAT,[1,7,768]> ⬅️ ::Add(%\"val_778\", %\"bert.encoder.layer.9.output.dense.bias\"{...})\n",
       "            389 |  # node_add_21\n",
       "                   %\"add_21\"<FLOAT,[1,7,768]> ⬅️ ::Add(%\"linear_59\", %\"layer_norm_19\")\n",
       "            390 |  # node_layer_norm_20\n",
       "                   %\"layer_norm_20\"<FLOAT,[1,7,768]>, %\"\"<?,?>, %\"\"<?,?> ⬅️ ::LayerNormalization(%\"add_21\", %\"bert.encoder.layer.9.output.LayerNorm.weight\"{...}, %\"bert.encoder.layer.9.output.LayerNorm.bias\"{...}) {axis=-1, epsilon=1e-12, stash_type=1}\n",
       "            391 |  # node_MatMul_740\n",
       "                   %\"val_782\"<FLOAT,[1,7,768]> ⬅️ ::MatMul(%\"layer_norm_20\", %\"val_781\"{...})\n",
       "            392 |  # node_linear_60\n",
       "                   %\"linear_60\"<FLOAT,[1,7,768]> ⬅️ ::Add(%\"val_782\", %\"bert.encoder.layer.10.attention.self.query.bias\"{...})\n",
       "            393 |  # node_view_40\n",
       "                   %\"view_40\"<FLOAT,[1,7,12,64]> ⬅️ ::Reshape(%\"linear_60\", %\"val_46\"{[1, -1, 12, 64]}) {allowzero=1}\n",
       "            394 |  # node_transpose_40\n",
       "                   %\"transpose_40\"<FLOAT,[1,12,7,64]> ⬅️ ::Transpose(%\"view_40\") {perm=(0, 2, 1, 3)}\n",
       "            395 |  # node_MatMul_748\n",
       "                   %\"val_790\"<FLOAT,[1,7,768]> ⬅️ ::MatMul(%\"layer_norm_20\", %\"val_789\"{...})\n",
       "            396 |  # node_linear_61\n",
       "                   %\"linear_61\"<FLOAT,[1,7,768]> ⬅️ ::Add(%\"val_790\", %\"bert.encoder.layer.10.attention.self.key.bias\"{...})\n",
       "            397 |  # node_view_41\n",
       "                   %\"view_41\"<FLOAT,[1,7,12,64]> ⬅️ ::Reshape(%\"linear_61\", %\"val_46\"{[1, -1, 12, 64]}) {allowzero=1}\n",
       "            398 |  # node_transpose_41\n",
       "                   %\"transpose_41\"<FLOAT,[1,12,7,64]> ⬅️ ::Transpose(%\"view_41\") {perm=(0, 2, 1, 3)}\n",
       "            399 |  # node_MatMul_756\n",
       "                   %\"val_798\"<FLOAT,[1,7,768]> ⬅️ ::MatMul(%\"layer_norm_20\", %\"val_797\"{...})\n",
       "            400 |  # node_linear_62\n",
       "                   %\"linear_62\"<FLOAT,[1,7,768]> ⬅️ ::Add(%\"val_798\", %\"bert.encoder.layer.10.attention.self.value.bias\"{...})\n",
       "            401 |  # node_view_42\n",
       "                   %\"view_42\"<FLOAT,[1,7,12,64]> ⬅️ ::Reshape(%\"linear_62\", %\"val_46\"{[1, -1, 12, 64]}) {allowzero=1}\n",
       "            402 |  # node_transpose_42\n",
       "                   %\"transpose_42\"<FLOAT,[1,12,7,64]> ⬅️ ::Transpose(%\"view_42\") {perm=(0, 2, 1, 3)}\n",
       "            403 |  # node_Reshape_780\n",
       "                   %\"val_822\"<FLOAT,[12,7,64]> ⬅️ ::Reshape(%\"transpose_41\", %\"val_81\"{[-1, 7, 64]}) {allowzero=0}\n",
       "            404 |  # node_Transpose_781\n",
       "                   %\"val_823\"<FLOAT,[12,64,7]> ⬅️ ::Transpose(%\"val_822\") {perm=(0, 2, 1)}\n",
       "            405 |  # node_Reshape_783\n",
       "                   %\"val_825\"<FLOAT,[1,12,64,7]> ⬅️ ::Reshape(%\"val_823\", %\"val_84\"{[1, 12, 64, 7]}) {allowzero=0}\n",
       "            406 |  # node_Mul_785\n",
       "                   %\"val_827\"<FLOAT,[1,12,7,64]> ⬅️ ::Mul(%\"transpose_40\", %\"val_86\"{[0.3535533845424652]})\n",
       "            407 |  # node_Mul_787\n",
       "                   %\"val_829\"<FLOAT,[1,12,64,7]> ⬅️ ::Mul(%\"val_825\", %\"val_86\"{[0.3535533845424652]})\n",
       "            408 |  # node_MatMul_788\n",
       "                   %\"val_830\"<FLOAT,[1,12,7,7]> ⬅️ ::MatMul(%\"val_827\", %\"val_829\")\n",
       "            409 |  # node_Add_789\n",
       "                   %\"val_831\"<FLOAT,[1,12,7,7]> ⬅️ ::Add(%\"val_830\", %\"masked_fill\")\n",
       "            410 |  # node_Softmax_790\n",
       "                   %\"val_832\"<FLOAT,[1,12,7,7]> ⬅️ ::Softmax(%\"val_831\") {axis=-1}\n",
       "            411 |  # node_scaled_dot_product_attention_10\n",
       "                   %\"scaled_dot_product_attention_10\"<FLOAT,[1,12,7,64]> ⬅️ ::MatMul(%\"val_832\", %\"transpose_42\")\n",
       "            412 |  # node_transpose_43\n",
       "                   %\"transpose_43\"<FLOAT,[1,7,12,64]> ⬅️ ::Transpose(%\"scaled_dot_product_attention_10\") {perm=(0, 2, 1, 3)}\n",
       "            413 |  # node_view_43\n",
       "                   %\"view_43\"<FLOAT,[1,7,768]> ⬅️ ::Reshape(%\"transpose_43\", %\"val_97\"{[1, 7, 768]}) {allowzero=1}\n",
       "            414 |  # node_MatMul_797\n",
       "                   %\"val_839\"<FLOAT,[1,7,768]> ⬅️ ::MatMul(%\"view_43\", %\"val_838\"{...})\n",
       "            415 |  # node_linear_63\n",
       "                   %\"linear_63\"<FLOAT,[1,7,768]> ⬅️ ::Add(%\"val_839\", %\"bert.encoder.layer.10.attention.output.dense.bias\"{...})\n",
       "            416 |  # node_add_22\n",
       "                   %\"add_22\"<FLOAT,[1,7,768]> ⬅️ ::Add(%\"linear_63\", %\"layer_norm_20\")\n",
       "            417 |  # node_layer_norm_21\n",
       "                   %\"layer_norm_21\"<FLOAT,[1,7,768]>, %\"\"<?,?>, %\"\"<?,?> ⬅️ ::LayerNormalization(%\"add_22\", %\"bert.encoder.layer.10.attention.output.LayerNorm.weight\"{...}, %\"bert.encoder.layer.10.attention.output.LayerNorm.bias\"{...}) {axis=-1, epsilon=1e-12, stash_type=1}\n",
       "            418 |  # node_MatMul_799\n",
       "                   %\"val_843\"<FLOAT,[1,7,3072]> ⬅️ ::MatMul(%\"layer_norm_21\", %\"val_842\"{...})\n",
       "            419 |  # node_linear_64\n",
       "                   %\"linear_64\"<FLOAT,[1,7,3072]> ⬅️ ::Add(%\"val_843\", %\"bert.encoder.layer.10.intermediate.dense.bias\"{...})\n",
       "            420 |  # node_Div_801\n",
       "                   %\"val_845\"<FLOAT,[1,7,3072]> ⬅️ ::Div(%\"linear_64\", %\"val_104\"{1.4142135381698608})\n",
       "            421 |  # node_Erf_802\n",
       "                   %\"val_846\"<FLOAT,[1,7,3072]> ⬅️ ::Erf(%\"val_845\")\n",
       "            422 |  # node_Add_804\n",
       "                   %\"val_848\"<FLOAT,[1,7,3072]> ⬅️ ::Add(%\"val_846\", %\"clone_1\"{1.0})\n",
       "            423 |  # node_Mul_806\n",
       "                   %\"val_850\"<FLOAT,[1,7,3072]> ⬅️ ::Mul(%\"val_109\"{0.5}, %\"val_848\")\n",
       "            424 |  # node_gelu_10\n",
       "                   %\"gelu_10\"<FLOAT,[1,7,3072]> ⬅️ ::Mul(%\"linear_64\", %\"val_850\")\n",
       "            425 |  # node_MatMul_808\n",
       "                   %\"val_852\"<FLOAT,[1,7,768]> ⬅️ ::MatMul(%\"gelu_10\", %\"val_851\"{...})\n",
       "            426 |  # node_linear_65\n",
       "                   %\"linear_65\"<FLOAT,[1,7,768]> ⬅️ ::Add(%\"val_852\", %\"bert.encoder.layer.10.output.dense.bias\"{...})\n",
       "            427 |  # node_add_23\n",
       "                   %\"add_23\"<FLOAT,[1,7,768]> ⬅️ ::Add(%\"linear_65\", %\"layer_norm_21\")\n",
       "            428 |  # node_layer_norm_22\n",
       "                   %\"layer_norm_22\"<FLOAT,[1,7,768]>, %\"\"<?,?>, %\"\"<?,?> ⬅️ ::LayerNormalization(%\"add_23\", %\"bert.encoder.layer.10.output.LayerNorm.weight\"{...}, %\"bert.encoder.layer.10.output.LayerNorm.bias\"{...}) {axis=-1, epsilon=1e-12, stash_type=1}\n",
       "            429 |  # node_MatMul_810\n",
       "                   %\"val_856\"<FLOAT,[1,7,768]> ⬅️ ::MatMul(%\"layer_norm_22\", %\"val_855\"{...})\n",
       "            430 |  # node_linear_66\n",
       "                   %\"linear_66\"<FLOAT,[1,7,768]> ⬅️ ::Add(%\"val_856\", %\"bert.encoder.layer.11.attention.self.query.bias\"{...})\n",
       "            431 |  # node_view_44\n",
       "                   %\"view_44\"<FLOAT,[1,7,12,64]> ⬅️ ::Reshape(%\"linear_66\", %\"val_46\"{[1, -1, 12, 64]}) {allowzero=1}\n",
       "            432 |  # node_transpose_44\n",
       "                   %\"transpose_44\"<FLOAT,[1,12,7,64]> ⬅️ ::Transpose(%\"view_44\") {perm=(0, 2, 1, 3)}\n",
       "            433 |  # node_MatMul_818\n",
       "                   %\"val_864\"<FLOAT,[1,7,768]> ⬅️ ::MatMul(%\"layer_norm_22\", %\"val_863\"{...})\n",
       "            434 |  # node_linear_67\n",
       "                   %\"linear_67\"<FLOAT,[1,7,768]> ⬅️ ::Add(%\"val_864\", %\"bert.encoder.layer.11.attention.self.key.bias\"{...})\n",
       "            435 |  # node_view_45\n",
       "                   %\"view_45\"<FLOAT,[1,7,12,64]> ⬅️ ::Reshape(%\"linear_67\", %\"val_46\"{[1, -1, 12, 64]}) {allowzero=1}\n",
       "            436 |  # node_transpose_45\n",
       "                   %\"transpose_45\"<FLOAT,[1,12,7,64]> ⬅️ ::Transpose(%\"view_45\") {perm=(0, 2, 1, 3)}\n",
       "            437 |  # node_MatMul_826\n",
       "                   %\"val_872\"<FLOAT,[1,7,768]> ⬅️ ::MatMul(%\"layer_norm_22\", %\"val_871\"{...})\n",
       "            438 |  # node_linear_68\n",
       "                   %\"linear_68\"<FLOAT,[1,7,768]> ⬅️ ::Add(%\"val_872\", %\"bert.encoder.layer.11.attention.self.value.bias\"{...})\n",
       "            439 |  # node_view_46\n",
       "                   %\"view_46\"<FLOAT,[1,7,12,64]> ⬅️ ::Reshape(%\"linear_68\", %\"val_46\"{[1, -1, 12, 64]}) {allowzero=1}\n",
       "            440 |  # node_transpose_46\n",
       "                   %\"transpose_46\"<FLOAT,[1,12,7,64]> ⬅️ ::Transpose(%\"view_46\") {perm=(0, 2, 1, 3)}\n",
       "            441 |  # node_Reshape_850\n",
       "                   %\"val_896\"<FLOAT,[12,7,64]> ⬅️ ::Reshape(%\"transpose_45\", %\"val_81\"{[-1, 7, 64]}) {allowzero=0}\n",
       "            442 |  # node_Transpose_851\n",
       "                   %\"val_897\"<FLOAT,[12,64,7]> ⬅️ ::Transpose(%\"val_896\") {perm=(0, 2, 1)}\n",
       "            443 |  # node_Reshape_853\n",
       "                   %\"val_899\"<FLOAT,[1,12,64,7]> ⬅️ ::Reshape(%\"val_897\", %\"val_84\"{[1, 12, 64, 7]}) {allowzero=0}\n",
       "            444 |  # node_Mul_855\n",
       "                   %\"val_901\"<FLOAT,[1,12,7,64]> ⬅️ ::Mul(%\"transpose_44\", %\"val_86\"{[0.3535533845424652]})\n",
       "            445 |  # node_Mul_857\n",
       "                   %\"val_903\"<FLOAT,[1,12,64,7]> ⬅️ ::Mul(%\"val_899\", %\"val_86\"{[0.3535533845424652]})\n",
       "            446 |  # node_MatMul_858\n",
       "                   %\"val_904\"<FLOAT,[1,12,7,7]> ⬅️ ::MatMul(%\"val_901\", %\"val_903\")\n",
       "            447 |  # node_Add_859\n",
       "                   %\"val_905\"<FLOAT,[1,12,7,7]> ⬅️ ::Add(%\"val_904\", %\"masked_fill\")\n",
       "            448 |  # node_Softmax_860\n",
       "                   %\"val_906\"<FLOAT,[1,12,7,7]> ⬅️ ::Softmax(%\"val_905\") {axis=-1}\n",
       "            449 |  # node_scaled_dot_product_attention_11\n",
       "                   %\"scaled_dot_product_attention_11\"<FLOAT,[1,12,7,64]> ⬅️ ::MatMul(%\"val_906\", %\"transpose_46\")\n",
       "            450 |  # node_transpose_47\n",
       "                   %\"transpose_47\"<FLOAT,[1,7,12,64]> ⬅️ ::Transpose(%\"scaled_dot_product_attention_11\") {perm=(0, 2, 1, 3)}\n",
       "            451 |  # node_view_47\n",
       "                   %\"view_47\"<FLOAT,[1,7,768]> ⬅️ ::Reshape(%\"transpose_47\", %\"val_97\"{[1, 7, 768]}) {allowzero=1}\n",
       "            452 |  # node_MatMul_867\n",
       "                   %\"val_913\"<FLOAT,[1,7,768]> ⬅️ ::MatMul(%\"view_47\", %\"val_912\"{...})\n",
       "            453 |  # node_linear_69\n",
       "                   %\"linear_69\"<FLOAT,[1,7,768]> ⬅️ ::Add(%\"val_913\", %\"bert.encoder.layer.11.attention.output.dense.bias\"{...})\n",
       "            454 |  # node_add_24\n",
       "                   %\"add_24\"<FLOAT,[1,7,768]> ⬅️ ::Add(%\"linear_69\", %\"layer_norm_22\")\n",
       "            455 |  # node_layer_norm_23\n",
       "                   %\"layer_norm_23\"<FLOAT,[1,7,768]>, %\"\"<?,?>, %\"\"<?,?> ⬅️ ::LayerNormalization(%\"add_24\", %\"bert.encoder.layer.11.attention.output.LayerNorm.weight\"{...}, %\"bert.encoder.layer.11.attention.output.LayerNorm.bias\"{...}) {axis=-1, epsilon=1e-12, stash_type=1}\n",
       "            456 |  # node_MatMul_869\n",
       "                   %\"val_917\"<FLOAT,[1,7,3072]> ⬅️ ::MatMul(%\"layer_norm_23\", %\"val_916\"{...})\n",
       "            457 |  # node_linear_70\n",
       "                   %\"linear_70\"<FLOAT,[1,7,3072]> ⬅️ ::Add(%\"val_917\", %\"bert.encoder.layer.11.intermediate.dense.bias\"{...})\n",
       "            458 |  # node_Div_871\n",
       "                   %\"val_919\"<FLOAT,[1,7,3072]> ⬅️ ::Div(%\"linear_70\", %\"val_104\"{1.4142135381698608})\n",
       "            459 |  # node_Erf_872\n",
       "                   %\"val_920\"<FLOAT,[1,7,3072]> ⬅️ ::Erf(%\"val_919\")\n",
       "            460 |  # node_Add_874\n",
       "                   %\"val_922\"<FLOAT,[1,7,3072]> ⬅️ ::Add(%\"val_920\", %\"clone_1\"{1.0})\n",
       "            461 |  # node_Mul_876\n",
       "                   %\"val_924\"<FLOAT,[1,7,3072]> ⬅️ ::Mul(%\"val_109\"{0.5}, %\"val_922\")\n",
       "            462 |  # node_gelu_11\n",
       "                   %\"gelu_11\"<FLOAT,[1,7,3072]> ⬅️ ::Mul(%\"linear_70\", %\"val_924\")\n",
       "            463 |  # node_MatMul_878\n",
       "                   %\"val_926\"<FLOAT,[1,7,768]> ⬅️ ::MatMul(%\"gelu_11\", %\"val_925\"{...})\n",
       "            464 |  # node_linear_71\n",
       "                   %\"linear_71\"<FLOAT,[1,7,768]> ⬅️ ::Add(%\"val_926\", %\"bert.encoder.layer.11.output.dense.bias\"{...})\n",
       "            465 |  # node_add_25\n",
       "                   %\"add_25\"<FLOAT,[1,7,768]> ⬅️ ::Add(%\"linear_71\", %\"layer_norm_23\")\n",
       "            466 |  # node_layer_norm_24\n",
       "                   %\"layer_norm_24\"<FLOAT,[1,7,768]>, %\"\"<?,?>, %\"\"<?,?> ⬅️ ::LayerNormalization(%\"add_25\", %\"bert.encoder.layer.11.output.LayerNorm.weight\"{...}, %\"bert.encoder.layer.11.output.LayerNorm.bias\"{...}) {axis=-1, epsilon=1e-12, stash_type=1}\n",
       "            467 |  # node_select\n",
       "                   %\"select\"<FLOAT,[1,768]> ⬅️ ::Gather(%\"layer_norm_24\", %\"val_0\"{0}) {axis=1}\n",
       "            468 |  # node_linear_72\n",
       "                   %\"linear_72\"<FLOAT,[1,768]> ⬅️ ::Gemm(%\"select\", %\"bert.pooler.dense.weight\"{...}, %\"bert.pooler.dense.bias\"{...}) {transA=0, transB=1, alpha=1.0, beta=1.0}\n",
       "            469 |  # node_tanh\n",
       "                   %\"tanh\"<FLOAT,[1,768]> ⬅️ ::Tanh(%\"linear_72\")\n",
       "            470 |  # node_linear_73\n",
       "                   %\"logits\"<FLOAT,[1,2]> ⬅️ ::Gemm(%\"tanh\", %\"classifier.weight\"{...}, %\"classifier.bias\"{[0.0010369560914114118, -0.0010363702895119786]}) {transA=0, transB=1, alpha=1.0, beta=1.0}\n",
       "            return %\"logits\"<FLOAT,[1,2]>\n",
       "        }\n",
       "\n",
       "\n",
       "    ,\n",
       "    exported_program=\n",
       "        ExportedProgram:\n",
       "            class GraphModule(torch.nn.Module):\n",
       "                def forward(self, p_bert_embeddings_word_embeddings_weight: \"f32[30522, 768]\", p_bert_embeddings_position_embeddings_weight: \"f32[512, 768]\", p_bert_embeddings_token_type_embeddings_weight: \"f32[2, 768]\", p_bert_embeddings_layernorm_weight: \"f32[768]\", p_bert_embeddings_layernorm_bias: \"f32[768]\", p_bert_encoder_layer_0_attention_self_query_weight: \"f32[768, 768]\", p_bert_encoder_layer_0_attention_self_query_bias: \"f32[768]\", p_bert_encoder_layer_0_attention_self_key_weight: \"f32[768, 768]\", p_bert_encoder_layer_0_attention_self_key_bias: \"f32[768]\", p_bert_encoder_layer_0_attention_self_value_weight: \"f32[768, 768]\", p_bert_encoder_layer_0_attention_self_value_bias: \"f32[768]\", p_bert_encoder_layer_0_attention_output_dense_weight: \"f32[768, 768]\", p_bert_encoder_layer_0_attention_output_dense_bias: \"f32[768]\", p_bert_encoder_layer_0_attention_output_layernorm_weight: \"f32[768]\", p_bert_encoder_layer_0_attention_output_layernorm_bias: \"f32[768]\", p_bert_encoder_layer_0_intermediate_dense_weight: \"f32[3072, 768]\", p_bert_encoder_layer_0_intermediate_dense_bias: \"f32[3072]\", p_bert_encoder_layer_0_output_dense_weight: \"f32[768, 3072]\", p_bert_encoder_layer_0_output_dense_bias: \"f32[768]\", p_bert_encoder_layer_0_output_layernorm_weight: \"f32[768]\", p_bert_encoder_layer_0_output_layernorm_bias: \"f32[768]\", p_bert_encoder_layer_1_attention_self_query_weight: \"f32[768, 768]\", p_bert_encoder_layer_1_attention_self_query_bias: \"f32[768]\", p_bert_encoder_layer_1_attention_self_key_weight: \"f32[768, 768]\", p_bert_encoder_layer_1_attention_self_key_bias: \"f32[768]\", p_bert_encoder_layer_1_attention_self_value_weight: \"f32[768, 768]\", p_bert_encoder_layer_1_attention_self_value_bias: \"f32[768]\", p_bert_encoder_layer_1_attention_output_dense_weight: \"f32[768, 768]\", p_bert_encoder_layer_1_attention_output_dense_bias: \"f32[768]\", p_bert_encoder_layer_1_attention_output_layernorm_weight: \"f32[768]\", p_bert_encoder_layer_1_attention_output_layernorm_bias: \"f32[768]\", p_bert_encoder_layer_1_intermediate_dense_weight: \"f32[3072, 768]\", p_bert_encoder_layer_1_intermediate_dense_bias: \"f32[3072]\", p_bert_encoder_layer_1_output_dense_weight: \"f32[768, 3072]\", p_bert_encoder_layer_1_output_dense_bias: \"f32[768]\", p_bert_encoder_layer_1_output_layernorm_weight: \"f32[768]\", p_bert_encoder_layer_1_output_layernorm_bias: \"f32[768]\", p_bert_encoder_layer_2_attention_self_query_weight: \"f32[768, 768]\", p_bert_encoder_layer_2_attention_self_query_bias: \"f32[768]\", p_bert_encoder_layer_2_attention_self_key_weight: \"f32[768, 768]\", p_bert_encoder_layer_2_attention_self_key_bias: \"f32[768]\", p_bert_encoder_layer_2_attention_self_value_weight: \"f32[768, 768]\", p_bert_encoder_layer_2_attention_self_value_bias: \"f32[768]\", p_bert_encoder_layer_2_attention_output_dense_weight: \"f32[768, 768]\", p_bert_encoder_layer_2_attention_output_dense_bias: \"f32[768]\", p_bert_encoder_layer_2_attention_output_layernorm_weight: \"f32[768]\", p_bert_encoder_layer_2_attention_output_layernorm_bias: \"f32[768]\", p_bert_encoder_layer_2_intermediate_dense_weight: \"f32[3072, 768]\", p_bert_encoder_layer_2_intermediate_dense_bias: \"f32[3072]\", p_bert_encoder_layer_2_output_dense_weight: \"f32[768, 3072]\", p_bert_encoder_layer_2_output_dense_bias: \"f32[768]\", p_bert_encoder_layer_2_output_layernorm_weight: \"f32[768]\", p_bert_encoder_layer_2_output_layernorm_bias: \"f32[768]\", p_bert_encoder_layer_3_attention_self_query_weight: \"f32[768, 768]\", p_bert_encoder_layer_3_attention_self_query_bias: \"f32[768]\", p_bert_encoder_layer_3_attention_self_key_weight: \"f32[768, 768]\", p_bert_encoder_layer_3_attention_self_key_bias: \"f32[768]\", p_bert_encoder_layer_3_attention_self_value_weight: \"f32[768, 768]\", p_bert_encoder_layer_3_attention_self_value_bias: \"f32[768]\", p_bert_encoder_layer_3_attention_output_dense_weight: \"f32[768, 768]\", p_bert_encoder_layer_3_attention_output_dense_bias: \"f32[768]\", p_bert_encoder_layer_3_attention_output_layernorm_weight: \"f32[768]\", p_bert_encoder_layer_3_attention_output_layernorm_bias: \"f32[768]\", p_bert_encoder_layer_3_intermediate_dense_weight: \"f32[3072, 768]\", p_bert_encoder_layer_3_intermediate_dense_bias: \"f32[3072]\", p_bert_encoder_layer_3_output_dense_weight: \"f32[768, 3072]\", p_bert_encoder_layer_3_output_dense_bias: \"f32[768]\", p_bert_encoder_layer_3_output_layernorm_weight: \"f32[768]\", p_bert_encoder_layer_3_output_layernorm_bias: \"f32[768]\", p_bert_encoder_layer_4_attention_self_query_weight: \"f32[768, 768]\", p_bert_encoder_layer_4_attention_self_query_bias: \"f32[768]\", p_bert_encoder_layer_4_attention_self_key_weight: \"f32[768, 768]\", p_bert_encoder_layer_4_attention_self_key_bias: \"f32[768]\", p_bert_encoder_layer_4_attention_self_value_weight: \"f32[768, 768]\", p_bert_encoder_layer_4_attention_self_value_bias: \"f32[768]\", p_bert_encoder_layer_4_attention_output_dense_weight: \"f32[768, 768]\", p_bert_encoder_layer_4_attention_output_dense_bias: \"f32[768]\", p_bert_encoder_layer_4_attention_output_layernorm_weight: \"f32[768]\", p_bert_encoder_layer_4_attention_output_layernorm_bias: \"f32[768]\", p_bert_encoder_layer_4_intermediate_dense_weight: \"f32[3072, 768]\", p_bert_encoder_layer_4_intermediate_dense_bias: \"f32[3072]\", p_bert_encoder_layer_4_output_dense_weight: \"f32[768, 3072]\", p_bert_encoder_layer_4_output_dense_bias: \"f32[768]\", p_bert_encoder_layer_4_output_layernorm_weight: \"f32[768]\", p_bert_encoder_layer_4_output_layernorm_bias: \"f32[768]\", p_bert_encoder_layer_5_attention_self_query_weight: \"f32[768, 768]\", p_bert_encoder_layer_5_attention_self_query_bias: \"f32[768]\", p_bert_encoder_layer_5_attention_self_key_weight: \"f32[768, 768]\", p_bert_encoder_layer_5_attention_self_key_bias: \"f32[768]\", p_bert_encoder_layer_5_attention_self_value_weight: \"f32[768, 768]\", p_bert_encoder_layer_5_attention_self_value_bias: \"f32[768]\", p_bert_encoder_layer_5_attention_output_dense_weight: \"f32[768, 768]\", p_bert_encoder_layer_5_attention_output_dense_bias: \"f32[768]\", p_bert_encoder_layer_5_attention_output_layernorm_weight: \"f32[768]\", p_bert_encoder_layer_5_attention_output_layernorm_bias: \"f32[768]\", p_bert_encoder_layer_5_intermediate_dense_weight: \"f32[3072, 768]\", p_bert_encoder_layer_5_intermediate_dense_bias: \"f32[3072]\", p_bert_encoder_layer_5_output_dense_weight: \"f32[768, 3072]\", p_bert_encoder_layer_5_output_dense_bias: \"f32[768]\", p_bert_encoder_layer_5_output_layernorm_weight: \"f32[768]\", p_bert_encoder_layer_5_output_layernorm_bias: \"f32[768]\", p_bert_encoder_layer_6_attention_self_query_weight: \"f32[768, 768]\", p_bert_encoder_layer_6_attention_self_query_bias: \"f32[768]\", p_bert_encoder_layer_6_attention_self_key_weight: \"f32[768, 768]\", p_bert_encoder_layer_6_attention_self_key_bias: \"f32[768]\", p_bert_encoder_layer_6_attention_self_value_weight: \"f32[768, 768]\", p_bert_encoder_layer_6_attention_self_value_bias: \"f32[768]\", p_bert_encoder_layer_6_attention_output_dense_weight: \"f32[768, 768]\", p_bert_encoder_layer_6_attention_output_dense_bias: \"f32[768]\", p_bert_encoder_layer_6_attention_output_layernorm_weight: \"f32[768]\", p_bert_encoder_layer_6_attention_output_layernorm_bias: \"f32[768]\", p_bert_encoder_layer_6_intermediate_dense_weight: \"f32[3072, 768]\", p_bert_encoder_layer_6_intermediate_dense_bias: \"f32[3072]\", p_bert_encoder_layer_6_output_dense_weight: \"f32[768, 3072]\", p_bert_encoder_layer_6_output_dense_bias: \"f32[768]\", p_bert_encoder_layer_6_output_layernorm_weight: \"f32[768]\", p_bert_encoder_layer_6_output_layernorm_bias: \"f32[768]\", p_bert_encoder_layer_7_attention_self_query_weight: \"f32[768, 768]\", p_bert_encoder_layer_7_attention_self_query_bias: \"f32[768]\", p_bert_encoder_layer_7_attention_self_key_weight: \"f32[768, 768]\", p_bert_encoder_layer_7_attention_self_key_bias: \"f32[768]\", p_bert_encoder_layer_7_attention_self_value_weight: \"f32[768, 768]\", p_bert_encoder_layer_7_attention_self_value_bias: \"f32[768]\", p_bert_encoder_layer_7_attention_output_dense_weight: \"f32[768, 768]\", p_bert_encoder_layer_7_attention_output_dense_bias: \"f32[768]\", p_bert_encoder_layer_7_attention_output_layernorm_weight: \"f32[768]\", p_bert_encoder_layer_7_attention_output_layernorm_bias: \"f32[768]\", p_bert_encoder_layer_7_intermediate_dense_weight: \"f32[3072, 768]\", p_bert_encoder_layer_7_intermediate_dense_bias: \"f32[3072]\", p_bert_encoder_layer_7_output_dense_weight: \"f32[768, 3072]\", p_bert_encoder_layer_7_output_dense_bias: \"f32[768]\", p_bert_encoder_layer_7_output_layernorm_weight: \"f32[768]\", p_bert_encoder_layer_7_output_layernorm_bias: \"f32[768]\", p_bert_encoder_layer_8_attention_self_query_weight: \"f32[768, 768]\", p_bert_encoder_layer_8_attention_self_query_bias: \"f32[768]\", p_bert_encoder_layer_8_attention_self_key_weight: \"f32[768, 768]\", p_bert_encoder_layer_8_attention_self_key_bias: \"f32[768]\", p_bert_encoder_layer_8_attention_self_value_weight: \"f32[768, 768]\", p_bert_encoder_layer_8_attention_self_value_bias: \"f32[768]\", p_bert_encoder_layer_8_attention_output_dense_weight: \"f32[768, 768]\", p_bert_encoder_layer_8_attention_output_dense_bias: \"f32[768]\", p_bert_encoder_layer_8_attention_output_layernorm_weight: \"f32[768]\", p_bert_encoder_layer_8_attention_output_layernorm_bias: \"f32[768]\", p_bert_encoder_layer_8_intermediate_dense_weight: \"f32[3072, 768]\", p_bert_encoder_layer_8_intermediate_dense_bias: \"f32[3072]\", p_bert_encoder_layer_8_output_dense_weight: \"f32[768, 3072]\", p_bert_encoder_layer_8_output_dense_bias: \"f32[768]\", p_bert_encoder_layer_8_output_layernorm_weight: \"f32[768]\", p_bert_encoder_layer_8_output_layernorm_bias: \"f32[768]\", p_bert_encoder_layer_9_attention_self_query_weight: \"f32[768, 768]\", p_bert_encoder_layer_9_attention_self_query_bias: \"f32[768]\", p_bert_encoder_layer_9_attention_self_key_weight: \"f32[768, 768]\", p_bert_encoder_layer_9_attention_self_key_bias: \"f32[768]\", p_bert_encoder_layer_9_attention_self_value_weight: \"f32[768, 768]\", p_bert_encoder_layer_9_attention_self_value_bias: \"f32[768]\", p_bert_encoder_layer_9_attention_output_dense_weight: \"f32[768, 768]\", p_bert_encoder_layer_9_attention_output_dense_bias: \"f32[768]\", p_bert_encoder_layer_9_attention_output_layernorm_weight: \"f32[768]\", p_bert_encoder_layer_9_attention_output_layernorm_bias: \"f32[768]\", p_bert_encoder_layer_9_intermediate_dense_weight: \"f32[3072, 768]\", p_bert_encoder_layer_9_intermediate_dense_bias: \"f32[3072]\", p_bert_encoder_layer_9_output_dense_weight: \"f32[768, 3072]\", p_bert_encoder_layer_9_output_dense_bias: \"f32[768]\", p_bert_encoder_layer_9_output_layernorm_weight: \"f32[768]\", p_bert_encoder_layer_9_output_layernorm_bias: \"f32[768]\", p_bert_encoder_layer_10_attention_self_query_weight: \"f32[768, 768]\", p_bert_encoder_layer_10_attention_self_query_bias: \"f32[768]\", p_bert_encoder_layer_10_attention_self_key_weight: \"f32[768, 768]\", p_bert_encoder_layer_10_attention_self_key_bias: \"f32[768]\", p_bert_encoder_layer_10_attention_self_value_weight: \"f32[768, 768]\", p_bert_encoder_layer_10_attention_self_value_bias: \"f32[768]\", p_bert_encoder_layer_10_attention_output_dense_weight: \"f32[768, 768]\", p_bert_encoder_layer_10_attention_output_dense_bias: \"f32[768]\", p_bert_encoder_layer_10_attention_output_layernorm_weight: \"f32[768]\", p_bert_encoder_layer_10_attention_output_layernorm_bias: \"f32[768]\", p_bert_encoder_layer_10_intermediate_dense_weight: \"f32[3072, 768]\", p_bert_encoder_layer_10_intermediate_dense_bias: \"f32[3072]\", p_bert_encoder_layer_10_output_dense_weight: \"f32[768, 3072]\", p_bert_encoder_layer_10_output_dense_bias: \"f32[768]\", p_bert_encoder_layer_10_output_layernorm_weight: \"f32[768]\", p_bert_encoder_layer_10_output_layernorm_bias: \"f32[768]\", p_bert_encoder_layer_11_attention_self_query_weight: \"f32[768, 768]\", p_bert_encoder_layer_11_attention_self_query_bias: \"f32[768]\", p_bert_encoder_layer_11_attention_self_key_weight: \"f32[768, 768]\", p_bert_encoder_layer_11_attention_self_key_bias: \"f32[768]\", p_bert_encoder_layer_11_attention_self_value_weight: \"f32[768, 768]\", p_bert_encoder_layer_11_attention_self_value_bias: \"f32[768]\", p_bert_encoder_layer_11_attention_output_dense_weight: \"f32[768, 768]\", p_bert_encoder_layer_11_attention_output_dense_bias: \"f32[768]\", p_bert_encoder_layer_11_attention_output_layernorm_weight: \"f32[768]\", p_bert_encoder_layer_11_attention_output_layernorm_bias: \"f32[768]\", p_bert_encoder_layer_11_intermediate_dense_weight: \"f32[3072, 768]\", p_bert_encoder_layer_11_intermediate_dense_bias: \"f32[3072]\", p_bert_encoder_layer_11_output_dense_weight: \"f32[768, 3072]\", p_bert_encoder_layer_11_output_dense_bias: \"f32[768]\", p_bert_encoder_layer_11_output_layernorm_weight: \"f32[768]\", p_bert_encoder_layer_11_output_layernorm_bias: \"f32[768]\", p_bert_pooler_dense_weight: \"f32[768, 768]\", p_bert_pooler_dense_bias: \"f32[768]\", p_classifier_weight: \"f32[2, 768]\", p_classifier_bias: \"f32[2]\", c_bert_lifted_tensor_0: \"f32[]\", b_bert_embeddings_position_ids: \"i64[1, 512]\", b_bert_embeddings_token_type_ids: \"i64[1, 512]\", input_ids: \"i64[1, 7]\", attention_mask: \"i64[1, 7]\"):\n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:930 in forward, code: buffered_token_type_ids = self.embeddings.token_type_ids[:, :seq_length]\n",
       "                    slice_1: \"i64[1, 7]\" = torch.ops.aten.slice.Tensor(b_bert_embeddings_token_type_ids, 1, 0, 7);  b_bert_embeddings_token_type_ids = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:931 in forward, code: buffered_token_type_ids_expanded = buffered_token_type_ids.expand(batch_size, seq_length)\n",
       "                    expand: \"i64[1, 7]\" = torch.ops.aten.expand.default(slice_1, [1, 7]);  slice_1 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:165 in forward, code: position_ids = self.position_ids[:, past_key_values_length : seq_length + past_key_values_length]\n",
       "                    slice_2: \"i64[1, 7]\" = torch.ops.aten.slice.Tensor(b_bert_embeddings_position_ids, 1, 0, 7);  b_bert_embeddings_position_ids = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\sparse.py:192 in forward, code: return F.embedding(\n",
       "                    embedding: \"f32[1, 7, 768]\" = torch.ops.aten.embedding.default(p_bert_embeddings_word_embeddings_weight, input_ids, 0);  p_bert_embeddings_word_embeddings_weight = input_ids = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\sparse.py:192 in forward, code: return F.embedding(\n",
       "                    embedding_1: \"f32[1, 7, 768]\" = torch.ops.aten.embedding.default(p_bert_embeddings_token_type_embeddings_weight, expand);  p_bert_embeddings_token_type_embeddings_weight = expand = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:182 in forward, code: embeddings = inputs_embeds + token_type_embeddings\n",
       "                    add: \"f32[1, 7, 768]\" = torch.ops.aten.add.Tensor(embedding, embedding_1);  embedding = embedding_1 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\sparse.py:192 in forward, code: return F.embedding(\n",
       "                    embedding_2: \"f32[1, 7, 768]\" = torch.ops.aten.embedding.default(p_bert_embeddings_position_embeddings_weight, slice_2);  p_bert_embeddings_position_embeddings_weight = slice_2 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:185 in forward, code: embeddings += position_embeddings\n",
       "                    add_1: \"f32[1, 7, 768]\" = torch.ops.aten.add.Tensor(add, embedding_2);  add = embedding_2 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\normalization.py:229 in forward, code: return F.layer_norm(\n",
       "                    layer_norm: \"f32[1, 7, 768]\" = torch.ops.aten.layer_norm.default(add_1, [768], p_bert_embeddings_layernorm_weight, p_bert_embeddings_layernorm_bias, 1e-12);  add_1 = p_bert_embeddings_layernorm_weight = p_bert_embeddings_layernorm_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\dropout.py:73 in forward, code: return F.dropout(input, self.p, self.training, self.inplace)\n",
       "                    clone: \"f32[1, 7, 768]\" = torch.ops.aten.clone.default(layer_norm);  layer_norm = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:966 in forward, code: extended_attention_mask = _prepare_4d_attention_mask_for_sdpa(\n",
       "                    unsqueeze: \"i64[1, 1, 7]\" = torch.ops.aten.unsqueeze.default(attention_mask, 1);  attention_mask = None\n",
       "                    unsqueeze_1: \"i64[1, 1, 1, 7]\" = torch.ops.aten.unsqueeze.default(unsqueeze, 2);  unsqueeze = None\n",
       "                    expand_1: \"i64[1, 1, 7, 7]\" = torch.ops.aten.expand.default(unsqueeze_1, [1, 1, 7, 7]);  unsqueeze_1 = None\n",
       "                    _to_copy: \"f32[1, 1, 7, 7]\" = torch.ops.aten._to_copy.default(expand_1, dtype = torch.float32);  expand_1 = None\n",
       "                    clone_1: \"f32[]\" = torch.ops.aten.clone.default(c_bert_lifted_tensor_0);  c_bert_lifted_tensor_0 = None\n",
       "                    sub: \"f32[1, 1, 7, 7]\" = torch.ops.aten.sub.Tensor(clone_1, _to_copy);  clone_1 = _to_copy = None\n",
       "                    _to_copy_1: \"b8[1, 1, 7, 7]\" = torch.ops.aten._to_copy.default(sub, dtype = torch.bool)\n",
       "                    masked_fill: \"f32[1, 1, 7, 7]\" = torch.ops.aten.masked_fill.Scalar(sub, _to_copy_1, -3.4028234663852886e+38);  sub = _to_copy_1 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear: \"f32[1, 7, 768]\" = torch.ops.aten.linear.default(clone, p_bert_encoder_layer_0_attention_self_query_weight, p_bert_encoder_layer_0_attention_self_query_bias);  p_bert_encoder_layer_0_attention_self_query_weight = p_bert_encoder_layer_0_attention_self_query_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:363 in forward, code: self.query(hidden_states).view(bsz, -1, self.num_attention_heads, self.attention_head_size).transpose(1, 2)\n",
       "                    view: \"f32[1, 7, 12, 64]\" = torch.ops.aten.view.default(linear, [1, -1, 12, 64]);  linear = None\n",
       "                    transpose: \"f32[1, 12, 7, 64]\" = torch.ops.aten.transpose.int(view, 1, 2);  view = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_1: \"f32[1, 7, 768]\" = torch.ops.aten.linear.default(clone, p_bert_encoder_layer_0_attention_self_key_weight, p_bert_encoder_layer_0_attention_self_key_bias);  p_bert_encoder_layer_0_attention_self_key_weight = p_bert_encoder_layer_0_attention_self_key_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:388 in forward, code: .view(bsz, -1, self.num_attention_heads, self.attention_head_size)\n",
       "                    view_1: \"f32[1, 7, 12, 64]\" = torch.ops.aten.view.default(linear_1, [1, -1, 12, 64]);  linear_1 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:389 in forward, code: .transpose(1, 2)\n",
       "                    transpose_1: \"f32[1, 12, 7, 64]\" = torch.ops.aten.transpose.int(view_1, 1, 2);  view_1 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_2: \"f32[1, 7, 768]\" = torch.ops.aten.linear.default(clone, p_bert_encoder_layer_0_attention_self_value_weight, p_bert_encoder_layer_0_attention_self_value_bias);  p_bert_encoder_layer_0_attention_self_value_weight = p_bert_encoder_layer_0_attention_self_value_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:393 in forward, code: .view(bsz, -1, self.num_attention_heads, self.attention_head_size)\n",
       "                    view_2: \"f32[1, 7, 12, 64]\" = torch.ops.aten.view.default(linear_2, [1, -1, 12, 64]);  linear_2 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:394 in forward, code: .transpose(1, 2)\n",
       "                    transpose_2: \"f32[1, 12, 7, 64]\" = torch.ops.aten.transpose.int(view_2, 1, 2);  view_2 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:413 in forward, code: attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
       "                    scaled_dot_product_attention: \"f32[1, 12, 7, 64]\" = torch.ops.aten.scaled_dot_product_attention.default(transpose, transpose_1, transpose_2, masked_fill);  transpose = transpose_1 = transpose_2 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:422 in forward, code: attn_output = attn_output.transpose(1, 2)\n",
       "                    transpose_3: \"f32[1, 7, 12, 64]\" = torch.ops.aten.transpose.int(scaled_dot_product_attention, 1, 2);  scaled_dot_product_attention = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:423 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.all_head_size)\n",
       "                    view_3: \"f32[1, 7, 768]\" = torch.ops.aten.view.default(transpose_3, [1, 7, 768]);  transpose_3 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_3: \"f32[1, 7, 768]\" = torch.ops.aten.linear.default(view_3, p_bert_encoder_layer_0_attention_output_dense_weight, p_bert_encoder_layer_0_attention_output_dense_bias);  view_3 = p_bert_encoder_layer_0_attention_output_dense_weight = p_bert_encoder_layer_0_attention_output_dense_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\dropout.py:73 in forward, code: return F.dropout(input, self.p, self.training, self.inplace)\n",
       "                    clone_2: \"f32[1, 7, 768]\" = torch.ops.aten.clone.default(linear_3);  linear_3 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:438 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
       "                    add_2: \"f32[1, 7, 768]\" = torch.ops.aten.add.Tensor(clone_2, clone);  clone_2 = clone = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\normalization.py:229 in forward, code: return F.layer_norm(\n",
       "                    layer_norm_1: \"f32[1, 7, 768]\" = torch.ops.aten.layer_norm.default(add_2, [768], p_bert_encoder_layer_0_attention_output_layernorm_weight, p_bert_encoder_layer_0_attention_output_layernorm_bias, 1e-12);  add_2 = p_bert_encoder_layer_0_attention_output_layernorm_weight = p_bert_encoder_layer_0_attention_output_layernorm_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_4: \"f32[1, 7, 3072]\" = torch.ops.aten.linear.default(layer_norm_1, p_bert_encoder_layer_0_intermediate_dense_weight, p_bert_encoder_layer_0_intermediate_dense_bias);  p_bert_encoder_layer_0_intermediate_dense_weight = p_bert_encoder_layer_0_intermediate_dense_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\activations.py:85 in forward, code: return self.act(input)\n",
       "                    gelu: \"f32[1, 7, 3072]\" = torch.ops.aten.gelu.default(linear_4);  linear_4 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_5: \"f32[1, 7, 768]\" = torch.ops.aten.linear.default(gelu, p_bert_encoder_layer_0_output_dense_weight, p_bert_encoder_layer_0_output_dense_bias);  gelu = p_bert_encoder_layer_0_output_dense_weight = p_bert_encoder_layer_0_output_dense_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\dropout.py:73 in forward, code: return F.dropout(input, self.p, self.training, self.inplace)\n",
       "                    clone_3: \"f32[1, 7, 768]\" = torch.ops.aten.clone.default(linear_5);  linear_5 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:527 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
       "                    add_3: \"f32[1, 7, 768]\" = torch.ops.aten.add.Tensor(clone_3, layer_norm_1);  clone_3 = layer_norm_1 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\normalization.py:229 in forward, code: return F.layer_norm(\n",
       "                    layer_norm_2: \"f32[1, 7, 768]\" = torch.ops.aten.layer_norm.default(add_3, [768], p_bert_encoder_layer_0_output_layernorm_weight, p_bert_encoder_layer_0_output_layernorm_bias, 1e-12);  add_3 = p_bert_encoder_layer_0_output_layernorm_weight = p_bert_encoder_layer_0_output_layernorm_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_6: \"f32[1, 7, 768]\" = torch.ops.aten.linear.default(layer_norm_2, p_bert_encoder_layer_1_attention_self_query_weight, p_bert_encoder_layer_1_attention_self_query_bias);  p_bert_encoder_layer_1_attention_self_query_weight = p_bert_encoder_layer_1_attention_self_query_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:363 in forward, code: self.query(hidden_states).view(bsz, -1, self.num_attention_heads, self.attention_head_size).transpose(1, 2)\n",
       "                    view_4: \"f32[1, 7, 12, 64]\" = torch.ops.aten.view.default(linear_6, [1, -1, 12, 64]);  linear_6 = None\n",
       "                    transpose_4: \"f32[1, 12, 7, 64]\" = torch.ops.aten.transpose.int(view_4, 1, 2);  view_4 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_7: \"f32[1, 7, 768]\" = torch.ops.aten.linear.default(layer_norm_2, p_bert_encoder_layer_1_attention_self_key_weight, p_bert_encoder_layer_1_attention_self_key_bias);  p_bert_encoder_layer_1_attention_self_key_weight = p_bert_encoder_layer_1_attention_self_key_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:388 in forward, code: .view(bsz, -1, self.num_attention_heads, self.attention_head_size)\n",
       "                    view_5: \"f32[1, 7, 12, 64]\" = torch.ops.aten.view.default(linear_7, [1, -1, 12, 64]);  linear_7 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:389 in forward, code: .transpose(1, 2)\n",
       "                    transpose_5: \"f32[1, 12, 7, 64]\" = torch.ops.aten.transpose.int(view_5, 1, 2);  view_5 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_8: \"f32[1, 7, 768]\" = torch.ops.aten.linear.default(layer_norm_2, p_bert_encoder_layer_1_attention_self_value_weight, p_bert_encoder_layer_1_attention_self_value_bias);  p_bert_encoder_layer_1_attention_self_value_weight = p_bert_encoder_layer_1_attention_self_value_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:393 in forward, code: .view(bsz, -1, self.num_attention_heads, self.attention_head_size)\n",
       "                    view_6: \"f32[1, 7, 12, 64]\" = torch.ops.aten.view.default(linear_8, [1, -1, 12, 64]);  linear_8 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:394 in forward, code: .transpose(1, 2)\n",
       "                    transpose_6: \"f32[1, 12, 7, 64]\" = torch.ops.aten.transpose.int(view_6, 1, 2);  view_6 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:413 in forward, code: attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
       "                    scaled_dot_product_attention_1: \"f32[1, 12, 7, 64]\" = torch.ops.aten.scaled_dot_product_attention.default(transpose_4, transpose_5, transpose_6, masked_fill);  transpose_4 = transpose_5 = transpose_6 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:422 in forward, code: attn_output = attn_output.transpose(1, 2)\n",
       "                    transpose_7: \"f32[1, 7, 12, 64]\" = torch.ops.aten.transpose.int(scaled_dot_product_attention_1, 1, 2);  scaled_dot_product_attention_1 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:423 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.all_head_size)\n",
       "                    view_7: \"f32[1, 7, 768]\" = torch.ops.aten.view.default(transpose_7, [1, 7, 768]);  transpose_7 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_9: \"f32[1, 7, 768]\" = torch.ops.aten.linear.default(view_7, p_bert_encoder_layer_1_attention_output_dense_weight, p_bert_encoder_layer_1_attention_output_dense_bias);  view_7 = p_bert_encoder_layer_1_attention_output_dense_weight = p_bert_encoder_layer_1_attention_output_dense_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\dropout.py:73 in forward, code: return F.dropout(input, self.p, self.training, self.inplace)\n",
       "                    clone_4: \"f32[1, 7, 768]\" = torch.ops.aten.clone.default(linear_9);  linear_9 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:438 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
       "                    add_4: \"f32[1, 7, 768]\" = torch.ops.aten.add.Tensor(clone_4, layer_norm_2);  clone_4 = layer_norm_2 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\normalization.py:229 in forward, code: return F.layer_norm(\n",
       "                    layer_norm_3: \"f32[1, 7, 768]\" = torch.ops.aten.layer_norm.default(add_4, [768], p_bert_encoder_layer_1_attention_output_layernorm_weight, p_bert_encoder_layer_1_attention_output_layernorm_bias, 1e-12);  add_4 = p_bert_encoder_layer_1_attention_output_layernorm_weight = p_bert_encoder_layer_1_attention_output_layernorm_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_10: \"f32[1, 7, 3072]\" = torch.ops.aten.linear.default(layer_norm_3, p_bert_encoder_layer_1_intermediate_dense_weight, p_bert_encoder_layer_1_intermediate_dense_bias);  p_bert_encoder_layer_1_intermediate_dense_weight = p_bert_encoder_layer_1_intermediate_dense_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\activations.py:85 in forward, code: return self.act(input)\n",
       "                    gelu_1: \"f32[1, 7, 3072]\" = torch.ops.aten.gelu.default(linear_10);  linear_10 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_11: \"f32[1, 7, 768]\" = torch.ops.aten.linear.default(gelu_1, p_bert_encoder_layer_1_output_dense_weight, p_bert_encoder_layer_1_output_dense_bias);  gelu_1 = p_bert_encoder_layer_1_output_dense_weight = p_bert_encoder_layer_1_output_dense_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\dropout.py:73 in forward, code: return F.dropout(input, self.p, self.training, self.inplace)\n",
       "                    clone_5: \"f32[1, 7, 768]\" = torch.ops.aten.clone.default(linear_11);  linear_11 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:527 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
       "                    add_5: \"f32[1, 7, 768]\" = torch.ops.aten.add.Tensor(clone_5, layer_norm_3);  clone_5 = layer_norm_3 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\normalization.py:229 in forward, code: return F.layer_norm(\n",
       "                    layer_norm_4: \"f32[1, 7, 768]\" = torch.ops.aten.layer_norm.default(add_5, [768], p_bert_encoder_layer_1_output_layernorm_weight, p_bert_encoder_layer_1_output_layernorm_bias, 1e-12);  add_5 = p_bert_encoder_layer_1_output_layernorm_weight = p_bert_encoder_layer_1_output_layernorm_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_12: \"f32[1, 7, 768]\" = torch.ops.aten.linear.default(layer_norm_4, p_bert_encoder_layer_2_attention_self_query_weight, p_bert_encoder_layer_2_attention_self_query_bias);  p_bert_encoder_layer_2_attention_self_query_weight = p_bert_encoder_layer_2_attention_self_query_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:363 in forward, code: self.query(hidden_states).view(bsz, -1, self.num_attention_heads, self.attention_head_size).transpose(1, 2)\n",
       "                    view_8: \"f32[1, 7, 12, 64]\" = torch.ops.aten.view.default(linear_12, [1, -1, 12, 64]);  linear_12 = None\n",
       "                    transpose_8: \"f32[1, 12, 7, 64]\" = torch.ops.aten.transpose.int(view_8, 1, 2);  view_8 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_13: \"f32[1, 7, 768]\" = torch.ops.aten.linear.default(layer_norm_4, p_bert_encoder_layer_2_attention_self_key_weight, p_bert_encoder_layer_2_attention_self_key_bias);  p_bert_encoder_layer_2_attention_self_key_weight = p_bert_encoder_layer_2_attention_self_key_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:388 in forward, code: .view(bsz, -1, self.num_attention_heads, self.attention_head_size)\n",
       "                    view_9: \"f32[1, 7, 12, 64]\" = torch.ops.aten.view.default(linear_13, [1, -1, 12, 64]);  linear_13 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:389 in forward, code: .transpose(1, 2)\n",
       "                    transpose_9: \"f32[1, 12, 7, 64]\" = torch.ops.aten.transpose.int(view_9, 1, 2);  view_9 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_14: \"f32[1, 7, 768]\" = torch.ops.aten.linear.default(layer_norm_4, p_bert_encoder_layer_2_attention_self_value_weight, p_bert_encoder_layer_2_attention_self_value_bias);  p_bert_encoder_layer_2_attention_self_value_weight = p_bert_encoder_layer_2_attention_self_value_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:393 in forward, code: .view(bsz, -1, self.num_attention_heads, self.attention_head_size)\n",
       "                    view_10: \"f32[1, 7, 12, 64]\" = torch.ops.aten.view.default(linear_14, [1, -1, 12, 64]);  linear_14 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:394 in forward, code: .transpose(1, 2)\n",
       "                    transpose_10: \"f32[1, 12, 7, 64]\" = torch.ops.aten.transpose.int(view_10, 1, 2);  view_10 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:413 in forward, code: attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
       "                    scaled_dot_product_attention_2: \"f32[1, 12, 7, 64]\" = torch.ops.aten.scaled_dot_product_attention.default(transpose_8, transpose_9, transpose_10, masked_fill);  transpose_8 = transpose_9 = transpose_10 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:422 in forward, code: attn_output = attn_output.transpose(1, 2)\n",
       "                    transpose_11: \"f32[1, 7, 12, 64]\" = torch.ops.aten.transpose.int(scaled_dot_product_attention_2, 1, 2);  scaled_dot_product_attention_2 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:423 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.all_head_size)\n",
       "                    view_11: \"f32[1, 7, 768]\" = torch.ops.aten.view.default(transpose_11, [1, 7, 768]);  transpose_11 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_15: \"f32[1, 7, 768]\" = torch.ops.aten.linear.default(view_11, p_bert_encoder_layer_2_attention_output_dense_weight, p_bert_encoder_layer_2_attention_output_dense_bias);  view_11 = p_bert_encoder_layer_2_attention_output_dense_weight = p_bert_encoder_layer_2_attention_output_dense_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\dropout.py:73 in forward, code: return F.dropout(input, self.p, self.training, self.inplace)\n",
       "                    clone_6: \"f32[1, 7, 768]\" = torch.ops.aten.clone.default(linear_15);  linear_15 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:438 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
       "                    add_6: \"f32[1, 7, 768]\" = torch.ops.aten.add.Tensor(clone_6, layer_norm_4);  clone_6 = layer_norm_4 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\normalization.py:229 in forward, code: return F.layer_norm(\n",
       "                    layer_norm_5: \"f32[1, 7, 768]\" = torch.ops.aten.layer_norm.default(add_6, [768], p_bert_encoder_layer_2_attention_output_layernorm_weight, p_bert_encoder_layer_2_attention_output_layernorm_bias, 1e-12);  add_6 = p_bert_encoder_layer_2_attention_output_layernorm_weight = p_bert_encoder_layer_2_attention_output_layernorm_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_16: \"f32[1, 7, 3072]\" = torch.ops.aten.linear.default(layer_norm_5, p_bert_encoder_layer_2_intermediate_dense_weight, p_bert_encoder_layer_2_intermediate_dense_bias);  p_bert_encoder_layer_2_intermediate_dense_weight = p_bert_encoder_layer_2_intermediate_dense_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\activations.py:85 in forward, code: return self.act(input)\n",
       "                    gelu_2: \"f32[1, 7, 3072]\" = torch.ops.aten.gelu.default(linear_16);  linear_16 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_17: \"f32[1, 7, 768]\" = torch.ops.aten.linear.default(gelu_2, p_bert_encoder_layer_2_output_dense_weight, p_bert_encoder_layer_2_output_dense_bias);  gelu_2 = p_bert_encoder_layer_2_output_dense_weight = p_bert_encoder_layer_2_output_dense_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\dropout.py:73 in forward, code: return F.dropout(input, self.p, self.training, self.inplace)\n",
       "                    clone_7: \"f32[1, 7, 768]\" = torch.ops.aten.clone.default(linear_17);  linear_17 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:527 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
       "                    add_7: \"f32[1, 7, 768]\" = torch.ops.aten.add.Tensor(clone_7, layer_norm_5);  clone_7 = layer_norm_5 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\normalization.py:229 in forward, code: return F.layer_norm(\n",
       "                    layer_norm_6: \"f32[1, 7, 768]\" = torch.ops.aten.layer_norm.default(add_7, [768], p_bert_encoder_layer_2_output_layernorm_weight, p_bert_encoder_layer_2_output_layernorm_bias, 1e-12);  add_7 = p_bert_encoder_layer_2_output_layernorm_weight = p_bert_encoder_layer_2_output_layernorm_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_18: \"f32[1, 7, 768]\" = torch.ops.aten.linear.default(layer_norm_6, p_bert_encoder_layer_3_attention_self_query_weight, p_bert_encoder_layer_3_attention_self_query_bias);  p_bert_encoder_layer_3_attention_self_query_weight = p_bert_encoder_layer_3_attention_self_query_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:363 in forward, code: self.query(hidden_states).view(bsz, -1, self.num_attention_heads, self.attention_head_size).transpose(1, 2)\n",
       "                    view_12: \"f32[1, 7, 12, 64]\" = torch.ops.aten.view.default(linear_18, [1, -1, 12, 64]);  linear_18 = None\n",
       "                    transpose_12: \"f32[1, 12, 7, 64]\" = torch.ops.aten.transpose.int(view_12, 1, 2);  view_12 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_19: \"f32[1, 7, 768]\" = torch.ops.aten.linear.default(layer_norm_6, p_bert_encoder_layer_3_attention_self_key_weight, p_bert_encoder_layer_3_attention_self_key_bias);  p_bert_encoder_layer_3_attention_self_key_weight = p_bert_encoder_layer_3_attention_self_key_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:388 in forward, code: .view(bsz, -1, self.num_attention_heads, self.attention_head_size)\n",
       "                    view_13: \"f32[1, 7, 12, 64]\" = torch.ops.aten.view.default(linear_19, [1, -1, 12, 64]);  linear_19 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:389 in forward, code: .transpose(1, 2)\n",
       "                    transpose_13: \"f32[1, 12, 7, 64]\" = torch.ops.aten.transpose.int(view_13, 1, 2);  view_13 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_20: \"f32[1, 7, 768]\" = torch.ops.aten.linear.default(layer_norm_6, p_bert_encoder_layer_3_attention_self_value_weight, p_bert_encoder_layer_3_attention_self_value_bias);  p_bert_encoder_layer_3_attention_self_value_weight = p_bert_encoder_layer_3_attention_self_value_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:393 in forward, code: .view(bsz, -1, self.num_attention_heads, self.attention_head_size)\n",
       "                    view_14: \"f32[1, 7, 12, 64]\" = torch.ops.aten.view.default(linear_20, [1, -1, 12, 64]);  linear_20 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:394 in forward, code: .transpose(1, 2)\n",
       "                    transpose_14: \"f32[1, 12, 7, 64]\" = torch.ops.aten.transpose.int(view_14, 1, 2);  view_14 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:413 in forward, code: attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
       "                    scaled_dot_product_attention_3: \"f32[1, 12, 7, 64]\" = torch.ops.aten.scaled_dot_product_attention.default(transpose_12, transpose_13, transpose_14, masked_fill);  transpose_12 = transpose_13 = transpose_14 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:422 in forward, code: attn_output = attn_output.transpose(1, 2)\n",
       "                    transpose_15: \"f32[1, 7, 12, 64]\" = torch.ops.aten.transpose.int(scaled_dot_product_attention_3, 1, 2);  scaled_dot_product_attention_3 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:423 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.all_head_size)\n",
       "                    view_15: \"f32[1, 7, 768]\" = torch.ops.aten.view.default(transpose_15, [1, 7, 768]);  transpose_15 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_21: \"f32[1, 7, 768]\" = torch.ops.aten.linear.default(view_15, p_bert_encoder_layer_3_attention_output_dense_weight, p_bert_encoder_layer_3_attention_output_dense_bias);  view_15 = p_bert_encoder_layer_3_attention_output_dense_weight = p_bert_encoder_layer_3_attention_output_dense_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\dropout.py:73 in forward, code: return F.dropout(input, self.p, self.training, self.inplace)\n",
       "                    clone_8: \"f32[1, 7, 768]\" = torch.ops.aten.clone.default(linear_21);  linear_21 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:438 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
       "                    add_8: \"f32[1, 7, 768]\" = torch.ops.aten.add.Tensor(clone_8, layer_norm_6);  clone_8 = layer_norm_6 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\normalization.py:229 in forward, code: return F.layer_norm(\n",
       "                    layer_norm_7: \"f32[1, 7, 768]\" = torch.ops.aten.layer_norm.default(add_8, [768], p_bert_encoder_layer_3_attention_output_layernorm_weight, p_bert_encoder_layer_3_attention_output_layernorm_bias, 1e-12);  add_8 = p_bert_encoder_layer_3_attention_output_layernorm_weight = p_bert_encoder_layer_3_attention_output_layernorm_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_22: \"f32[1, 7, 3072]\" = torch.ops.aten.linear.default(layer_norm_7, p_bert_encoder_layer_3_intermediate_dense_weight, p_bert_encoder_layer_3_intermediate_dense_bias);  p_bert_encoder_layer_3_intermediate_dense_weight = p_bert_encoder_layer_3_intermediate_dense_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\activations.py:85 in forward, code: return self.act(input)\n",
       "                    gelu_3: \"f32[1, 7, 3072]\" = torch.ops.aten.gelu.default(linear_22);  linear_22 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_23: \"f32[1, 7, 768]\" = torch.ops.aten.linear.default(gelu_3, p_bert_encoder_layer_3_output_dense_weight, p_bert_encoder_layer_3_output_dense_bias);  gelu_3 = p_bert_encoder_layer_3_output_dense_weight = p_bert_encoder_layer_3_output_dense_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\dropout.py:73 in forward, code: return F.dropout(input, self.p, self.training, self.inplace)\n",
       "                    clone_9: \"f32[1, 7, 768]\" = torch.ops.aten.clone.default(linear_23);  linear_23 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:527 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
       "                    add_9: \"f32[1, 7, 768]\" = torch.ops.aten.add.Tensor(clone_9, layer_norm_7);  clone_9 = layer_norm_7 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\normalization.py:229 in forward, code: return F.layer_norm(\n",
       "                    layer_norm_8: \"f32[1, 7, 768]\" = torch.ops.aten.layer_norm.default(add_9, [768], p_bert_encoder_layer_3_output_layernorm_weight, p_bert_encoder_layer_3_output_layernorm_bias, 1e-12);  add_9 = p_bert_encoder_layer_3_output_layernorm_weight = p_bert_encoder_layer_3_output_layernorm_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_24: \"f32[1, 7, 768]\" = torch.ops.aten.linear.default(layer_norm_8, p_bert_encoder_layer_4_attention_self_query_weight, p_bert_encoder_layer_4_attention_self_query_bias);  p_bert_encoder_layer_4_attention_self_query_weight = p_bert_encoder_layer_4_attention_self_query_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:363 in forward, code: self.query(hidden_states).view(bsz, -1, self.num_attention_heads, self.attention_head_size).transpose(1, 2)\n",
       "                    view_16: \"f32[1, 7, 12, 64]\" = torch.ops.aten.view.default(linear_24, [1, -1, 12, 64]);  linear_24 = None\n",
       "                    transpose_16: \"f32[1, 12, 7, 64]\" = torch.ops.aten.transpose.int(view_16, 1, 2);  view_16 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_25: \"f32[1, 7, 768]\" = torch.ops.aten.linear.default(layer_norm_8, p_bert_encoder_layer_4_attention_self_key_weight, p_bert_encoder_layer_4_attention_self_key_bias);  p_bert_encoder_layer_4_attention_self_key_weight = p_bert_encoder_layer_4_attention_self_key_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:388 in forward, code: .view(bsz, -1, self.num_attention_heads, self.attention_head_size)\n",
       "                    view_17: \"f32[1, 7, 12, 64]\" = torch.ops.aten.view.default(linear_25, [1, -1, 12, 64]);  linear_25 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:389 in forward, code: .transpose(1, 2)\n",
       "                    transpose_17: \"f32[1, 12, 7, 64]\" = torch.ops.aten.transpose.int(view_17, 1, 2);  view_17 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_26: \"f32[1, 7, 768]\" = torch.ops.aten.linear.default(layer_norm_8, p_bert_encoder_layer_4_attention_self_value_weight, p_bert_encoder_layer_4_attention_self_value_bias);  p_bert_encoder_layer_4_attention_self_value_weight = p_bert_encoder_layer_4_attention_self_value_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:393 in forward, code: .view(bsz, -1, self.num_attention_heads, self.attention_head_size)\n",
       "                    view_18: \"f32[1, 7, 12, 64]\" = torch.ops.aten.view.default(linear_26, [1, -1, 12, 64]);  linear_26 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:394 in forward, code: .transpose(1, 2)\n",
       "                    transpose_18: \"f32[1, 12, 7, 64]\" = torch.ops.aten.transpose.int(view_18, 1, 2);  view_18 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:413 in forward, code: attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
       "                    scaled_dot_product_attention_4: \"f32[1, 12, 7, 64]\" = torch.ops.aten.scaled_dot_product_attention.default(transpose_16, transpose_17, transpose_18, masked_fill);  transpose_16 = transpose_17 = transpose_18 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:422 in forward, code: attn_output = attn_output.transpose(1, 2)\n",
       "                    transpose_19: \"f32[1, 7, 12, 64]\" = torch.ops.aten.transpose.int(scaled_dot_product_attention_4, 1, 2);  scaled_dot_product_attention_4 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:423 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.all_head_size)\n",
       "                    view_19: \"f32[1, 7, 768]\" = torch.ops.aten.view.default(transpose_19, [1, 7, 768]);  transpose_19 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_27: \"f32[1, 7, 768]\" = torch.ops.aten.linear.default(view_19, p_bert_encoder_layer_4_attention_output_dense_weight, p_bert_encoder_layer_4_attention_output_dense_bias);  view_19 = p_bert_encoder_layer_4_attention_output_dense_weight = p_bert_encoder_layer_4_attention_output_dense_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\dropout.py:73 in forward, code: return F.dropout(input, self.p, self.training, self.inplace)\n",
       "                    clone_10: \"f32[1, 7, 768]\" = torch.ops.aten.clone.default(linear_27);  linear_27 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:438 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
       "                    add_10: \"f32[1, 7, 768]\" = torch.ops.aten.add.Tensor(clone_10, layer_norm_8);  clone_10 = layer_norm_8 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\normalization.py:229 in forward, code: return F.layer_norm(\n",
       "                    layer_norm_9: \"f32[1, 7, 768]\" = torch.ops.aten.layer_norm.default(add_10, [768], p_bert_encoder_layer_4_attention_output_layernorm_weight, p_bert_encoder_layer_4_attention_output_layernorm_bias, 1e-12);  add_10 = p_bert_encoder_layer_4_attention_output_layernorm_weight = p_bert_encoder_layer_4_attention_output_layernorm_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_28: \"f32[1, 7, 3072]\" = torch.ops.aten.linear.default(layer_norm_9, p_bert_encoder_layer_4_intermediate_dense_weight, p_bert_encoder_layer_4_intermediate_dense_bias);  p_bert_encoder_layer_4_intermediate_dense_weight = p_bert_encoder_layer_4_intermediate_dense_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\activations.py:85 in forward, code: return self.act(input)\n",
       "                    gelu_4: \"f32[1, 7, 3072]\" = torch.ops.aten.gelu.default(linear_28);  linear_28 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_29: \"f32[1, 7, 768]\" = torch.ops.aten.linear.default(gelu_4, p_bert_encoder_layer_4_output_dense_weight, p_bert_encoder_layer_4_output_dense_bias);  gelu_4 = p_bert_encoder_layer_4_output_dense_weight = p_bert_encoder_layer_4_output_dense_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\dropout.py:73 in forward, code: return F.dropout(input, self.p, self.training, self.inplace)\n",
       "                    clone_11: \"f32[1, 7, 768]\" = torch.ops.aten.clone.default(linear_29);  linear_29 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:527 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
       "                    add_11: \"f32[1, 7, 768]\" = torch.ops.aten.add.Tensor(clone_11, layer_norm_9);  clone_11 = layer_norm_9 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\normalization.py:229 in forward, code: return F.layer_norm(\n",
       "                    layer_norm_10: \"f32[1, 7, 768]\" = torch.ops.aten.layer_norm.default(add_11, [768], p_bert_encoder_layer_4_output_layernorm_weight, p_bert_encoder_layer_4_output_layernorm_bias, 1e-12);  add_11 = p_bert_encoder_layer_4_output_layernorm_weight = p_bert_encoder_layer_4_output_layernorm_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_30: \"f32[1, 7, 768]\" = torch.ops.aten.linear.default(layer_norm_10, p_bert_encoder_layer_5_attention_self_query_weight, p_bert_encoder_layer_5_attention_self_query_bias);  p_bert_encoder_layer_5_attention_self_query_weight = p_bert_encoder_layer_5_attention_self_query_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:363 in forward, code: self.query(hidden_states).view(bsz, -1, self.num_attention_heads, self.attention_head_size).transpose(1, 2)\n",
       "                    view_20: \"f32[1, 7, 12, 64]\" = torch.ops.aten.view.default(linear_30, [1, -1, 12, 64]);  linear_30 = None\n",
       "                    transpose_20: \"f32[1, 12, 7, 64]\" = torch.ops.aten.transpose.int(view_20, 1, 2);  view_20 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_31: \"f32[1, 7, 768]\" = torch.ops.aten.linear.default(layer_norm_10, p_bert_encoder_layer_5_attention_self_key_weight, p_bert_encoder_layer_5_attention_self_key_bias);  p_bert_encoder_layer_5_attention_self_key_weight = p_bert_encoder_layer_5_attention_self_key_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:388 in forward, code: .view(bsz, -1, self.num_attention_heads, self.attention_head_size)\n",
       "                    view_21: \"f32[1, 7, 12, 64]\" = torch.ops.aten.view.default(linear_31, [1, -1, 12, 64]);  linear_31 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:389 in forward, code: .transpose(1, 2)\n",
       "                    transpose_21: \"f32[1, 12, 7, 64]\" = torch.ops.aten.transpose.int(view_21, 1, 2);  view_21 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_32: \"f32[1, 7, 768]\" = torch.ops.aten.linear.default(layer_norm_10, p_bert_encoder_layer_5_attention_self_value_weight, p_bert_encoder_layer_5_attention_self_value_bias);  p_bert_encoder_layer_5_attention_self_value_weight = p_bert_encoder_layer_5_attention_self_value_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:393 in forward, code: .view(bsz, -1, self.num_attention_heads, self.attention_head_size)\n",
       "                    view_22: \"f32[1, 7, 12, 64]\" = torch.ops.aten.view.default(linear_32, [1, -1, 12, 64]);  linear_32 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:394 in forward, code: .transpose(1, 2)\n",
       "                    transpose_22: \"f32[1, 12, 7, 64]\" = torch.ops.aten.transpose.int(view_22, 1, 2);  view_22 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:413 in forward, code: attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
       "                    scaled_dot_product_attention_5: \"f32[1, 12, 7, 64]\" = torch.ops.aten.scaled_dot_product_attention.default(transpose_20, transpose_21, transpose_22, masked_fill);  transpose_20 = transpose_21 = transpose_22 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:422 in forward, code: attn_output = attn_output.transpose(1, 2)\n",
       "                    transpose_23: \"f32[1, 7, 12, 64]\" = torch.ops.aten.transpose.int(scaled_dot_product_attention_5, 1, 2);  scaled_dot_product_attention_5 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:423 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.all_head_size)\n",
       "                    view_23: \"f32[1, 7, 768]\" = torch.ops.aten.view.default(transpose_23, [1, 7, 768]);  transpose_23 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_33: \"f32[1, 7, 768]\" = torch.ops.aten.linear.default(view_23, p_bert_encoder_layer_5_attention_output_dense_weight, p_bert_encoder_layer_5_attention_output_dense_bias);  view_23 = p_bert_encoder_layer_5_attention_output_dense_weight = p_bert_encoder_layer_5_attention_output_dense_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\dropout.py:73 in forward, code: return F.dropout(input, self.p, self.training, self.inplace)\n",
       "                    clone_12: \"f32[1, 7, 768]\" = torch.ops.aten.clone.default(linear_33);  linear_33 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:438 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
       "                    add_12: \"f32[1, 7, 768]\" = torch.ops.aten.add.Tensor(clone_12, layer_norm_10);  clone_12 = layer_norm_10 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\normalization.py:229 in forward, code: return F.layer_norm(\n",
       "                    layer_norm_11: \"f32[1, 7, 768]\" = torch.ops.aten.layer_norm.default(add_12, [768], p_bert_encoder_layer_5_attention_output_layernorm_weight, p_bert_encoder_layer_5_attention_output_layernorm_bias, 1e-12);  add_12 = p_bert_encoder_layer_5_attention_output_layernorm_weight = p_bert_encoder_layer_5_attention_output_layernorm_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_34: \"f32[1, 7, 3072]\" = torch.ops.aten.linear.default(layer_norm_11, p_bert_encoder_layer_5_intermediate_dense_weight, p_bert_encoder_layer_5_intermediate_dense_bias);  p_bert_encoder_layer_5_intermediate_dense_weight = p_bert_encoder_layer_5_intermediate_dense_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\activations.py:85 in forward, code: return self.act(input)\n",
       "                    gelu_5: \"f32[1, 7, 3072]\" = torch.ops.aten.gelu.default(linear_34);  linear_34 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_35: \"f32[1, 7, 768]\" = torch.ops.aten.linear.default(gelu_5, p_bert_encoder_layer_5_output_dense_weight, p_bert_encoder_layer_5_output_dense_bias);  gelu_5 = p_bert_encoder_layer_5_output_dense_weight = p_bert_encoder_layer_5_output_dense_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\dropout.py:73 in forward, code: return F.dropout(input, self.p, self.training, self.inplace)\n",
       "                    clone_13: \"f32[1, 7, 768]\" = torch.ops.aten.clone.default(linear_35);  linear_35 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:527 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
       "                    add_13: \"f32[1, 7, 768]\" = torch.ops.aten.add.Tensor(clone_13, layer_norm_11);  clone_13 = layer_norm_11 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\normalization.py:229 in forward, code: return F.layer_norm(\n",
       "                    layer_norm_12: \"f32[1, 7, 768]\" = torch.ops.aten.layer_norm.default(add_13, [768], p_bert_encoder_layer_5_output_layernorm_weight, p_bert_encoder_layer_5_output_layernorm_bias, 1e-12);  add_13 = p_bert_encoder_layer_5_output_layernorm_weight = p_bert_encoder_layer_5_output_layernorm_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_36: \"f32[1, 7, 768]\" = torch.ops.aten.linear.default(layer_norm_12, p_bert_encoder_layer_6_attention_self_query_weight, p_bert_encoder_layer_6_attention_self_query_bias);  p_bert_encoder_layer_6_attention_self_query_weight = p_bert_encoder_layer_6_attention_self_query_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:363 in forward, code: self.query(hidden_states).view(bsz, -1, self.num_attention_heads, self.attention_head_size).transpose(1, 2)\n",
       "                    view_24: \"f32[1, 7, 12, 64]\" = torch.ops.aten.view.default(linear_36, [1, -1, 12, 64]);  linear_36 = None\n",
       "                    transpose_24: \"f32[1, 12, 7, 64]\" = torch.ops.aten.transpose.int(view_24, 1, 2);  view_24 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_37: \"f32[1, 7, 768]\" = torch.ops.aten.linear.default(layer_norm_12, p_bert_encoder_layer_6_attention_self_key_weight, p_bert_encoder_layer_6_attention_self_key_bias);  p_bert_encoder_layer_6_attention_self_key_weight = p_bert_encoder_layer_6_attention_self_key_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:388 in forward, code: .view(bsz, -1, self.num_attention_heads, self.attention_head_size)\n",
       "                    view_25: \"f32[1, 7, 12, 64]\" = torch.ops.aten.view.default(linear_37, [1, -1, 12, 64]);  linear_37 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:389 in forward, code: .transpose(1, 2)\n",
       "                    transpose_25: \"f32[1, 12, 7, 64]\" = torch.ops.aten.transpose.int(view_25, 1, 2);  view_25 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_38: \"f32[1, 7, 768]\" = torch.ops.aten.linear.default(layer_norm_12, p_bert_encoder_layer_6_attention_self_value_weight, p_bert_encoder_layer_6_attention_self_value_bias);  p_bert_encoder_layer_6_attention_self_value_weight = p_bert_encoder_layer_6_attention_self_value_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:393 in forward, code: .view(bsz, -1, self.num_attention_heads, self.attention_head_size)\n",
       "                    view_26: \"f32[1, 7, 12, 64]\" = torch.ops.aten.view.default(linear_38, [1, -1, 12, 64]);  linear_38 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:394 in forward, code: .transpose(1, 2)\n",
       "                    transpose_26: \"f32[1, 12, 7, 64]\" = torch.ops.aten.transpose.int(view_26, 1, 2);  view_26 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:413 in forward, code: attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
       "                    scaled_dot_product_attention_6: \"f32[1, 12, 7, 64]\" = torch.ops.aten.scaled_dot_product_attention.default(transpose_24, transpose_25, transpose_26, masked_fill);  transpose_24 = transpose_25 = transpose_26 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:422 in forward, code: attn_output = attn_output.transpose(1, 2)\n",
       "                    transpose_27: \"f32[1, 7, 12, 64]\" = torch.ops.aten.transpose.int(scaled_dot_product_attention_6, 1, 2);  scaled_dot_product_attention_6 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:423 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.all_head_size)\n",
       "                    view_27: \"f32[1, 7, 768]\" = torch.ops.aten.view.default(transpose_27, [1, 7, 768]);  transpose_27 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_39: \"f32[1, 7, 768]\" = torch.ops.aten.linear.default(view_27, p_bert_encoder_layer_6_attention_output_dense_weight, p_bert_encoder_layer_6_attention_output_dense_bias);  view_27 = p_bert_encoder_layer_6_attention_output_dense_weight = p_bert_encoder_layer_6_attention_output_dense_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\dropout.py:73 in forward, code: return F.dropout(input, self.p, self.training, self.inplace)\n",
       "                    clone_14: \"f32[1, 7, 768]\" = torch.ops.aten.clone.default(linear_39);  linear_39 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:438 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
       "                    add_14: \"f32[1, 7, 768]\" = torch.ops.aten.add.Tensor(clone_14, layer_norm_12);  clone_14 = layer_norm_12 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\normalization.py:229 in forward, code: return F.layer_norm(\n",
       "                    layer_norm_13: \"f32[1, 7, 768]\" = torch.ops.aten.layer_norm.default(add_14, [768], p_bert_encoder_layer_6_attention_output_layernorm_weight, p_bert_encoder_layer_6_attention_output_layernorm_bias, 1e-12);  add_14 = p_bert_encoder_layer_6_attention_output_layernorm_weight = p_bert_encoder_layer_6_attention_output_layernorm_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_40: \"f32[1, 7, 3072]\" = torch.ops.aten.linear.default(layer_norm_13, p_bert_encoder_layer_6_intermediate_dense_weight, p_bert_encoder_layer_6_intermediate_dense_bias);  p_bert_encoder_layer_6_intermediate_dense_weight = p_bert_encoder_layer_6_intermediate_dense_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\activations.py:85 in forward, code: return self.act(input)\n",
       "                    gelu_6: \"f32[1, 7, 3072]\" = torch.ops.aten.gelu.default(linear_40);  linear_40 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_41: \"f32[1, 7, 768]\" = torch.ops.aten.linear.default(gelu_6, p_bert_encoder_layer_6_output_dense_weight, p_bert_encoder_layer_6_output_dense_bias);  gelu_6 = p_bert_encoder_layer_6_output_dense_weight = p_bert_encoder_layer_6_output_dense_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\dropout.py:73 in forward, code: return F.dropout(input, self.p, self.training, self.inplace)\n",
       "                    clone_15: \"f32[1, 7, 768]\" = torch.ops.aten.clone.default(linear_41);  linear_41 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:527 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
       "                    add_15: \"f32[1, 7, 768]\" = torch.ops.aten.add.Tensor(clone_15, layer_norm_13);  clone_15 = layer_norm_13 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\normalization.py:229 in forward, code: return F.layer_norm(\n",
       "                    layer_norm_14: \"f32[1, 7, 768]\" = torch.ops.aten.layer_norm.default(add_15, [768], p_bert_encoder_layer_6_output_layernorm_weight, p_bert_encoder_layer_6_output_layernorm_bias, 1e-12);  add_15 = p_bert_encoder_layer_6_output_layernorm_weight = p_bert_encoder_layer_6_output_layernorm_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_42: \"f32[1, 7, 768]\" = torch.ops.aten.linear.default(layer_norm_14, p_bert_encoder_layer_7_attention_self_query_weight, p_bert_encoder_layer_7_attention_self_query_bias);  p_bert_encoder_layer_7_attention_self_query_weight = p_bert_encoder_layer_7_attention_self_query_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:363 in forward, code: self.query(hidden_states).view(bsz, -1, self.num_attention_heads, self.attention_head_size).transpose(1, 2)\n",
       "                    view_28: \"f32[1, 7, 12, 64]\" = torch.ops.aten.view.default(linear_42, [1, -1, 12, 64]);  linear_42 = None\n",
       "                    transpose_28: \"f32[1, 12, 7, 64]\" = torch.ops.aten.transpose.int(view_28, 1, 2);  view_28 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_43: \"f32[1, 7, 768]\" = torch.ops.aten.linear.default(layer_norm_14, p_bert_encoder_layer_7_attention_self_key_weight, p_bert_encoder_layer_7_attention_self_key_bias);  p_bert_encoder_layer_7_attention_self_key_weight = p_bert_encoder_layer_7_attention_self_key_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:388 in forward, code: .view(bsz, -1, self.num_attention_heads, self.attention_head_size)\n",
       "                    view_29: \"f32[1, 7, 12, 64]\" = torch.ops.aten.view.default(linear_43, [1, -1, 12, 64]);  linear_43 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:389 in forward, code: .transpose(1, 2)\n",
       "                    transpose_29: \"f32[1, 12, 7, 64]\" = torch.ops.aten.transpose.int(view_29, 1, 2);  view_29 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_44: \"f32[1, 7, 768]\" = torch.ops.aten.linear.default(layer_norm_14, p_bert_encoder_layer_7_attention_self_value_weight, p_bert_encoder_layer_7_attention_self_value_bias);  p_bert_encoder_layer_7_attention_self_value_weight = p_bert_encoder_layer_7_attention_self_value_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:393 in forward, code: .view(bsz, -1, self.num_attention_heads, self.attention_head_size)\n",
       "                    view_30: \"f32[1, 7, 12, 64]\" = torch.ops.aten.view.default(linear_44, [1, -1, 12, 64]);  linear_44 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:394 in forward, code: .transpose(1, 2)\n",
       "                    transpose_30: \"f32[1, 12, 7, 64]\" = torch.ops.aten.transpose.int(view_30, 1, 2);  view_30 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:413 in forward, code: attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
       "                    scaled_dot_product_attention_7: \"f32[1, 12, 7, 64]\" = torch.ops.aten.scaled_dot_product_attention.default(transpose_28, transpose_29, transpose_30, masked_fill);  transpose_28 = transpose_29 = transpose_30 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:422 in forward, code: attn_output = attn_output.transpose(1, 2)\n",
       "                    transpose_31: \"f32[1, 7, 12, 64]\" = torch.ops.aten.transpose.int(scaled_dot_product_attention_7, 1, 2);  scaled_dot_product_attention_7 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:423 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.all_head_size)\n",
       "                    view_31: \"f32[1, 7, 768]\" = torch.ops.aten.view.default(transpose_31, [1, 7, 768]);  transpose_31 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_45: \"f32[1, 7, 768]\" = torch.ops.aten.linear.default(view_31, p_bert_encoder_layer_7_attention_output_dense_weight, p_bert_encoder_layer_7_attention_output_dense_bias);  view_31 = p_bert_encoder_layer_7_attention_output_dense_weight = p_bert_encoder_layer_7_attention_output_dense_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\dropout.py:73 in forward, code: return F.dropout(input, self.p, self.training, self.inplace)\n",
       "                    clone_16: \"f32[1, 7, 768]\" = torch.ops.aten.clone.default(linear_45);  linear_45 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:438 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
       "                    add_16: \"f32[1, 7, 768]\" = torch.ops.aten.add.Tensor(clone_16, layer_norm_14);  clone_16 = layer_norm_14 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\normalization.py:229 in forward, code: return F.layer_norm(\n",
       "                    layer_norm_15: \"f32[1, 7, 768]\" = torch.ops.aten.layer_norm.default(add_16, [768], p_bert_encoder_layer_7_attention_output_layernorm_weight, p_bert_encoder_layer_7_attention_output_layernorm_bias, 1e-12);  add_16 = p_bert_encoder_layer_7_attention_output_layernorm_weight = p_bert_encoder_layer_7_attention_output_layernorm_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_46: \"f32[1, 7, 3072]\" = torch.ops.aten.linear.default(layer_norm_15, p_bert_encoder_layer_7_intermediate_dense_weight, p_bert_encoder_layer_7_intermediate_dense_bias);  p_bert_encoder_layer_7_intermediate_dense_weight = p_bert_encoder_layer_7_intermediate_dense_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\activations.py:85 in forward, code: return self.act(input)\n",
       "                    gelu_7: \"f32[1, 7, 3072]\" = torch.ops.aten.gelu.default(linear_46);  linear_46 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_47: \"f32[1, 7, 768]\" = torch.ops.aten.linear.default(gelu_7, p_bert_encoder_layer_7_output_dense_weight, p_bert_encoder_layer_7_output_dense_bias);  gelu_7 = p_bert_encoder_layer_7_output_dense_weight = p_bert_encoder_layer_7_output_dense_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\dropout.py:73 in forward, code: return F.dropout(input, self.p, self.training, self.inplace)\n",
       "                    clone_17: \"f32[1, 7, 768]\" = torch.ops.aten.clone.default(linear_47);  linear_47 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:527 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
       "                    add_17: \"f32[1, 7, 768]\" = torch.ops.aten.add.Tensor(clone_17, layer_norm_15);  clone_17 = layer_norm_15 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\normalization.py:229 in forward, code: return F.layer_norm(\n",
       "                    layer_norm_16: \"f32[1, 7, 768]\" = torch.ops.aten.layer_norm.default(add_17, [768], p_bert_encoder_layer_7_output_layernorm_weight, p_bert_encoder_layer_7_output_layernorm_bias, 1e-12);  add_17 = p_bert_encoder_layer_7_output_layernorm_weight = p_bert_encoder_layer_7_output_layernorm_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_48: \"f32[1, 7, 768]\" = torch.ops.aten.linear.default(layer_norm_16, p_bert_encoder_layer_8_attention_self_query_weight, p_bert_encoder_layer_8_attention_self_query_bias);  p_bert_encoder_layer_8_attention_self_query_weight = p_bert_encoder_layer_8_attention_self_query_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:363 in forward, code: self.query(hidden_states).view(bsz, -1, self.num_attention_heads, self.attention_head_size).transpose(1, 2)\n",
       "                    view_32: \"f32[1, 7, 12, 64]\" = torch.ops.aten.view.default(linear_48, [1, -1, 12, 64]);  linear_48 = None\n",
       "                    transpose_32: \"f32[1, 12, 7, 64]\" = torch.ops.aten.transpose.int(view_32, 1, 2);  view_32 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_49: \"f32[1, 7, 768]\" = torch.ops.aten.linear.default(layer_norm_16, p_bert_encoder_layer_8_attention_self_key_weight, p_bert_encoder_layer_8_attention_self_key_bias);  p_bert_encoder_layer_8_attention_self_key_weight = p_bert_encoder_layer_8_attention_self_key_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:388 in forward, code: .view(bsz, -1, self.num_attention_heads, self.attention_head_size)\n",
       "                    view_33: \"f32[1, 7, 12, 64]\" = torch.ops.aten.view.default(linear_49, [1, -1, 12, 64]);  linear_49 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:389 in forward, code: .transpose(1, 2)\n",
       "                    transpose_33: \"f32[1, 12, 7, 64]\" = torch.ops.aten.transpose.int(view_33, 1, 2);  view_33 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_50: \"f32[1, 7, 768]\" = torch.ops.aten.linear.default(layer_norm_16, p_bert_encoder_layer_8_attention_self_value_weight, p_bert_encoder_layer_8_attention_self_value_bias);  p_bert_encoder_layer_8_attention_self_value_weight = p_bert_encoder_layer_8_attention_self_value_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:393 in forward, code: .view(bsz, -1, self.num_attention_heads, self.attention_head_size)\n",
       "                    view_34: \"f32[1, 7, 12, 64]\" = torch.ops.aten.view.default(linear_50, [1, -1, 12, 64]);  linear_50 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:394 in forward, code: .transpose(1, 2)\n",
       "                    transpose_34: \"f32[1, 12, 7, 64]\" = torch.ops.aten.transpose.int(view_34, 1, 2);  view_34 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:413 in forward, code: attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
       "                    scaled_dot_product_attention_8: \"f32[1, 12, 7, 64]\" = torch.ops.aten.scaled_dot_product_attention.default(transpose_32, transpose_33, transpose_34, masked_fill);  transpose_32 = transpose_33 = transpose_34 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:422 in forward, code: attn_output = attn_output.transpose(1, 2)\n",
       "                    transpose_35: \"f32[1, 7, 12, 64]\" = torch.ops.aten.transpose.int(scaled_dot_product_attention_8, 1, 2);  scaled_dot_product_attention_8 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:423 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.all_head_size)\n",
       "                    view_35: \"f32[1, 7, 768]\" = torch.ops.aten.view.default(transpose_35, [1, 7, 768]);  transpose_35 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_51: \"f32[1, 7, 768]\" = torch.ops.aten.linear.default(view_35, p_bert_encoder_layer_8_attention_output_dense_weight, p_bert_encoder_layer_8_attention_output_dense_bias);  view_35 = p_bert_encoder_layer_8_attention_output_dense_weight = p_bert_encoder_layer_8_attention_output_dense_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\dropout.py:73 in forward, code: return F.dropout(input, self.p, self.training, self.inplace)\n",
       "                    clone_18: \"f32[1, 7, 768]\" = torch.ops.aten.clone.default(linear_51);  linear_51 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:438 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
       "                    add_18: \"f32[1, 7, 768]\" = torch.ops.aten.add.Tensor(clone_18, layer_norm_16);  clone_18 = layer_norm_16 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\normalization.py:229 in forward, code: return F.layer_norm(\n",
       "                    layer_norm_17: \"f32[1, 7, 768]\" = torch.ops.aten.layer_norm.default(add_18, [768], p_bert_encoder_layer_8_attention_output_layernorm_weight, p_bert_encoder_layer_8_attention_output_layernorm_bias, 1e-12);  add_18 = p_bert_encoder_layer_8_attention_output_layernorm_weight = p_bert_encoder_layer_8_attention_output_layernorm_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_52: \"f32[1, 7, 3072]\" = torch.ops.aten.linear.default(layer_norm_17, p_bert_encoder_layer_8_intermediate_dense_weight, p_bert_encoder_layer_8_intermediate_dense_bias);  p_bert_encoder_layer_8_intermediate_dense_weight = p_bert_encoder_layer_8_intermediate_dense_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\activations.py:85 in forward, code: return self.act(input)\n",
       "                    gelu_8: \"f32[1, 7, 3072]\" = torch.ops.aten.gelu.default(linear_52);  linear_52 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_53: \"f32[1, 7, 768]\" = torch.ops.aten.linear.default(gelu_8, p_bert_encoder_layer_8_output_dense_weight, p_bert_encoder_layer_8_output_dense_bias);  gelu_8 = p_bert_encoder_layer_8_output_dense_weight = p_bert_encoder_layer_8_output_dense_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\dropout.py:73 in forward, code: return F.dropout(input, self.p, self.training, self.inplace)\n",
       "                    clone_19: \"f32[1, 7, 768]\" = torch.ops.aten.clone.default(linear_53);  linear_53 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:527 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
       "                    add_19: \"f32[1, 7, 768]\" = torch.ops.aten.add.Tensor(clone_19, layer_norm_17);  clone_19 = layer_norm_17 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\normalization.py:229 in forward, code: return F.layer_norm(\n",
       "                    layer_norm_18: \"f32[1, 7, 768]\" = torch.ops.aten.layer_norm.default(add_19, [768], p_bert_encoder_layer_8_output_layernorm_weight, p_bert_encoder_layer_8_output_layernorm_bias, 1e-12);  add_19 = p_bert_encoder_layer_8_output_layernorm_weight = p_bert_encoder_layer_8_output_layernorm_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_54: \"f32[1, 7, 768]\" = torch.ops.aten.linear.default(layer_norm_18, p_bert_encoder_layer_9_attention_self_query_weight, p_bert_encoder_layer_9_attention_self_query_bias);  p_bert_encoder_layer_9_attention_self_query_weight = p_bert_encoder_layer_9_attention_self_query_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:363 in forward, code: self.query(hidden_states).view(bsz, -1, self.num_attention_heads, self.attention_head_size).transpose(1, 2)\n",
       "                    view_36: \"f32[1, 7, 12, 64]\" = torch.ops.aten.view.default(linear_54, [1, -1, 12, 64]);  linear_54 = None\n",
       "                    transpose_36: \"f32[1, 12, 7, 64]\" = torch.ops.aten.transpose.int(view_36, 1, 2);  view_36 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_55: \"f32[1, 7, 768]\" = torch.ops.aten.linear.default(layer_norm_18, p_bert_encoder_layer_9_attention_self_key_weight, p_bert_encoder_layer_9_attention_self_key_bias);  p_bert_encoder_layer_9_attention_self_key_weight = p_bert_encoder_layer_9_attention_self_key_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:388 in forward, code: .view(bsz, -1, self.num_attention_heads, self.attention_head_size)\n",
       "                    view_37: \"f32[1, 7, 12, 64]\" = torch.ops.aten.view.default(linear_55, [1, -1, 12, 64]);  linear_55 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:389 in forward, code: .transpose(1, 2)\n",
       "                    transpose_37: \"f32[1, 12, 7, 64]\" = torch.ops.aten.transpose.int(view_37, 1, 2);  view_37 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_56: \"f32[1, 7, 768]\" = torch.ops.aten.linear.default(layer_norm_18, p_bert_encoder_layer_9_attention_self_value_weight, p_bert_encoder_layer_9_attention_self_value_bias);  p_bert_encoder_layer_9_attention_self_value_weight = p_bert_encoder_layer_9_attention_self_value_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:393 in forward, code: .view(bsz, -1, self.num_attention_heads, self.attention_head_size)\n",
       "                    view_38: \"f32[1, 7, 12, 64]\" = torch.ops.aten.view.default(linear_56, [1, -1, 12, 64]);  linear_56 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:394 in forward, code: .transpose(1, 2)\n",
       "                    transpose_38: \"f32[1, 12, 7, 64]\" = torch.ops.aten.transpose.int(view_38, 1, 2);  view_38 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:413 in forward, code: attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
       "                    scaled_dot_product_attention_9: \"f32[1, 12, 7, 64]\" = torch.ops.aten.scaled_dot_product_attention.default(transpose_36, transpose_37, transpose_38, masked_fill);  transpose_36 = transpose_37 = transpose_38 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:422 in forward, code: attn_output = attn_output.transpose(1, 2)\n",
       "                    transpose_39: \"f32[1, 7, 12, 64]\" = torch.ops.aten.transpose.int(scaled_dot_product_attention_9, 1, 2);  scaled_dot_product_attention_9 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:423 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.all_head_size)\n",
       "                    view_39: \"f32[1, 7, 768]\" = torch.ops.aten.view.default(transpose_39, [1, 7, 768]);  transpose_39 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_57: \"f32[1, 7, 768]\" = torch.ops.aten.linear.default(view_39, p_bert_encoder_layer_9_attention_output_dense_weight, p_bert_encoder_layer_9_attention_output_dense_bias);  view_39 = p_bert_encoder_layer_9_attention_output_dense_weight = p_bert_encoder_layer_9_attention_output_dense_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\dropout.py:73 in forward, code: return F.dropout(input, self.p, self.training, self.inplace)\n",
       "                    clone_20: \"f32[1, 7, 768]\" = torch.ops.aten.clone.default(linear_57);  linear_57 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:438 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
       "                    add_20: \"f32[1, 7, 768]\" = torch.ops.aten.add.Tensor(clone_20, layer_norm_18);  clone_20 = layer_norm_18 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\normalization.py:229 in forward, code: return F.layer_norm(\n",
       "                    layer_norm_19: \"f32[1, 7, 768]\" = torch.ops.aten.layer_norm.default(add_20, [768], p_bert_encoder_layer_9_attention_output_layernorm_weight, p_bert_encoder_layer_9_attention_output_layernorm_bias, 1e-12);  add_20 = p_bert_encoder_layer_9_attention_output_layernorm_weight = p_bert_encoder_layer_9_attention_output_layernorm_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_58: \"f32[1, 7, 3072]\" = torch.ops.aten.linear.default(layer_norm_19, p_bert_encoder_layer_9_intermediate_dense_weight, p_bert_encoder_layer_9_intermediate_dense_bias);  p_bert_encoder_layer_9_intermediate_dense_weight = p_bert_encoder_layer_9_intermediate_dense_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\activations.py:85 in forward, code: return self.act(input)\n",
       "                    gelu_9: \"f32[1, 7, 3072]\" = torch.ops.aten.gelu.default(linear_58);  linear_58 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_59: \"f32[1, 7, 768]\" = torch.ops.aten.linear.default(gelu_9, p_bert_encoder_layer_9_output_dense_weight, p_bert_encoder_layer_9_output_dense_bias);  gelu_9 = p_bert_encoder_layer_9_output_dense_weight = p_bert_encoder_layer_9_output_dense_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\dropout.py:73 in forward, code: return F.dropout(input, self.p, self.training, self.inplace)\n",
       "                    clone_21: \"f32[1, 7, 768]\" = torch.ops.aten.clone.default(linear_59);  linear_59 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:527 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
       "                    add_21: \"f32[1, 7, 768]\" = torch.ops.aten.add.Tensor(clone_21, layer_norm_19);  clone_21 = layer_norm_19 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\normalization.py:229 in forward, code: return F.layer_norm(\n",
       "                    layer_norm_20: \"f32[1, 7, 768]\" = torch.ops.aten.layer_norm.default(add_21, [768], p_bert_encoder_layer_9_output_layernorm_weight, p_bert_encoder_layer_9_output_layernorm_bias, 1e-12);  add_21 = p_bert_encoder_layer_9_output_layernorm_weight = p_bert_encoder_layer_9_output_layernorm_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_60: \"f32[1, 7, 768]\" = torch.ops.aten.linear.default(layer_norm_20, p_bert_encoder_layer_10_attention_self_query_weight, p_bert_encoder_layer_10_attention_self_query_bias);  p_bert_encoder_layer_10_attention_self_query_weight = p_bert_encoder_layer_10_attention_self_query_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:363 in forward, code: self.query(hidden_states).view(bsz, -1, self.num_attention_heads, self.attention_head_size).transpose(1, 2)\n",
       "                    view_40: \"f32[1, 7, 12, 64]\" = torch.ops.aten.view.default(linear_60, [1, -1, 12, 64]);  linear_60 = None\n",
       "                    transpose_40: \"f32[1, 12, 7, 64]\" = torch.ops.aten.transpose.int(view_40, 1, 2);  view_40 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_61: \"f32[1, 7, 768]\" = torch.ops.aten.linear.default(layer_norm_20, p_bert_encoder_layer_10_attention_self_key_weight, p_bert_encoder_layer_10_attention_self_key_bias);  p_bert_encoder_layer_10_attention_self_key_weight = p_bert_encoder_layer_10_attention_self_key_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:388 in forward, code: .view(bsz, -1, self.num_attention_heads, self.attention_head_size)\n",
       "                    view_41: \"f32[1, 7, 12, 64]\" = torch.ops.aten.view.default(linear_61, [1, -1, 12, 64]);  linear_61 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:389 in forward, code: .transpose(1, 2)\n",
       "                    transpose_41: \"f32[1, 12, 7, 64]\" = torch.ops.aten.transpose.int(view_41, 1, 2);  view_41 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_62: \"f32[1, 7, 768]\" = torch.ops.aten.linear.default(layer_norm_20, p_bert_encoder_layer_10_attention_self_value_weight, p_bert_encoder_layer_10_attention_self_value_bias);  p_bert_encoder_layer_10_attention_self_value_weight = p_bert_encoder_layer_10_attention_self_value_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:393 in forward, code: .view(bsz, -1, self.num_attention_heads, self.attention_head_size)\n",
       "                    view_42: \"f32[1, 7, 12, 64]\" = torch.ops.aten.view.default(linear_62, [1, -1, 12, 64]);  linear_62 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:394 in forward, code: .transpose(1, 2)\n",
       "                    transpose_42: \"f32[1, 12, 7, 64]\" = torch.ops.aten.transpose.int(view_42, 1, 2);  view_42 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:413 in forward, code: attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
       "                    scaled_dot_product_attention_10: \"f32[1, 12, 7, 64]\" = torch.ops.aten.scaled_dot_product_attention.default(transpose_40, transpose_41, transpose_42, masked_fill);  transpose_40 = transpose_41 = transpose_42 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:422 in forward, code: attn_output = attn_output.transpose(1, 2)\n",
       "                    transpose_43: \"f32[1, 7, 12, 64]\" = torch.ops.aten.transpose.int(scaled_dot_product_attention_10, 1, 2);  scaled_dot_product_attention_10 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:423 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.all_head_size)\n",
       "                    view_43: \"f32[1, 7, 768]\" = torch.ops.aten.view.default(transpose_43, [1, 7, 768]);  transpose_43 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_63: \"f32[1, 7, 768]\" = torch.ops.aten.linear.default(view_43, p_bert_encoder_layer_10_attention_output_dense_weight, p_bert_encoder_layer_10_attention_output_dense_bias);  view_43 = p_bert_encoder_layer_10_attention_output_dense_weight = p_bert_encoder_layer_10_attention_output_dense_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\dropout.py:73 in forward, code: return F.dropout(input, self.p, self.training, self.inplace)\n",
       "                    clone_22: \"f32[1, 7, 768]\" = torch.ops.aten.clone.default(linear_63);  linear_63 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:438 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
       "                    add_22: \"f32[1, 7, 768]\" = torch.ops.aten.add.Tensor(clone_22, layer_norm_20);  clone_22 = layer_norm_20 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\normalization.py:229 in forward, code: return F.layer_norm(\n",
       "                    layer_norm_21: \"f32[1, 7, 768]\" = torch.ops.aten.layer_norm.default(add_22, [768], p_bert_encoder_layer_10_attention_output_layernorm_weight, p_bert_encoder_layer_10_attention_output_layernorm_bias, 1e-12);  add_22 = p_bert_encoder_layer_10_attention_output_layernorm_weight = p_bert_encoder_layer_10_attention_output_layernorm_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_64: \"f32[1, 7, 3072]\" = torch.ops.aten.linear.default(layer_norm_21, p_bert_encoder_layer_10_intermediate_dense_weight, p_bert_encoder_layer_10_intermediate_dense_bias);  p_bert_encoder_layer_10_intermediate_dense_weight = p_bert_encoder_layer_10_intermediate_dense_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\activations.py:85 in forward, code: return self.act(input)\n",
       "                    gelu_10: \"f32[1, 7, 3072]\" = torch.ops.aten.gelu.default(linear_64);  linear_64 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_65: \"f32[1, 7, 768]\" = torch.ops.aten.linear.default(gelu_10, p_bert_encoder_layer_10_output_dense_weight, p_bert_encoder_layer_10_output_dense_bias);  gelu_10 = p_bert_encoder_layer_10_output_dense_weight = p_bert_encoder_layer_10_output_dense_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\dropout.py:73 in forward, code: return F.dropout(input, self.p, self.training, self.inplace)\n",
       "                    clone_23: \"f32[1, 7, 768]\" = torch.ops.aten.clone.default(linear_65);  linear_65 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:527 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
       "                    add_23: \"f32[1, 7, 768]\" = torch.ops.aten.add.Tensor(clone_23, layer_norm_21);  clone_23 = layer_norm_21 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\normalization.py:229 in forward, code: return F.layer_norm(\n",
       "                    layer_norm_22: \"f32[1, 7, 768]\" = torch.ops.aten.layer_norm.default(add_23, [768], p_bert_encoder_layer_10_output_layernorm_weight, p_bert_encoder_layer_10_output_layernorm_bias, 1e-12);  add_23 = p_bert_encoder_layer_10_output_layernorm_weight = p_bert_encoder_layer_10_output_layernorm_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_66: \"f32[1, 7, 768]\" = torch.ops.aten.linear.default(layer_norm_22, p_bert_encoder_layer_11_attention_self_query_weight, p_bert_encoder_layer_11_attention_self_query_bias);  p_bert_encoder_layer_11_attention_self_query_weight = p_bert_encoder_layer_11_attention_self_query_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:363 in forward, code: self.query(hidden_states).view(bsz, -1, self.num_attention_heads, self.attention_head_size).transpose(1, 2)\n",
       "                    view_44: \"f32[1, 7, 12, 64]\" = torch.ops.aten.view.default(linear_66, [1, -1, 12, 64]);  linear_66 = None\n",
       "                    transpose_44: \"f32[1, 12, 7, 64]\" = torch.ops.aten.transpose.int(view_44, 1, 2);  view_44 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_67: \"f32[1, 7, 768]\" = torch.ops.aten.linear.default(layer_norm_22, p_bert_encoder_layer_11_attention_self_key_weight, p_bert_encoder_layer_11_attention_self_key_bias);  p_bert_encoder_layer_11_attention_self_key_weight = p_bert_encoder_layer_11_attention_self_key_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:388 in forward, code: .view(bsz, -1, self.num_attention_heads, self.attention_head_size)\n",
       "                    view_45: \"f32[1, 7, 12, 64]\" = torch.ops.aten.view.default(linear_67, [1, -1, 12, 64]);  linear_67 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:389 in forward, code: .transpose(1, 2)\n",
       "                    transpose_45: \"f32[1, 12, 7, 64]\" = torch.ops.aten.transpose.int(view_45, 1, 2);  view_45 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_68: \"f32[1, 7, 768]\" = torch.ops.aten.linear.default(layer_norm_22, p_bert_encoder_layer_11_attention_self_value_weight, p_bert_encoder_layer_11_attention_self_value_bias);  p_bert_encoder_layer_11_attention_self_value_weight = p_bert_encoder_layer_11_attention_self_value_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:393 in forward, code: .view(bsz, -1, self.num_attention_heads, self.attention_head_size)\n",
       "                    view_46: \"f32[1, 7, 12, 64]\" = torch.ops.aten.view.default(linear_68, [1, -1, 12, 64]);  linear_68 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:394 in forward, code: .transpose(1, 2)\n",
       "                    transpose_46: \"f32[1, 12, 7, 64]\" = torch.ops.aten.transpose.int(view_46, 1, 2);  view_46 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:413 in forward, code: attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
       "                    scaled_dot_product_attention_11: \"f32[1, 12, 7, 64]\" = torch.ops.aten.scaled_dot_product_attention.default(transpose_44, transpose_45, transpose_46, masked_fill);  transpose_44 = transpose_45 = transpose_46 = masked_fill = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:422 in forward, code: attn_output = attn_output.transpose(1, 2)\n",
       "                    transpose_47: \"f32[1, 7, 12, 64]\" = torch.ops.aten.transpose.int(scaled_dot_product_attention_11, 1, 2);  scaled_dot_product_attention_11 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:423 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.all_head_size)\n",
       "                    view_47: \"f32[1, 7, 768]\" = torch.ops.aten.view.default(transpose_47, [1, 7, 768]);  transpose_47 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_69: \"f32[1, 7, 768]\" = torch.ops.aten.linear.default(view_47, p_bert_encoder_layer_11_attention_output_dense_weight, p_bert_encoder_layer_11_attention_output_dense_bias);  view_47 = p_bert_encoder_layer_11_attention_output_dense_weight = p_bert_encoder_layer_11_attention_output_dense_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\dropout.py:73 in forward, code: return F.dropout(input, self.p, self.training, self.inplace)\n",
       "                    clone_24: \"f32[1, 7, 768]\" = torch.ops.aten.clone.default(linear_69);  linear_69 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:438 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
       "                    add_24: \"f32[1, 7, 768]\" = torch.ops.aten.add.Tensor(clone_24, layer_norm_22);  clone_24 = layer_norm_22 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\normalization.py:229 in forward, code: return F.layer_norm(\n",
       "                    layer_norm_23: \"f32[1, 7, 768]\" = torch.ops.aten.layer_norm.default(add_24, [768], p_bert_encoder_layer_11_attention_output_layernorm_weight, p_bert_encoder_layer_11_attention_output_layernorm_bias, 1e-12);  add_24 = p_bert_encoder_layer_11_attention_output_layernorm_weight = p_bert_encoder_layer_11_attention_output_layernorm_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_70: \"f32[1, 7, 3072]\" = torch.ops.aten.linear.default(layer_norm_23, p_bert_encoder_layer_11_intermediate_dense_weight, p_bert_encoder_layer_11_intermediate_dense_bias);  p_bert_encoder_layer_11_intermediate_dense_weight = p_bert_encoder_layer_11_intermediate_dense_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\activations.py:85 in forward, code: return self.act(input)\n",
       "                    gelu_11: \"f32[1, 7, 3072]\" = torch.ops.aten.gelu.default(linear_70);  linear_70 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_71: \"f32[1, 7, 768]\" = torch.ops.aten.linear.default(gelu_11, p_bert_encoder_layer_11_output_dense_weight, p_bert_encoder_layer_11_output_dense_bias);  gelu_11 = p_bert_encoder_layer_11_output_dense_weight = p_bert_encoder_layer_11_output_dense_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\dropout.py:73 in forward, code: return F.dropout(input, self.p, self.training, self.inplace)\n",
       "                    clone_25: \"f32[1, 7, 768]\" = torch.ops.aten.clone.default(linear_71);  linear_71 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:527 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
       "                    add_25: \"f32[1, 7, 768]\" = torch.ops.aten.add.Tensor(clone_25, layer_norm_23);  clone_25 = layer_norm_23 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\normalization.py:229 in forward, code: return F.layer_norm(\n",
       "                    layer_norm_24: \"f32[1, 7, 768]\" = torch.ops.aten.layer_norm.default(add_25, [768], p_bert_encoder_layer_11_output_layernorm_weight, p_bert_encoder_layer_11_output_layernorm_bias, 1e-12);  add_25 = p_bert_encoder_layer_11_output_layernorm_weight = p_bert_encoder_layer_11_output_layernorm_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:700 in forward, code: first_token_tensor = hidden_states[:, 0]\n",
       "                    select: \"f32[1, 768]\" = torch.ops.aten.select.int(layer_norm_24, 1, 0);  layer_norm_24 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_72: \"f32[1, 768]\" = torch.ops.aten.linear.default(select, p_bert_pooler_dense_weight, p_bert_pooler_dense_bias);  select = p_bert_pooler_dense_weight = p_bert_pooler_dense_bias = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:430 in forward, code: return torch.tanh(input)\n",
       "                    tanh: \"f32[1, 768]\" = torch.ops.aten.tanh.default(linear_72);  linear_72 = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\dropout.py:73 in forward, code: return F.dropout(input, self.p, self.training, self.inplace)\n",
       "                    clone_26: \"f32[1, 768]\" = torch.ops.aten.clone.default(tanh);  tanh = None\n",
       "            \n",
       "                     # File: d:\\Project\\move-review-sentiment-analysis-model\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_73: \"f32[1, 2]\" = torch.ops.aten.linear.default(clone_26, p_classifier_weight, p_classifier_bias);  clone_26 = p_classifier_weight = p_classifier_bias = None\n",
       "                    return (linear_73,)\n",
       "            \n",
       "        Graph signature: \n",
       "            # inputs\n",
       "            p_bert_embeddings_word_embeddings_weight: PARAMETER target='bert.embeddings.word_embeddings.weight'\n",
       "            p_bert_embeddings_position_embeddings_weight: PARAMETER target='bert.embeddings.position_embeddings.weight'\n",
       "            p_bert_embeddings_token_type_embeddings_weight: PARAMETER target='bert.embeddings.token_type_embeddings.weight'\n",
       "            p_bert_embeddings_layernorm_weight: PARAMETER target='bert.embeddings.LayerNorm.weight'\n",
       "            p_bert_embeddings_layernorm_bias: PARAMETER target='bert.embeddings.LayerNorm.bias'\n",
       "            p_bert_encoder_layer_0_attention_self_query_weight: PARAMETER target='bert.encoder.layer.0.attention.self.query.weight'\n",
       "            p_bert_encoder_layer_0_attention_self_query_bias: PARAMETER target='bert.encoder.layer.0.attention.self.query.bias'\n",
       "            p_bert_encoder_layer_0_attention_self_key_weight: PARAMETER target='bert.encoder.layer.0.attention.self.key.weight'\n",
       "            p_bert_encoder_layer_0_attention_self_key_bias: PARAMETER target='bert.encoder.layer.0.attention.self.key.bias'\n",
       "            p_bert_encoder_layer_0_attention_self_value_weight: PARAMETER target='bert.encoder.layer.0.attention.self.value.weight'\n",
       "            p_bert_encoder_layer_0_attention_self_value_bias: PARAMETER target='bert.encoder.layer.0.attention.self.value.bias'\n",
       "            p_bert_encoder_layer_0_attention_output_dense_weight: PARAMETER target='bert.encoder.layer.0.attention.output.dense.weight'\n",
       "            p_bert_encoder_layer_0_attention_output_dense_bias: PARAMETER target='bert.encoder.layer.0.attention.output.dense.bias'\n",
       "            p_bert_encoder_layer_0_attention_output_layernorm_weight: PARAMETER target='bert.encoder.layer.0.attention.output.LayerNorm.weight'\n",
       "            p_bert_encoder_layer_0_attention_output_layernorm_bias: PARAMETER target='bert.encoder.layer.0.attention.output.LayerNorm.bias'\n",
       "            p_bert_encoder_layer_0_intermediate_dense_weight: PARAMETER target='bert.encoder.layer.0.intermediate.dense.weight'\n",
       "            p_bert_encoder_layer_0_intermediate_dense_bias: PARAMETER target='bert.encoder.layer.0.intermediate.dense.bias'\n",
       "            p_bert_encoder_layer_0_output_dense_weight: PARAMETER target='bert.encoder.layer.0.output.dense.weight'\n",
       "            p_bert_encoder_layer_0_output_dense_bias: PARAMETER target='bert.encoder.layer.0.output.dense.bias'\n",
       "            p_bert_encoder_layer_0_output_layernorm_weight: PARAMETER target='bert.encoder.layer.0.output.LayerNorm.weight'\n",
       "            p_bert_encoder_layer_0_output_layernorm_bias: PARAMETER target='bert.encoder.layer.0.output.LayerNorm.bias'\n",
       "            p_bert_encoder_layer_1_attention_self_query_weight: PARAMETER target='bert.encoder.layer.1.attention.self.query.weight'\n",
       "            p_bert_encoder_layer_1_attention_self_query_bias: PARAMETER target='bert.encoder.layer.1.attention.self.query.bias'\n",
       "            p_bert_encoder_layer_1_attention_self_key_weight: PARAMETER target='bert.encoder.layer.1.attention.self.key.weight'\n",
       "            p_bert_encoder_layer_1_attention_self_key_bias: PARAMETER target='bert.encoder.layer.1.attention.self.key.bias'\n",
       "            p_bert_encoder_layer_1_attention_self_value_weight: PARAMETER target='bert.encoder.layer.1.attention.self.value.weight'\n",
       "            p_bert_encoder_layer_1_attention_self_value_bias: PARAMETER target='bert.encoder.layer.1.attention.self.value.bias'\n",
       "            p_bert_encoder_layer_1_attention_output_dense_weight: PARAMETER target='bert.encoder.layer.1.attention.output.dense.weight'\n",
       "            p_bert_encoder_layer_1_attention_output_dense_bias: PARAMETER target='bert.encoder.layer.1.attention.output.dense.bias'\n",
       "            p_bert_encoder_layer_1_attention_output_layernorm_weight: PARAMETER target='bert.encoder.layer.1.attention.output.LayerNorm.weight'\n",
       "            p_bert_encoder_layer_1_attention_output_layernorm_bias: PARAMETER target='bert.encoder.layer.1.attention.output.LayerNorm.bias'\n",
       "            p_bert_encoder_layer_1_intermediate_dense_weight: PARAMETER target='bert.encoder.layer.1.intermediate.dense.weight'\n",
       "            p_bert_encoder_layer_1_intermediate_dense_bias: PARAMETER target='bert.encoder.layer.1.intermediate.dense.bias'\n",
       "            p_bert_encoder_layer_1_output_dense_weight: PARAMETER target='bert.encoder.layer.1.output.dense.weight'\n",
       "            p_bert_encoder_layer_1_output_dense_bias: PARAMETER target='bert.encoder.layer.1.output.dense.bias'\n",
       "            p_bert_encoder_layer_1_output_layernorm_weight: PARAMETER target='bert.encoder.layer.1.output.LayerNorm.weight'\n",
       "            p_bert_encoder_layer_1_output_layernorm_bias: PARAMETER target='bert.encoder.layer.1.output.LayerNorm.bias'\n",
       "            p_bert_encoder_layer_2_attention_self_query_weight: PARAMETER target='bert.encoder.layer.2.attention.self.query.weight'\n",
       "            p_bert_encoder_layer_2_attention_self_query_bias: PARAMETER target='bert.encoder.layer.2.attention.self.query.bias'\n",
       "            p_bert_encoder_layer_2_attention_self_key_weight: PARAMETER target='bert.encoder.layer.2.attention.self.key.weight'\n",
       "            p_bert_encoder_layer_2_attention_self_key_bias: PARAMETER target='bert.encoder.layer.2.attention.self.key.bias'\n",
       "            p_bert_encoder_layer_2_attention_self_value_weight: PARAMETER target='bert.encoder.layer.2.attention.self.value.weight'\n",
       "            p_bert_encoder_layer_2_attention_self_value_bias: PARAMETER target='bert.encoder.layer.2.attention.self.value.bias'\n",
       "            p_bert_encoder_layer_2_attention_output_dense_weight: PARAMETER target='bert.encoder.layer.2.attention.output.dense.weight'\n",
       "            p_bert_encoder_layer_2_attention_output_dense_bias: PARAMETER target='bert.encoder.layer.2.attention.output.dense.bias'\n",
       "            p_bert_encoder_layer_2_attention_output_layernorm_weight: PARAMETER target='bert.encoder.layer.2.attention.output.LayerNorm.weight'\n",
       "            p_bert_encoder_layer_2_attention_output_layernorm_bias: PARAMETER target='bert.encoder.layer.2.attention.output.LayerNorm.bias'\n",
       "            p_bert_encoder_layer_2_intermediate_dense_weight: PARAMETER target='bert.encoder.layer.2.intermediate.dense.weight'\n",
       "            p_bert_encoder_layer_2_intermediate_dense_bias: PARAMETER target='bert.encoder.layer.2.intermediate.dense.bias'\n",
       "            p_bert_encoder_layer_2_output_dense_weight: PARAMETER target='bert.encoder.layer.2.output.dense.weight'\n",
       "            p_bert_encoder_layer_2_output_dense_bias: PARAMETER target='bert.encoder.layer.2.output.dense.bias'\n",
       "            p_bert_encoder_layer_2_output_layernorm_weight: PARAMETER target='bert.encoder.layer.2.output.LayerNorm.weight'\n",
       "            p_bert_encoder_layer_2_output_layernorm_bias: PARAMETER target='bert.encoder.layer.2.output.LayerNorm.bias'\n",
       "            p_bert_encoder_layer_3_attention_self_query_weight: PARAMETER target='bert.encoder.layer.3.attention.self.query.weight'\n",
       "            p_bert_encoder_layer_3_attention_self_query_bias: PARAMETER target='bert.encoder.layer.3.attention.self.query.bias'\n",
       "            p_bert_encoder_layer_3_attention_self_key_weight: PARAMETER target='bert.encoder.layer.3.attention.self.key.weight'\n",
       "            p_bert_encoder_layer_3_attention_self_key_bias: PARAMETER target='bert.encoder.layer.3.attention.self.key.bias'\n",
       "            p_bert_encoder_layer_3_attention_self_value_weight: PARAMETER target='bert.encoder.layer.3.attention.self.value.weight'\n",
       "            p_bert_encoder_layer_3_attention_self_value_bias: PARAMETER target='bert.encoder.layer.3.attention.self.value.bias'\n",
       "            p_bert_encoder_layer_3_attention_output_dense_weight: PARAMETER target='bert.encoder.layer.3.attention.output.dense.weight'\n",
       "            p_bert_encoder_layer_3_attention_output_dense_bias: PARAMETER target='bert.encoder.layer.3.attention.output.dense.bias'\n",
       "            p_bert_encoder_layer_3_attention_output_layernorm_weight: PARAMETER target='bert.encoder.layer.3.attention.output.LayerNorm.weight'\n",
       "            p_bert_encoder_layer_3_attention_output_layernorm_bias: PARAMETER target='bert.encoder.layer.3.attention.output.LayerNorm.bias'\n",
       "            p_bert_encoder_layer_3_intermediate_dense_weight: PARAMETER target='bert.encoder.layer.3.intermediate.dense.weight'\n",
       "            p_bert_encoder_layer_3_intermediate_dense_bias: PARAMETER target='bert.encoder.layer.3.intermediate.dense.bias'\n",
       "            p_bert_encoder_layer_3_output_dense_weight: PARAMETER target='bert.encoder.layer.3.output.dense.weight'\n",
       "            p_bert_encoder_layer_3_output_dense_bias: PARAMETER target='bert.encoder.layer.3.output.dense.bias'\n",
       "            p_bert_encoder_layer_3_output_layernorm_weight: PARAMETER target='bert.encoder.layer.3.output.LayerNorm.weight'\n",
       "            p_bert_encoder_layer_3_output_layernorm_bias: PARAMETER target='bert.encoder.layer.3.output.LayerNorm.bias'\n",
       "            p_bert_encoder_layer_4_attention_self_query_weight: PARAMETER target='bert.encoder.layer.4.attention.self.query.weight'\n",
       "            p_bert_encoder_layer_4_attention_self_query_bias: PARAMETER target='bert.encoder.layer.4.attention.self.query.bias'\n",
       "            p_bert_encoder_layer_4_attention_self_key_weight: PARAMETER target='bert.encoder.layer.4.attention.self.key.weight'\n",
       "            p_bert_encoder_layer_4_attention_self_key_bias: PARAMETER target='bert.encoder.layer.4.attention.self.key.bias'\n",
       "            p_bert_encoder_layer_4_attention_self_value_weight: PARAMETER target='bert.encoder.layer.4.attention.self.value.weight'\n",
       "            p_bert_encoder_layer_4_attention_self_value_bias: PARAMETER target='bert.encoder.layer.4.attention.self.value.bias'\n",
       "            p_bert_encoder_layer_4_attention_output_dense_weight: PARAMETER target='bert.encoder.layer.4.attention.output.dense.weight'\n",
       "            p_bert_encoder_layer_4_attention_output_dense_bias: PARAMETER target='bert.encoder.layer.4.attention.output.dense.bias'\n",
       "            p_bert_encoder_layer_4_attention_output_layernorm_weight: PARAMETER target='bert.encoder.layer.4.attention.output.LayerNorm.weight'\n",
       "            p_bert_encoder_layer_4_attention_output_layernorm_bias: PARAMETER target='bert.encoder.layer.4.attention.output.LayerNorm.bias'\n",
       "            p_bert_encoder_layer_4_intermediate_dense_weight: PARAMETER target='bert.encoder.layer.4.intermediate.dense.weight'\n",
       "            p_bert_encoder_layer_4_intermediate_dense_bias: PARAMETER target='bert.encoder.layer.4.intermediate.dense.bias'\n",
       "            p_bert_encoder_layer_4_output_dense_weight: PARAMETER target='bert.encoder.layer.4.output.dense.weight'\n",
       "            p_bert_encoder_layer_4_output_dense_bias: PARAMETER target='bert.encoder.layer.4.output.dense.bias'\n",
       "            p_bert_encoder_layer_4_output_layernorm_weight: PARAMETER target='bert.encoder.layer.4.output.LayerNorm.weight'\n",
       "            p_bert_encoder_layer_4_output_layernorm_bias: PARAMETER target='bert.encoder.layer.4.output.LayerNorm.bias'\n",
       "            p_bert_encoder_layer_5_attention_self_query_weight: PARAMETER target='bert.encoder.layer.5.attention.self.query.weight'\n",
       "            p_bert_encoder_layer_5_attention_self_query_bias: PARAMETER target='bert.encoder.layer.5.attention.self.query.bias'\n",
       "            p_bert_encoder_layer_5_attention_self_key_weight: PARAMETER target='bert.encoder.layer.5.attention.self.key.weight'\n",
       "            p_bert_encoder_layer_5_attention_self_key_bias: PARAMETER target='bert.encoder.layer.5.attention.self.key.bias'\n",
       "            p_bert_encoder_layer_5_attention_self_value_weight: PARAMETER target='bert.encoder.layer.5.attention.self.value.weight'\n",
       "            p_bert_encoder_layer_5_attention_self_value_bias: PARAMETER target='bert.encoder.layer.5.attention.self.value.bias'\n",
       "            p_bert_encoder_layer_5_attention_output_dense_weight: PARAMETER target='bert.encoder.layer.5.attention.output.dense.weight'\n",
       "            p_bert_encoder_layer_5_attention_output_dense_bias: PARAMETER target='bert.encoder.layer.5.attention.output.dense.bias'\n",
       "            p_bert_encoder_layer_5_attention_output_layernorm_weight: PARAMETER target='bert.encoder.layer.5.attention.output.LayerNorm.weight'\n",
       "            p_bert_encoder_layer_5_attention_output_layernorm_bias: PARAMETER target='bert.encoder.layer.5.attention.output.LayerNorm.bias'\n",
       "            p_bert_encoder_layer_5_intermediate_dense_weight: PARAMETER target='bert.encoder.layer.5.intermediate.dense.weight'\n",
       "            p_bert_encoder_layer_5_intermediate_dense_bias: PARAMETER target='bert.encoder.layer.5.intermediate.dense.bias'\n",
       "            p_bert_encoder_layer_5_output_dense_weight: PARAMETER target='bert.encoder.layer.5.output.dense.weight'\n",
       "            p_bert_encoder_layer_5_output_dense_bias: PARAMETER target='bert.encoder.layer.5.output.dense.bias'\n",
       "            p_bert_encoder_layer_5_output_layernorm_weight: PARAMETER target='bert.encoder.layer.5.output.LayerNorm.weight'\n",
       "            p_bert_encoder_layer_5_output_layernorm_bias: PARAMETER target='bert.encoder.layer.5.output.LayerNorm.bias'\n",
       "            p_bert_encoder_layer_6_attention_self_query_weight: PARAMETER target='bert.encoder.layer.6.attention.self.query.weight'\n",
       "            p_bert_encoder_layer_6_attention_self_query_bias: PARAMETER target='bert.encoder.layer.6.attention.self.query.bias'\n",
       "            p_bert_encoder_layer_6_attention_self_key_weight: PARAMETER target='bert.encoder.layer.6.attention.self.key.weight'\n",
       "            p_bert_encoder_layer_6_attention_self_key_bias: PARAMETER target='bert.encoder.layer.6.attention.self.key.bias'\n",
       "            p_bert_encoder_layer_6_attention_self_value_weight: PARAMETER target='bert.encoder.layer.6.attention.self.value.weight'\n",
       "            p_bert_encoder_layer_6_attention_self_value_bias: PARAMETER target='bert.encoder.layer.6.attention.self.value.bias'\n",
       "            p_bert_encoder_layer_6_attention_output_dense_weight: PARAMETER target='bert.encoder.layer.6.attention.output.dense.weight'\n",
       "            p_bert_encoder_layer_6_attention_output_dense_bias: PARAMETER target='bert.encoder.layer.6.attention.output.dense.bias'\n",
       "            p_bert_encoder_layer_6_attention_output_layernorm_weight: PARAMETER target='bert.encoder.layer.6.attention.output.LayerNorm.weight'\n",
       "            p_bert_encoder_layer_6_attention_output_layernorm_bias: PARAMETER target='bert.encoder.layer.6.attention.output.LayerNorm.bias'\n",
       "            p_bert_encoder_layer_6_intermediate_dense_weight: PARAMETER target='bert.encoder.layer.6.intermediate.dense.weight'\n",
       "            p_bert_encoder_layer_6_intermediate_dense_bias: PARAMETER target='bert.encoder.layer.6.intermediate.dense.bias'\n",
       "            p_bert_encoder_layer_6_output_dense_weight: PARAMETER target='bert.encoder.layer.6.output.dense.weight'\n",
       "            p_bert_encoder_layer_6_output_dense_bias: PARAMETER target='bert.encoder.layer.6.output.dense.bias'\n",
       "            p_bert_encoder_layer_6_output_layernorm_weight: PARAMETER target='bert.encoder.layer.6.output.LayerNorm.weight'\n",
       "            p_bert_encoder_layer_6_output_layernorm_bias: PARAMETER target='bert.encoder.layer.6.output.LayerNorm.bias'\n",
       "            p_bert_encoder_layer_7_attention_self_query_weight: PARAMETER target='bert.encoder.layer.7.attention.self.query.weight'\n",
       "            p_bert_encoder_layer_7_attention_self_query_bias: PARAMETER target='bert.encoder.layer.7.attention.self.query.bias'\n",
       "            p_bert_encoder_layer_7_attention_self_key_weight: PARAMETER target='bert.encoder.layer.7.attention.self.key.weight'\n",
       "            p_bert_encoder_layer_7_attention_self_key_bias: PARAMETER target='bert.encoder.layer.7.attention.self.key.bias'\n",
       "            p_bert_encoder_layer_7_attention_self_value_weight: PARAMETER target='bert.encoder.layer.7.attention.self.value.weight'\n",
       "            p_bert_encoder_layer_7_attention_self_value_bias: PARAMETER target='bert.encoder.layer.7.attention.self.value.bias'\n",
       "            p_bert_encoder_layer_7_attention_output_dense_weight: PARAMETER target='bert.encoder.layer.7.attention.output.dense.weight'\n",
       "            p_bert_encoder_layer_7_attention_output_dense_bias: PARAMETER target='bert.encoder.layer.7.attention.output.dense.bias'\n",
       "            p_bert_encoder_layer_7_attention_output_layernorm_weight: PARAMETER target='bert.encoder.layer.7.attention.output.LayerNorm.weight'\n",
       "            p_bert_encoder_layer_7_attention_output_layernorm_bias: PARAMETER target='bert.encoder.layer.7.attention.output.LayerNorm.bias'\n",
       "            p_bert_encoder_layer_7_intermediate_dense_weight: PARAMETER target='bert.encoder.layer.7.intermediate.dense.weight'\n",
       "            p_bert_encoder_layer_7_intermediate_dense_bias: PARAMETER target='bert.encoder.layer.7.intermediate.dense.bias'\n",
       "            p_bert_encoder_layer_7_output_dense_weight: PARAMETER target='bert.encoder.layer.7.output.dense.weight'\n",
       "            p_bert_encoder_layer_7_output_dense_bias: PARAMETER target='bert.encoder.layer.7.output.dense.bias'\n",
       "            p_bert_encoder_layer_7_output_layernorm_weight: PARAMETER target='bert.encoder.layer.7.output.LayerNorm.weight'\n",
       "            p_bert_encoder_layer_7_output_layernorm_bias: PARAMETER target='bert.encoder.layer.7.output.LayerNorm.bias'\n",
       "            p_bert_encoder_layer_8_attention_self_query_weight: PARAMETER target='bert.encoder.layer.8.attention.self.query.weight'\n",
       "            p_bert_encoder_layer_8_attention_self_query_bias: PARAMETER target='bert.encoder.layer.8.attention.self.query.bias'\n",
       "            p_bert_encoder_layer_8_attention_self_key_weight: PARAMETER target='bert.encoder.layer.8.attention.self.key.weight'\n",
       "            p_bert_encoder_layer_8_attention_self_key_bias: PARAMETER target='bert.encoder.layer.8.attention.self.key.bias'\n",
       "            p_bert_encoder_layer_8_attention_self_value_weight: PARAMETER target='bert.encoder.layer.8.attention.self.value.weight'\n",
       "            p_bert_encoder_layer_8_attention_self_value_bias: PARAMETER target='bert.encoder.layer.8.attention.self.value.bias'\n",
       "            p_bert_encoder_layer_8_attention_output_dense_weight: PARAMETER target='bert.encoder.layer.8.attention.output.dense.weight'\n",
       "            p_bert_encoder_layer_8_attention_output_dense_bias: PARAMETER target='bert.encoder.layer.8.attention.output.dense.bias'\n",
       "            p_bert_encoder_layer_8_attention_output_layernorm_weight: PARAMETER target='bert.encoder.layer.8.attention.output.LayerNorm.weight'\n",
       "            p_bert_encoder_layer_8_attention_output_layernorm_bias: PARAMETER target='bert.encoder.layer.8.attention.output.LayerNorm.bias'\n",
       "            p_bert_encoder_layer_8_intermediate_dense_weight: PARAMETER target='bert.encoder.layer.8.intermediate.dense.weight'\n",
       "            p_bert_encoder_layer_8_intermediate_dense_bias: PARAMETER target='bert.encoder.layer.8.intermediate.dense.bias'\n",
       "            p_bert_encoder_layer_8_output_dense_weight: PARAMETER target='bert.encoder.layer.8.output.dense.weight'\n",
       "            p_bert_encoder_layer_8_output_dense_bias: PARAMETER target='bert.encoder.layer.8.output.dense.bias'\n",
       "            p_bert_encoder_layer_8_output_layernorm_weight: PARAMETER target='bert.encoder.layer.8.output.LayerNorm.weight'\n",
       "            p_bert_encoder_layer_8_output_layernorm_bias: PARAMETER target='bert.encoder.layer.8.output.LayerNorm.bias'\n",
       "            p_bert_encoder_layer_9_attention_self_query_weight: PARAMETER target='bert.encoder.layer.9.attention.self.query.weight'\n",
       "            p_bert_encoder_layer_9_attention_self_query_bias: PARAMETER target='bert.encoder.layer.9.attention.self.query.bias'\n",
       "            p_bert_encoder_layer_9_attention_self_key_weight: PARAMETER target='bert.encoder.layer.9.attention.self.key.weight'\n",
       "            p_bert_encoder_layer_9_attention_self_key_bias: PARAMETER target='bert.encoder.layer.9.attention.self.key.bias'\n",
       "            p_bert_encoder_layer_9_attention_self_value_weight: PARAMETER target='bert.encoder.layer.9.attention.self.value.weight'\n",
       "            p_bert_encoder_layer_9_attention_self_value_bias: PARAMETER target='bert.encoder.layer.9.attention.self.value.bias'\n",
       "            p_bert_encoder_layer_9_attention_output_dense_weight: PARAMETER target='bert.encoder.layer.9.attention.output.dense.weight'\n",
       "            p_bert_encoder_layer_9_attention_output_dense_bias: PARAMETER target='bert.encoder.layer.9.attention.output.dense.bias'\n",
       "            p_bert_encoder_layer_9_attention_output_layernorm_weight: PARAMETER target='bert.encoder.layer.9.attention.output.LayerNorm.weight'\n",
       "            p_bert_encoder_layer_9_attention_output_layernorm_bias: PARAMETER target='bert.encoder.layer.9.attention.output.LayerNorm.bias'\n",
       "            p_bert_encoder_layer_9_intermediate_dense_weight: PARAMETER target='bert.encoder.layer.9.intermediate.dense.weight'\n",
       "            p_bert_encoder_layer_9_intermediate_dense_bias: PARAMETER target='bert.encoder.layer.9.intermediate.dense.bias'\n",
       "            p_bert_encoder_layer_9_output_dense_weight: PARAMETER target='bert.encoder.layer.9.output.dense.weight'\n",
       "            p_bert_encoder_layer_9_output_dense_bias: PARAMETER target='bert.encoder.layer.9.output.dense.bias'\n",
       "            p_bert_encoder_layer_9_output_layernorm_weight: PARAMETER target='bert.encoder.layer.9.output.LayerNorm.weight'\n",
       "            p_bert_encoder_layer_9_output_layernorm_bias: PARAMETER target='bert.encoder.layer.9.output.LayerNorm.bias'\n",
       "            p_bert_encoder_layer_10_attention_self_query_weight: PARAMETER target='bert.encoder.layer.10.attention.self.query.weight'\n",
       "            p_bert_encoder_layer_10_attention_self_query_bias: PARAMETER target='bert.encoder.layer.10.attention.self.query.bias'\n",
       "            p_bert_encoder_layer_10_attention_self_key_weight: PARAMETER target='bert.encoder.layer.10.attention.self.key.weight'\n",
       "            p_bert_encoder_layer_10_attention_self_key_bias: PARAMETER target='bert.encoder.layer.10.attention.self.key.bias'\n",
       "            p_bert_encoder_layer_10_attention_self_value_weight: PARAMETER target='bert.encoder.layer.10.attention.self.value.weight'\n",
       "            p_bert_encoder_layer_10_attention_self_value_bias: PARAMETER target='bert.encoder.layer.10.attention.self.value.bias'\n",
       "            p_bert_encoder_layer_10_attention_output_dense_weight: PARAMETER target='bert.encoder.layer.10.attention.output.dense.weight'\n",
       "            p_bert_encoder_layer_10_attention_output_dense_bias: PARAMETER target='bert.encoder.layer.10.attention.output.dense.bias'\n",
       "            p_bert_encoder_layer_10_attention_output_layernorm_weight: PARAMETER target='bert.encoder.layer.10.attention.output.LayerNorm.weight'\n",
       "            p_bert_encoder_layer_10_attention_output_layernorm_bias: PARAMETER target='bert.encoder.layer.10.attention.output.LayerNorm.bias'\n",
       "            p_bert_encoder_layer_10_intermediate_dense_weight: PARAMETER target='bert.encoder.layer.10.intermediate.dense.weight'\n",
       "            p_bert_encoder_layer_10_intermediate_dense_bias: PARAMETER target='bert.encoder.layer.10.intermediate.dense.bias'\n",
       "            p_bert_encoder_layer_10_output_dense_weight: PARAMETER target='bert.encoder.layer.10.output.dense.weight'\n",
       "            p_bert_encoder_layer_10_output_dense_bias: PARAMETER target='bert.encoder.layer.10.output.dense.bias'\n",
       "            p_bert_encoder_layer_10_output_layernorm_weight: PARAMETER target='bert.encoder.layer.10.output.LayerNorm.weight'\n",
       "            p_bert_encoder_layer_10_output_layernorm_bias: PARAMETER target='bert.encoder.layer.10.output.LayerNorm.bias'\n",
       "            p_bert_encoder_layer_11_attention_self_query_weight: PARAMETER target='bert.encoder.layer.11.attention.self.query.weight'\n",
       "            p_bert_encoder_layer_11_attention_self_query_bias: PARAMETER target='bert.encoder.layer.11.attention.self.query.bias'\n",
       "            p_bert_encoder_layer_11_attention_self_key_weight: PARAMETER target='bert.encoder.layer.11.attention.self.key.weight'\n",
       "            p_bert_encoder_layer_11_attention_self_key_bias: PARAMETER target='bert.encoder.layer.11.attention.self.key.bias'\n",
       "            p_bert_encoder_layer_11_attention_self_value_weight: PARAMETER target='bert.encoder.layer.11.attention.self.value.weight'\n",
       "            p_bert_encoder_layer_11_attention_self_value_bias: PARAMETER target='bert.encoder.layer.11.attention.self.value.bias'\n",
       "            p_bert_encoder_layer_11_attention_output_dense_weight: PARAMETER target='bert.encoder.layer.11.attention.output.dense.weight'\n",
       "            p_bert_encoder_layer_11_attention_output_dense_bias: PARAMETER target='bert.encoder.layer.11.attention.output.dense.bias'\n",
       "            p_bert_encoder_layer_11_attention_output_layernorm_weight: PARAMETER target='bert.encoder.layer.11.attention.output.LayerNorm.weight'\n",
       "            p_bert_encoder_layer_11_attention_output_layernorm_bias: PARAMETER target='bert.encoder.layer.11.attention.output.LayerNorm.bias'\n",
       "            p_bert_encoder_layer_11_intermediate_dense_weight: PARAMETER target='bert.encoder.layer.11.intermediate.dense.weight'\n",
       "            p_bert_encoder_layer_11_intermediate_dense_bias: PARAMETER target='bert.encoder.layer.11.intermediate.dense.bias'\n",
       "            p_bert_encoder_layer_11_output_dense_weight: PARAMETER target='bert.encoder.layer.11.output.dense.weight'\n",
       "            p_bert_encoder_layer_11_output_dense_bias: PARAMETER target='bert.encoder.layer.11.output.dense.bias'\n",
       "            p_bert_encoder_layer_11_output_layernorm_weight: PARAMETER target='bert.encoder.layer.11.output.LayerNorm.weight'\n",
       "            p_bert_encoder_layer_11_output_layernorm_bias: PARAMETER target='bert.encoder.layer.11.output.LayerNorm.bias'\n",
       "            p_bert_pooler_dense_weight: PARAMETER target='bert.pooler.dense.weight'\n",
       "            p_bert_pooler_dense_bias: PARAMETER target='bert.pooler.dense.bias'\n",
       "            p_classifier_weight: PARAMETER target='classifier.weight'\n",
       "            p_classifier_bias: PARAMETER target='classifier.bias'\n",
       "            c_bert_lifted_tensor_0: CONSTANT_TENSOR target='bert.lifted_tensor_0'\n",
       "            b_bert_embeddings_position_ids: BUFFER target='bert.embeddings.position_ids' persistent=False\n",
       "            b_bert_embeddings_token_type_ids: BUFFER target='bert.embeddings.token_type_ids' persistent=False\n",
       "            input_ids: USER_INPUT\n",
       "            attention_mask: USER_INPUT\n",
       "    \n",
       "            # outputs\n",
       "            linear_73: USER_OUTPUT\n",
       "    \n",
       "        Range constraints: {}\n",
       "\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_input = tokenizer(\"This movie is good.\", return_tensors=\"pt\")\n",
    "\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    (dummy_input[\"input_ids\"], dummy_input[\"attention_mask\"]), # example inputs\n",
    "    \"../deploy/movie-review-sentiment-analysis.onnx\",\n",
    "    input_names=[\"input_ids\", \"attention_mask\"],\n",
    "    output_names=[\"logits\"],\n",
    "    opset_version=14,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990cd0fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "move-review-sentiment-analysis-model",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
